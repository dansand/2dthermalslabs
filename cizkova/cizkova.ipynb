{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## composite, non-linear rheology:\n",
    "\n",
    "\n",
    "The viscous rheology in this model is similar to the Čížková and Bina paper cited below. Other parts of the model setup are similar to Arredondo and Billen (2016) and Korenaga (2011). \n",
    "\n",
    "Here we use a dimensionless system. For the psuedo-plastic effective rheology a Drucker-prager model is used.\n",
    "\n",
    "\n",
    "**Keywords:** thermal covection, dislocation creep\n",
    "\n",
    "\n",
    "**References**\n",
    "\n",
    "Čížková, Hana, and Craig R. Bina. \"Geodynamics of trench advance: Insights from a Philippine-Sea-style geometry.\" Earth and Planetary Science Letters 430 (2015): 408-415.\n",
    "\n",
    "Arredondo, Katrina M., and Magali I. Billen. \"The Effects of Phase Transitions and Compositional Layering in Two-dimensional Kinematic Models of Subduction.\" Journal of Geodynamics (2016).\n",
    "\n",
    "Korenaga, Jun. \"Scaling of plate tectonic convection with pseudoplastic rheology.\" Journal of Geophysical Research: Solid Earth 115.B11 (2010)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import underworld as uw\n",
    "import math\n",
    "from underworld import function as fn\n",
    "import glucifer\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import natsort\n",
    "import shutil\n",
    "from easydict import EasyDict as edict\n",
    "import operator\n",
    "import pint\n",
    "import time\n",
    "import operator\n",
    "from slippy2 import boundary_layer2d\n",
    "from slippy2 import material_graph\n",
    "from slippy2 import spmesh\n",
    "\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model name and directories\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############\n",
    "#Model name.  \n",
    "############\n",
    "Model = \"T\"\n",
    "ModNum = 9\n",
    "\n",
    "if len(sys.argv) == 1:\n",
    "    ModIt = \"Base\"\n",
    "elif sys.argv[1] == '-f':\n",
    "    ModIt = \"Base\"\n",
    "else:\n",
    "    ModIt = str(sys.argv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Standard output directory setup\n",
    "###########\n",
    "\n",
    "\n",
    "outputPath = \"results\" + \"/\" +  str(Model) + \"/\" + str(ModNum) + \"/\" + str(ModIt) + \"/\"\n",
    "imagePath = outputPath + 'images/'\n",
    "filePath = outputPath + 'files/'\n",
    "checkpointPath = outputPath + 'checkpoint/'\n",
    "dbPath = outputPath + 'gldbs/'\n",
    "outputFile = 'results_model' + Model + '_' + str(ModNum) + '_' + str(ModIt) + '.dat'\n",
    "\n",
    "if uw.rank()==0:\n",
    "    # make directories if they don't exist\n",
    "    if not os.path.isdir(outputPath):\n",
    "        os.makedirs(outputPath)\n",
    "    if not os.path.isdir(checkpointPath):\n",
    "        os.makedirs(checkpointPath)\n",
    "    if not os.path.isdir(imagePath):\n",
    "        os.makedirs(imagePath)\n",
    "    if not os.path.isdir(dbPath):\n",
    "        os.makedirs(dbPath)\n",
    "    if not os.path.isdir(filePath):\n",
    "        os.makedirs(filePath)\n",
    "        \n",
    "comm.Barrier() #Barrier here so no procs run the check in the next cell too early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/T/9/Base/checkpoint/ is empty\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "#Check if starting from checkpoint\n",
    "###########\n",
    "\n",
    "checkdirs = []\n",
    "for dirpath, dirnames, files in os.walk(checkpointPath):\n",
    "    if files:\n",
    "        print dirpath, 'has files'\n",
    "        checkpointLoad = True\n",
    "        checkdirs.append(dirpath)\n",
    "    if not files:\n",
    "        print dirpath, 'is empty'\n",
    "        checkpointLoad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup parameters\n",
    "-----\n",
    "\n",
    "Set simulation parameters for test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use pint to setup any unit conversions we'll need**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "10000.0 meter/megayear"
      ],
      "text/latex": [
       "$10000.0 \\frac{meter}{megayear}$"
      ],
      "text/plain": [
       "<Quantity(10000.0, 'meter / megayear')>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = pint.UnitRegistry()\n",
    "cmpery = 1.*u.cm/u.year\n",
    "mpermy = 1.*u.m/u.megayear\n",
    "\n",
    "cmpery.to(mpermy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set parameter dictionaries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Store the physical paramters, scale factors and dimensionless pramters in easyDicts\n",
    "#Mainly helps with avoiding overwriting variables\n",
    "###########\n",
    "\n",
    "dp = edict({#'LS':2900.*1e3,\n",
    "            'LS':2000.*1e3,\n",
    "           'rho':3300,\n",
    "           'g':9.8, \n",
    "           'eta0':4e20, #Dislocation creep at 250 km, 1573 K, 1e-15 s-1 \n",
    "           'k':1e-6,\n",
    "           'a':3e-5, #surface thermal expansivity\n",
    "           'TP':1573., #potential temp\n",
    "           'TS':273., #surface temp\n",
    "           'cohesion':1e7, #\n",
    "           'fc':0.06,   \n",
    "           'Adf':1e-9,\n",
    "           'Ads':3.1e-17,\n",
    "           'Edf':3.35e5,\n",
    "           'Eds':4.8e5,\n",
    "           'Vdf':4e-6,\n",
    "           'Vds':11e-6,\n",
    "           'Alm':1.3e-16,\n",
    "           'Elm':2.0e5,\n",
    "           'Vlm':1.1e-6,\n",
    "           'Ba':4.3e-12,  #A value to simulate pressure increase with depth\n",
    "           'SR':1e-15,\n",
    "           'Dr':250e3, #Reference depth\n",
    "           'R':8.314,\n",
    "           'Cp':1250., #Jkg-1K-1\n",
    "           'StALS':100e3,\n",
    "           'plate_vel':8})\n",
    "\n",
    "#Adibatic heating stuff\n",
    "dp.dTa = (dp.a*dp.g*(dp.TP))/dp.Cp #adibatic gradient, at Tp\n",
    "dp.deltaTa = (dp.TP + dp.dTa*dp.LS) - dp.TS  #Adiabatic Temp at base of mantle, minus Ts\n",
    "dp.deltaT = dp.deltaTa\n",
    "\n",
    "\n",
    "\n",
    "#scale_factors\n",
    "\n",
    "sf = edict({'stress':dp.LS**2/(dp.k*dp.eta0),\n",
    "            'lith_grad':dp.rho*dp.g*(dp.LS)**3/(dp.eta0*dp.k) ,\n",
    "            'vel':dp.LS/dp.k,\n",
    "            'SR':dp.LS**2/dp.k,\n",
    "            'W':(-1./dp.Ba)*(np.log(1.-dp.rho*dp.g*dp.Ba*dp.LS))/(dp.R*dp.deltaTa), #Including adiabatic compression, and deltaTa\n",
    "            'E': 1./(dp.R*dp.deltaTa), #using deltaTa, the guesstimated adiabatic temp differnnce to scale these paramters\n",
    "            #'Ads':(dp.eta0**(ndp.n-2))*((dp.k)**(ndp.n-1))*((dp.LS)**(2. - 2*ndp.n))       \n",
    "           })\n",
    "\n",
    "#dimensionless parameters\n",
    "\n",
    "ndp = edict({'RA':(dp.g*dp.rho*dp.a*dp.deltaT*(dp.LS)**3)/(dp.k*dp.eta0),\n",
    "            'cohesion':dp.cohesion*sf.stress,\n",
    "            'fcd':dp.fc*sf.lith_grad,\n",
    "            'gamma':dp.fc/(dp.a*dp.deltaT),\n",
    "            'Wdf':dp.Vdf*sf.W,\n",
    "            'Edf':dp.Edf*sf.E,\n",
    "            'Wds':dp.Vds*sf.W,\n",
    "            'Eds':dp.Eds*sf.E,\n",
    "            'Elm':dp.Elm*sf.E,\n",
    "           'Wlm':dp.Vlm*sf.W,\n",
    "            'TSP':0., \n",
    "            'TBP':1.,\n",
    "            'TPP':(dp.TP - dp.TS)/dp.deltaT,\n",
    "            'Dr':dp.Dr/dp.LS,\n",
    "            'n':3.5,\n",
    "            'TS':dp.TS/dp.deltaT,\n",
    "            'TP':dp.TP/dp.deltaT,\n",
    "             #'eta_crust':1e21/dp.eta0,\n",
    "             'eta_crust':0.06,\n",
    "            'eta_min':1e-3,\n",
    "            'eta_max':1e5,\n",
    "            'H':0.,\n",
    "            'Tmvp':0.6,\n",
    "             'Di': dp.a*dp.g*dp.LS/dp.Cp, #Dissipation number\n",
    "            'Steta0':1e2,\n",
    "            'plate_vel':sf.vel*dp.plate_vel*(cmpery.to(u.m/u.second)).magnitude,})\n",
    "\n",
    "\n",
    "\n",
    "#Make some further additions to paramter dictionaries\n",
    "\n",
    "#dp.VR = (0.1*(dp.k/dp.LS)*ndp.RA**(2/3.)) #characteristic velocity from a scaling relationship\n",
    "#dp.SR = dp.VR/dp.LS #characteristic strain rate\n",
    "#ndp.VR = dp.VR*sf.vel #characteristic velocity\n",
    "#ndp.SR = dp.SR*sf.SR #characteristic strain rate\n",
    "\n",
    "dp.SR = 1e-15\n",
    "ndp.SR = dp.SR*sf.SR #characteristic strain rate\n",
    "\n",
    "ndp.StRA = (3300.*dp.g*(dp.LS)**3)/(dp.eta0 *dp.k) #Composisitional Rayleigh number for rock-air buoyancy force\n",
    "ndp.TaP = 1. - ndp.TPP,  #Dimensionles adiabtic component of delta t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ndp.RA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#A few parameters defining lengths scales, affects materal transistions etc.\n",
    "###########\n",
    "\n",
    "MANTLETOCRUST = (18.*1e3)/dp.LS #Crust depth\n",
    "HARZBURGDEPTH = MANTLETOCRUST + (27.7e3/dp.LS)\n",
    "CRUSTTOMANTLE = (200.*1e3)/dp.LS\n",
    "LITHTOMANTLE = (900.*1e3)/dp.LS \n",
    "MANTLETOLITH = (200.*1e3)/dp.LS \n",
    "TOPOHEIGHT = (10.*1e3)/dp.LS  #rock-air topography limits\n",
    "CRUSTTOECL  = (100.*1e3)/dp.LS\n",
    "AVGTEMP = ndp.TPP #Used to define lithosphere\n",
    "LOWERMANTLE = (1000.*1e3)/dp.LS \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setup parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Model setup parameters\n",
    "###########\n",
    "\n",
    "refineMesh = True\n",
    "stickyAir = False \n",
    "lower_mantle = False \n",
    "melt_viscosity_reduction= False\n",
    "symmetric_IC = False\n",
    "VelBC = True\n",
    "WeakZone = True\n",
    "\n",
    "\n",
    "MINX = -2.\n",
    "MINY = 0.\n",
    "MAXX = 2.\n",
    "\n",
    "#MAXY = 1.035\n",
    "MAXY = 1.\n",
    "\n",
    "if MINX == 0.:\n",
    "    squareModel = True\n",
    "else: \n",
    "    squareModel = False\n",
    "    \n",
    "    \n",
    "dim = 2          # number of spatial dimensions\n",
    "\n",
    "\n",
    "#MESH STUFF\n",
    "\n",
    "RES = 64\n",
    "\n",
    "Xres = int(RES*4)\n",
    "\n",
    "\n",
    "if stickyAir:\n",
    "    Yres = RES\n",
    "    MAXY = 1. + dp.StALS/dp.LS #150km\n",
    "    \n",
    "else:\n",
    "    Yres = RES\n",
    "    MAXY = 1.\n",
    "\n",
    "\n",
    "periodic = [True, False]\n",
    "elementType = \"Q1/dQ0\"\n",
    "#elementType =\"Q2/DPC1\"\n",
    "\n",
    "\n",
    "#System/Solver stuff\n",
    "\n",
    "PIC_integration=True\n",
    "ppc = 25\n",
    "\n",
    "#Output and safety stuff\n",
    "swarm_repop, swarm_update = 10, 10\n",
    "gldbs_output = 20\n",
    "checkpoint_every, files_output = 50, 50\n",
    "metric_output = 10\n",
    "sticky_air_temp = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create mesh and finite element variables\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mesh = uw.mesh.FeMesh_Cartesian( elementType = (elementType),\n",
    "                                 elementRes  = (Xres, Yres), \n",
    "                                 minCoord    = (MINX, MINY), \n",
    "                                 maxCoord    = (MAXX, MAXY), periodic=periodic)\n",
    "\n",
    "velocityField       = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=2 )\n",
    "pressureField       = uw.mesh.MeshVariable( mesh=mesh.subMesh, nodeDofCount=1 )\n",
    "temperatureField    = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=1 )\n",
    "temperatureDotField = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mesh.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min\n",
      "(256, 0.012501562500000001, 4.200400000000001, -0.20040000000000086)\n",
      "('edges', 256)\n",
      "-- iteration 0 --\n",
      "| F( p_n ) |^2: 1.98165943146e-05\n",
      "| p_n+1 - p_n |^2: 1.36480086187\n",
      "-- iteration 1 --\n",
      "| F( p_n ) |^2: 3.58989730515e-30\n",
      "Min, Max element width: \n",
      "0.01250\n",
      "0.01875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#X-Axis\n",
    "\n",
    "if refineMesh:\n",
    "    mesh.reset()\n",
    "    axis = 0\n",
    "    origcoords = np.linspace(mesh.minCoord[axis], mesh.maxCoord[axis], mesh.elementRes[axis] + 1)\n",
    "    edge_rest_lengths = np.diff(origcoords)\n",
    "\n",
    "    deform_lengths = edge_rest_lengths.copy()\n",
    "    min_point =  (abs(mesh.maxCoord[axis]) - abs(mesh.minCoord[axis]))/2.\n",
    "    el_reduction = 0.8001\n",
    "    dx = mesh.maxCoord[axis] - min_point\n",
    "\n",
    "    deform_lengths = deform_lengths - \\\n",
    "                                    ((1.-el_reduction) *deform_lengths[0]) + \\\n",
    "                                    abs((origcoords[1:] - min_point))*((0.5*deform_lengths[0])/dx)\n",
    "\n",
    "    #print(edge_rest_lengths.shape, deform_lengths.shape)\n",
    "\n",
    "    spmesh.deform_1d(deform_lengths, mesh,axis = 'x',norm = 'Min', constraints = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "axis = 1\n",
    "orgs = np.linspace(mesh.minCoord[axis], mesh.maxCoord[axis], mesh.elementRes[axis] + 1)\n",
    "\n",
    "value_to_constrain = 1.\n",
    "\n",
    "\n",
    "yconst = [(spmesh.find_closest(orgs, value_to_constrain), np.array([value_to_constrain,0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min\n",
      "(64, 0.0093765624999999995, 0.84619375000000008, 0.62499047619047554)\n",
      "('edges', 64)\n",
      "-- iteration 0 --\n",
      "| F( p_n ) |^2: 8.05648611886e-05\n",
      "| p_n+1 - p_n |^2: 0.352079185376\n",
      "-- iteration 1 --\n",
      "| F( p_n ) |^2: 3.12512226132e-31\n",
      "Min, Max element width: \n",
      "0.00938\n",
      "0.02187\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "#Mesh refinement\n",
    "###########\n",
    "\n",
    "if refineMesh:\n",
    "    #Y-Axis\n",
    "    axis = 1\n",
    "    origcoords = np.linspace(mesh.minCoord[axis], mesh.maxCoord[axis], mesh.elementRes[axis] + 1)\n",
    "    edge_rest_lengths = np.diff(origcoords)\n",
    "\n",
    "    deform_lengths = edge_rest_lengths.copy()\n",
    "    min_point =  (mesh.maxCoord[axis])\n",
    "    el_reduction = 0.6001\n",
    "    dx = mesh.maxCoord[axis]\n",
    "\n",
    "    deform_lengths = deform_lengths - \\\n",
    "                                    ((1.-el_reduction)*deform_lengths[0]) + \\\n",
    "                                    abs((origcoords[1:] - min_point))*((0.5*deform_lengths[0])/dx)\n",
    "\n",
    "    #print(edge_rest_lengths.shape, deform_lengths.shape)\n",
    "\n",
    "    spmesh.deform_1d(deform_lengths, mesh,axis = 'y',norm = 'Min', constraints = yconst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial conditions\n",
    "-------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coordinate = fn.input()\n",
    "depthFn = 1. - coordinate[1] #a function providing the depth\n",
    "xFn = coordinate[0]  #a function providing the x-coordinate\n",
    "\n",
    "potTempFn = ndp.TPP + (depthFn)*ndp.TaP #a function providing the adiabatic temp at any depth\n",
    "abHeatFn = -1.*velocityField[1]*temperatureField*ndp.Di #a function providing the adiabatic heating rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Thermal initial condition:\n",
    "#if symmetric_IC, we build a symmetric downwelling on top of a sinusoidal perturbation\n",
    "##########\n",
    "\n",
    "#Sinusoidal initial condition\n",
    "A = 0.2\n",
    "sinFn = depthFn + A*(fn.math.cos( math.pi * coordinate[0])  * fn.math.sin( math.pi * coordinate[1] ))        \n",
    "iD = 660e3/dp.LS #Initial Slab depth\n",
    "dl =  2*math.sqrt(dp.k*160e6*3600*24*365) #diffusion Length at ... My\n",
    "w0 = dl/dp.LS #Boundary layer/slab initial condition\n",
    "delX1 = fn.misc.min(fn.math.abs(coordinate[0] - -0.), fn.math.abs(coordinate[0] - -2.))\n",
    "delX = fn.misc.min(delX1 , fn.math.abs(coordinate[0] - 2.))\n",
    "w = w0*fn.math.sqrt(delX + 1e-7)\n",
    "tempBL = (potTempFn) *fn.math.erf((depthFn)/w) + ndp.TSP\n",
    "delX = fn.misc.min(fn.math.abs(coordinate[0] - - 1.) , fn.math.abs(coordinate[0] - 1.))\n",
    "tempSlab = (potTempFn ) *fn.math.erf((delX*2.)/w0) + ndp.TSP       \n",
    "tempFn1 =  fn.misc.min(tempBL, tempSlab)\n",
    "blFn = fn.branching.conditional([(depthFn < iD, tempFn1), \n",
    "                                    (True, potTempFn)])\n",
    "\n",
    "tempFn = 0.*sinFn + 1.*blFn #partition the temp between these the symmetric downwelling and sinusoid\n",
    "if symmetric_IC:  \n",
    "    if not checkpointLoad:\n",
    "        temperatureField.data[:] = tempFn.evaluate(mesh)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Thermal initial condition 2: \n",
    "#if symmetric_IC == False, we build an asymmetric subduction-zone\n",
    "###########\n",
    "\n",
    "#Main control paramters are:\n",
    "\n",
    "Roc = 550e3 #radius of curvature of slab\n",
    "theta = 89. #Angle to truncate the slab (can also do with with a cutoff depth)\n",
    "subzone = 0.0 #X position of subduction zone...in model coordinates\n",
    "slabmaxAge = 160e6 #age of subduction plate at trench\n",
    "sense = 'Right' #dip direction\n",
    "op_age_fac = 1. #this controls the overidding plate speed, hence age reduction\n",
    "\n",
    "\n",
    "#First build the top TBL\n",
    "\n",
    "dl =  2*math.sqrt(dp.k*slabmaxAge*3600*24*365) #diffusion Length at ... My\n",
    "w0 = dl/dp.LS\n",
    "ageFn1 = (fn.math.abs(fn.math.abs(coordinate[0]) - 2.)/2.)\n",
    "ageFn  = fn.branching.conditional([(coordinate[0] <= 0, ageFn1),\n",
    "                                  (True, ageFn1/op_age_fac)])\n",
    "w = w0*fn.math.sqrt(ageFn + 1e-7)\n",
    "tempBL = (potTempFn) *fn.math.erf((depthFn)/w) + ndp.TSP\n",
    "if not symmetric_IC:\n",
    "    if not checkpointLoad:\n",
    "        out = uw.utils.MeshVariable_Projection( temperatureField, tempBL) #apply function with projection\n",
    "        out.solve()\n",
    "\n",
    "        \n",
    "        \n",
    "#Now build the perturbation part\n",
    "\n",
    "def inCircleFnGenerator(centre, radius):\n",
    "    coord = fn.input()\n",
    "    offsetFn = coord - centre\n",
    "    return fn.math.dot( offsetFn, offsetFn ) < radius**2\n",
    "\n",
    "#Setup slab perturbation params (mostly dimensionlesl / model params here)\n",
    "phi = 90. - theta\n",
    "RocM = (Roc/dp.LS)\n",
    "CrustM = MANTLETOCRUST\n",
    "Org = (subzone, 1.-RocM)\n",
    "\n",
    "#Use three circles to define our slab and crust perturbation,  \n",
    "Oc = inCircleFnGenerator(Org , RocM)\n",
    "Ic = inCircleFnGenerator(Org , RocM - w0)\n",
    "Cc = inCircleFnGenerator(Org , RocM - (2.*CrustM)) #Twice as wide as ordinary crust, weak zone on 'outside' of slab\n",
    "dx = (RocM)/(np.math.tan((np.math.pi/180.)*phi))\n",
    "\n",
    "\n",
    "#We'll also create a triangle which will truncate the circles defining the slab...\n",
    "if sense == 'Left': \n",
    "    ptx = subzone - dx\n",
    "else:\n",
    "    ptx = subzone + dx\n",
    "coords = ((0.+subzone, 1), (0.+subzone, 1.-RocM), (ptx, 1.))\n",
    "Tri = fn.shape.Polygon(np.array(coords))\n",
    "\n",
    "#Actually apply the perturbation\n",
    "if not symmetric_IC:\n",
    "    if not checkpointLoad:\n",
    "        sdFn = ((RocM - fn.math.sqrt((coordinate[0] - Org[0])**2. + (coordinate[1] - Org[1])**2.))) \n",
    "        slabFn = ndp.TPP*fn.math.erf((sdFn)/w0)\n",
    "\n",
    "        for index, coord in enumerate(mesh.data):\n",
    "            #if Oc.evaluate(tuple(coord)) and Tri.evaluate(tuple(coord)) and not Ic.evaluate(tuple(coord)): #in inner circle, not in outer circle\n",
    "            if (\n",
    "                Oc.evaluate(tuple(coord)) and\n",
    "                Tri.evaluate(tuple(coord)) and not\n",
    "                Ic.evaluate(tuple(coord)) and\n",
    "                coord[1] > (1. - (250.e3/dp.LS)) \n",
    "                ): #In the quarter-circle defining the lithosphere\n",
    "                temperatureField.data[index] = slabFn.evaluate(mesh)[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make sure material in sticky air region is at the surface temperature.\n",
    "for index, coord in enumerate(mesh.data):\n",
    "            if coord[1] >= 1.:\n",
    "                temperatureField.data[index] = ndp.TSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig= glucifer.Figure()\n",
    "fig.append( glucifer.objects.Surface(mesh, temperatureField))\n",
    "\n",
    "#fig.append(glucifer.objects.Mesh(mesh))\n",
    "#fig.save_database('test.gldb')\n",
    "\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boundary conditions\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "for index in mesh.specialSets[\"MinJ_VertexSet\"]:\n",
    "    temperatureField.data[index] = ndp.TBP\n",
    "for index in mesh.specialSets[\"MaxJ_VertexSet\"]:\n",
    "    temperatureField.data[index] = ndp.TSP\n",
    "    \n",
    "iWalls = mesh.specialSets[\"MinI_VertexSet\"] + mesh.specialSets[\"MaxI_VertexSet\"]\n",
    "jWalls = mesh.specialSets[\"MinJ_VertexSet\"] + mesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "tWalls = mesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "bWalls =mesh.specialSets[\"MinJ_VertexSet\"]\n",
    "\n",
    "VelBCs = mesh.specialSets[\"Empty\"]\n",
    "\n",
    "if VelBC:\n",
    "    for index in list(tWalls.data):\n",
    "        if (mesh.data[int(index)][0] < (subzone - 0.2) and mesh.data[int(index)][0] > -2 + 0.2): #Only push with a portion of teh overiding plate\n",
    "            VelBCs.add(int(index))\n",
    "            #Set the plate velocities for the kinematic phase\n",
    "            velocityField.data[index] = [ndp.plate_vel, 0.]\n",
    "        \n",
    "\n",
    "#If periodic, we'll fix a the x-vel at a single node - at the bottom left (index 0)\n",
    "Fixed = mesh.specialSets[\"Empty\"]\n",
    "Fixed.add(int(0))        \n",
    "        \n",
    "\n",
    "if periodic[0] == False:\n",
    "    if VelBC:\n",
    "        print(1)\n",
    "        freeslipBC = uw.conditions.DirichletCondition( variable      = velocityField, \n",
    "                                               indexSetsPerDof = ( iWalls + VelBCs, jWalls) )\n",
    "    else:\n",
    "        print(2)\n",
    "        freeslipBC = uw.conditions.DirichletCondition( variable      = velocityField, \n",
    "                                               indexSetsPerDof = ( iWalls, jWalls) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if periodic[0] == True:\n",
    "    if VelBC:\n",
    "        print(3)\n",
    "        freeslipBC = uw.conditions.DirichletCondition( variable      = velocityField, \n",
    "                                               indexSetsPerDof = ( Fixed + VelBCs , jWalls) )\n",
    "    else:\n",
    "        print(4)\n",
    "        freeslipBC = uw.conditions.DirichletCondition( variable      = velocityField, \n",
    "                                               indexSetsPerDof = ( Fixed, jWalls) )\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "# also set dirichlet for temp field\n",
    "dirichTempBC = uw.conditions.DirichletCondition(     variable=temperatureField, \n",
    "                                              indexSetsPerDof=(tWalls,) )\n",
    "dT_dy = [0.,0.]\n",
    "\n",
    "# also set dirichlet for temp field\n",
    "neumannTempBC = uw.conditions.NeumannCondition( dT_dy, variable=temperatureField, \n",
    "                                         nodeIndexSet=bWalls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5070.202342530959"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#periodic[0]\n",
    "ndp.plate_vel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swarm setup\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Material Swarm and variables\n",
    "###########\n",
    "\n",
    "#create material swarm\n",
    "gSwarm = uw.swarm.Swarm(mesh=mesh, particleEscape=True)\n",
    "\n",
    "#create swarm variables\n",
    "yieldingCheck = gSwarm.add_variable( dataType=\"int\", count=1 )\n",
    "tracerVariable = gSwarm.add_variable( dataType=\"int\", count=1)\n",
    "materialVariable = gSwarm.add_variable( dataType=\"int\", count=1 )\n",
    "ageVariable = gSwarm.add_variable( dataType=\"float\", count=1 )\n",
    "\n",
    "\n",
    "#these lists  are part of the checkpointing implementation\n",
    "varlist = [tracerVariable, tracerVariable, yieldingCheck]\n",
    "varlist = [materialVariable, yieldingCheck, ageVariable]\n",
    "varnames = ['materialVariable', 'yieldingCheck', 'ageVariable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mantleIndex = 0\n",
    "crustIndex = 1\n",
    "harzIndex = 2\n",
    "airIndex = 3\n",
    "\n",
    "\n",
    "\n",
    "if checkpointLoad:\n",
    "    checkpointLoadDir = natsort.natsort(checkdirs)[-1]\n",
    "    temperatureField.load(os.path.join(checkpointLoadDir, \"temperatureField\" + \".hdf5\"))\n",
    "    pressureField.load(os.path.join(checkpointLoadDir, \"pressureField\" + \".hdf5\"))\n",
    "    velocityField.load(os.path.join(checkpointLoadDir, \"velocityField\" + \".hdf5\"))\n",
    "    gSwarm.load(os.path.join(checkpointLoadDir, \"swarm\" + \".h5\"))\n",
    "    for ix in range(len(varlist)):\n",
    "        varb = varlist[ix]\n",
    "        varb.load(os.path.join(checkpointLoadDir,varnames[ix] + \".h5\"))\n",
    "\n",
    "else:\n",
    "\n",
    "    # Layouts are used to populate the swarm across the whole domain\n",
    "    layout = uw.swarm.layouts.PerCellRandomLayout(swarm=gSwarm, particlesPerCell=ppc)\n",
    "    gSwarm.populate_using_layout( layout=layout ) # Now use it to populate.\n",
    "    # Swarm variables\n",
    "    materialVariable.data[:] = mantleIndex\n",
    "    tracerVariable.data[:] = 1\n",
    "    yieldingCheck.data[:] = 0\n",
    "    ageVariable.data[:] = -1\n",
    "\n",
    "    #Set initial air and crust materials (allow the graph to take care of lithsophere)\n",
    "    #########\n",
    "    #This initial material setup will be model dependent\n",
    "    #########\n",
    "    for particleID in range(gSwarm.particleCoordinates.data.shape[0]):\n",
    "        if (1. - gSwarm.particleCoordinates.data[particleID][1]) < MANTLETOCRUST:\n",
    "                 materialVariable.data[particleID] = crustIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#This block sets up a checkboard layout of passive tracers\n",
    "###########\n",
    "\n",
    "square_size = 0.1\n",
    "xlist = np.arange(mesh.minCoord[0] + square_size/2., mesh.maxCoord[0] + square_size/2., square_size)\n",
    "xlist = zip(xlist[:], xlist[1:])[::2]\n",
    "ylist = np.arange(mesh.minCoord[1] + square_size/2., mesh.maxCoord[1] + square_size/2., square_size)\n",
    "ylist = zip(ylist[:], ylist[1:])[::2]\n",
    "xops = []\n",
    "for vals in xlist:\n",
    "    xops.append( (operator.and_(   operator.gt(coordinate[0],vals[0]),   operator.lt(coordinate[0],vals[1])  ),0.) )\n",
    "xops.append((True,1.))\n",
    "\n",
    "testfunc = fn.branching.conditional(xops) \n",
    "\n",
    "yops = []\n",
    "for vals in ylist:\n",
    "    yops.append( (operator.and_(   operator.gt(coordinate[1],vals[0]),   operator.lt(coordinate[1],vals[1])  ),0.) )\n",
    "yops.append((True,testfunc))\n",
    "\n",
    "testfunc2 = fn.branching.conditional(yops) \n",
    "tracerVariable.data[:] = testfunc.evaluate(gSwarm)\n",
    "tracerVariable.data[:] = testfunc2.evaluate(gSwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   1.99999995e-05], dtype=float32)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set the inital particle age, for particles above the critical depth \n",
    "#(only these will be transformed to crust / harzburgite)\n",
    "\n",
    "ageVariable.data[:] = 0. #start with all zeor\n",
    "crustageCond = 1e-05 #set inital age above critical depth. (about 1.2 Ma.) Might have to be shorter than this - need to experiment\n",
    "ageDT = crustageCond + 1e-5 #initalize ages\n",
    "ageConditions = [ (depthFn < 100e3/dp.LS , ageDT),  \n",
    "                  (True, 0.) ]\n",
    "                 \n",
    "\n",
    "ageEval = fn.branching.conditional( ageConditions ).evaluate(gSwarm)\n",
    "ageVariable.data[np.where(ageEval == 0)] = 0 #If below the critical depth, age is set to zero\n",
    "ageVariable.data[np.where(ageEval != 0)] += ageDT #If age above critical depth, increment age\n",
    "\n",
    "np.unique(ageVariable.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Swarm control (material graph)\n",
    "-----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#Here we set up a directed graph object that we we use to control the transformation from one material type to another\n",
    "##############\n",
    "\n",
    "#All depth conditions are given as (km/D) where D is the length scale,\n",
    "#note that 'model depths' are used, e.g. 1-z, where z is the vertical Underworld coordinate\n",
    "#All temp conditions are in dimensionless temp. [0. - 1.]\n",
    "\n",
    "#This is a quick fix for a bug that arises in parallel runs\n",
    "material_list = [0,1,2,3]\n",
    "\n",
    "if not checkpointLoad:\n",
    "    materialVariable.data[:] = 0 #Initialize to zero \n",
    "\n",
    "#Setup the graph object\n",
    "DG = material_graph.MatGraph()\n",
    "\n",
    "#Important: First thing to do is to add all the material types to the graph (i.e add nodes)\n",
    "DG.add_nodes_from(material_list)\n",
    "\n",
    "#Now set the conditions for transformations\n",
    "\n",
    "#... to mantle\n",
    "DG.add_transition((crustIndex,mantleIndex), depthFn, operator.gt, CRUSTTOMANTLE)\n",
    "DG.add_transition((harzIndex,mantleIndex), depthFn, operator.gt, CRUSTTOMANTLE)\n",
    "#DG.add_transition((airIndex,mantleIndex), depthFn, operator.gt, TOPOHEIGHT)\n",
    "\n",
    "#... to crust\n",
    "DG.add_transition((mantleIndex,crustIndex), depthFn, operator.lt, MANTLETOCRUST)\n",
    "DG.add_transition((mantleIndex,crustIndex), xFn, operator.lt, 0.) #No crust on the upper plate\n",
    "DG.add_transition((mantleIndex,crustIndex), ageVariable, operator.gt, crustageCond)\n",
    "\n",
    "DG.add_transition((harzIndex,crustIndex), depthFn, operator.lt, MANTLETOCRUST)\n",
    "DG.add_transition((harzIndex,crustIndex), xFn, operator.lt, 0.) #This one sets no crust on the upper plate\n",
    "DG.add_transition((harzIndex,crustIndex), ageVariable, operator.gt, crustageCond)\n",
    "\n",
    "#... to Harzbugite\n",
    "DG.add_transition((mantleIndex,harzIndex), depthFn, operator.lt, HARZBURGDEPTH)\n",
    "DG.add_transition((mantleIndex,harzIndex), depthFn, operator.gt, MANTLETOCRUST)\n",
    "DG.add_transition((mantleIndex,harzIndex), ageVariable, operator.gt, crustageCond) #Note we can mix functions and swarm variabls\n",
    "\n",
    "#... to air\n",
    "#DG.add_transition((mantleIndex,airIndex), depthFn, operator.lt,0. - TOPOHEIGHT)\n",
    "#DG.add_transition((crustIndex,airIndex), depthFn, operator.lt, 0. - TOPOHEIGHT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1, 0.02285)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CRUSTTOMANTLE, HARZBURGDEPTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#For the slab_IC, we'll also add a crustal weak zone following the dipping perturbation\n",
    "##############\n",
    "\n",
    "if checkpointLoad != True:\n",
    "    if not symmetric_IC:\n",
    "        for particleID in range(gSwarm.particleCoordinates.data.shape[0]):\n",
    "            if (\n",
    "                Oc.evaluate(list(gSwarm.particleCoordinates.data[particleID])) and\n",
    "                Tri.evaluate(list(gSwarm.particleCoordinates.data[particleID])) and\n",
    "                Cc.evaluate(list(gSwarm.particleCoordinates.data[particleID])) == False\n",
    "                ):\n",
    "                materialVariable.data[particleID] = crustIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#This is how we use the material graph object to test / apply material transformations\n",
    "##############\n",
    "DG.build_condition_list(materialVariable)\n",
    "for i in range(3): #Need to go through a number of times\n",
    "    materialVariable.data[:] = fn.branching.conditional(DG.condition_list).evaluate(gSwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#DG.build_condition_list(materialVariable)\n",
    "#materialVariable.data[:] = fn.branching.conditional(DG.condition_list).evaluate(gSwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rheology\n",
    "-----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The yeilding of the upper slab is dependent on the strain rate.\n",
    "strainRate_2ndInvariant = fn.tensor.second_invariant( \n",
    "                            fn.tensor.symmetric( \n",
    "                            velocityField.fn_gradient ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ViscReduce = 0.1\n",
    "\n",
    "#ndp.Wds *= ViscReduce\n",
    "#ndp.Wdf *= ViscReduce\n",
    "#ndp.Eds *= ViscReduce\n",
    "#ndp.Edf *= ViscReduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndp.Wds, ndp.Wdf, ndp.Eds, ndp.Edf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############\n",
    "#Rheology\n",
    "#############\n",
    "#\n",
    "#The final mantle rheology is composed as follows*:\n",
    "# \n",
    "#\n",
    "# mantleviscosityFn = max{  min{(1/omega*Visc + 1/eta_p)**-1,\n",
    "#                           eta_max},\n",
    "#                           eta_min}\n",
    "#                      \n",
    "#Visc => min{diffusionCreep, dislocationCreep, }\n",
    "#eta_p   => stress-limiting effective viscosity\n",
    "#\n",
    "\n",
    "omega = fn.misc.constant(1.)\n",
    "\n",
    "if melt_viscosity_reduction:\n",
    "    mvr =  fn.branching.conditional( [ (temperatureField > (ndp.Tmvp + 7.5*(1. - coordinate[1])) , 0.1 ),   (         True, 1.) ] )\n",
    "    omega = omega*mvr\n",
    "\n",
    "\n",
    "#implementation of the lower mantle viscosity increase, similar to Bello et al. 2015\n",
    "a = 1.\n",
    "B = 30.\n",
    "d0 = 660e3/dp.LS  \n",
    "ds = d0/10.\n",
    "if lower_mantle:\n",
    "    inner1 = 1. - 0.5*(1. - fn.math.tanh(((1. - d0)-(coordinate[1]))/(ds)))\n",
    "    modfac = a*fn.math.exp(np.log(B)*inner1)\n",
    "    omega = omega*modfac\n",
    "\n",
    "\n",
    "##Diffusion Creep\n",
    "ndfp = fn.misc.min(ndp.eta_max, fn.math.exp( ((ndp.Edf + (depthFn*ndp.Wdf))/((temperatureField + ndp.TS))) - \n",
    "              ((ndp.Edf + (ndp.Dr*ndp.Wdf))/((ndp.TPP + ndp.TS)))  ))\n",
    "\n",
    "linearVisc = fn.misc.min(ndp.eta_max, ndfp)\n",
    "\n",
    "##Dislocation Creep\n",
    "nl_correction = (strainRate_2ndInvariant/ndp.SR)**((1.-ndp.n)/(ndp.n))\n",
    "\n",
    "\n",
    "ndsp = fn.misc.min(ndp.eta_max,(nl_correction)*fn.math.exp( ((ndp.Eds + (depthFn*ndp.Wds))/(ndp.n*(temperatureField + ndp.TS))) -\n",
    "                                     ((ndp.Eds + (ndp.Dr*ndp.Wds))/(ndp.n*(ndp.TPP + ndp.TS)))))\n",
    "\n",
    "\n",
    "##Combine the creep mechanisms\n",
    "Visc = fn.misc.max(fn.misc.min(ndp.eta_max, fn.misc.min(ndfp, ndsp)), ndp.eta_min)\n",
    "\n",
    "##Define the Plasticity\n",
    "ys =  ndp.cohesion + (depthFn*ndp.fcd) #In this case we'll use a valid cohesion\n",
    "yielding = ys/(strainRate_2ndInvariant/math.sqrt(0.5)) #extra factor to account for underworld second invariant form\n",
    "\n",
    "\n",
    "#Combine the viscous creep and plasticity\n",
    "#mantleviscosityFn = fn.misc.max(fn.misc.min(1./(((1./Visc) + (1./yielding))), ndp.eta_max), ndp.eta_min)\n",
    "mantleviscosityFn = fn.misc.max(fn.misc.min(fn.misc.min(Visc, yielding), ndp.eta_max), ndp.eta_min)\n",
    "\n",
    "\n",
    "#fn.misc.min(Visc, yielding)\n",
    "\n",
    "#lower mantle rheology\n",
    "\n",
    "#ndflm = fn.misc.min(ndp.eta_max, fn.math.exp( ((ndp.Elm + (depthFn*ndp.Wlm))/((temperatureField + ndp.TS))) - \n",
    "#              ((ndp.Elm + (ndp.Dr*ndp.Wlm))/((ndp.TPP + ndp.TS)))  ))\n",
    "\n",
    "#I ignored Cizkova's lower mantle diffusion creep parameters, \n",
    "#as they appeared to give lower values that the upper mantle rheology, i.e a visc. decrease at 660.\n",
    "#lm_increase = 1.\n",
    "#lowermantleviscosityFn = fn.misc.max(lm_increase*ndfp, ndp.eta_min)\n",
    "\n",
    "\n",
    "##Crust rheology\n",
    "#reduceFac = 0.1\n",
    "#ysc =  reduceFac*ndp.cohesion + reduceFac*(depthFn*gamma*ndp.RA) #In this case we'll use a valid cohesion\n",
    "#crust_yielding = ysc/(strainRate_2ndInvariant/math.sqrt(0.5)) #extra factor to account for underworld second invariant form\n",
    "#crustviscosityFn = fn.misc.max(fn.misc.min(1./(((1./Visc) + (1./crust_yielding))), ndp.eta_max), ndp.eta_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############\n",
    "#Build a weak zone\n",
    "#############\n",
    "#\n",
    "\n",
    "def disGen(centre):\n",
    "    coord = fn.input()\n",
    "    offsetFn = coord - centre\n",
    "    return fn.math.sqrt(fn.math.dot( offsetFn, offsetFn ))\n",
    "\n",
    "depth = 200.e3 #m\n",
    "angle = 20. #degrees\n",
    "num_circles = 50\n",
    "half_width = 5e3 #m\n",
    "\n",
    "\n",
    "xpos = depth/math.tan((angle*math.pi/180.))\n",
    "start = (0.075, 1.)\n",
    "end = (start[0] +xpos/dp.LS , start[1] - depth/dp.LS)\n",
    "xar = np.linspace(start[0], end[0], num_circles)\n",
    "yar = np.linspace(start[1], end[1], num_circles)\n",
    "fnBuilder = fn.misc.constant(1000.)\n",
    "for i in range(num_circles):\n",
    "    circ_dist = disGen((xar[i], yar[i]))\n",
    "    fnBuilder = fn.misc.min(circ_dist, fnBuilder)\n",
    "    \n",
    "sig = half_width/dp.LS\n",
    "gammaFn =  fn.math.exp(-fn.math.pow(fnBuilder, 2.) / (2. * fn.math.pow(sig, 2.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testFn = disGen((0., 1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weakzoneFn = fn.misc.min((10./gammaFn*1.),ndp.eta_max)\n",
    "combmantleviscosityFn = fn.misc.max(ndp.eta_min, fn.misc.min(mantleviscosityFn, weakzoneFn))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig= glucifer.Figure()\n",
    "#fig.append( glucifer.objects.Points(gSwarm,tracerVariable, colours= 'white black'))\n",
    "fig.append( glucifer.objects.Points(gSwarm,materialVariable))\n",
    "#fig.append( glucifer.objects.Surface(mesh, combmantleviscosityFn, logScale=True))\n",
    "#fig.append( glucifer.objects.VectorArrows(mesh, testFn))\n",
    "fig.show()\n",
    "fig.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#velocityField.data.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import matplotlib.pylab as pyplt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "##################\n",
    "#Output functions to numpy vertical averages, maxes, mins\n",
    "##################\n",
    "\n",
    "viscmapFnmesh = uw.mesh.MeshVariable(mesh,nodeDofCount=1)\n",
    "out = uw.utils.MeshVariable_Projection( viscmapFnmesh, viscosityMapFn)\n",
    "out.solve()\n",
    "\n",
    "\n",
    "#avDf = ndfp.evaluate(mesh).reshape(mesh.elementRes[1] + 1, mesh.elementRes[0] + 1).mean(axis=1)\n",
    "avDs = ndsp.evaluate(mesh).reshape(mesh.elementRes[1] + 1, mesh.elementRes[0] + 1).mean(axis=1)\n",
    "umantle = mantleviscosityFn.evaluate(mesh).reshape(mesh.elementRes[1] + 1, mesh.elementRes[0] + 1).mean(axis=1)\n",
    "lmantle = lowermantleviscosityFn.evaluate(mesh).reshape(mesh.elementRes[1] + 1, mesh.elementRes[0] + 1).mean(axis=1)\n",
    "eff = viscmapFnmesh.evaluate(mesh).reshape(mesh.elementRes[1] + 1, mesh.elementRes[0] + 1).mean(axis=1)\n",
    "\n",
    "effMin = viscmapFnmesh.evaluate(mesh).reshape(mesh.elementRes[1] + 1, mesh.elementRes[0] + 1).min(axis=1)\n",
    "effMax = viscmapFnmesh.evaluate(mesh).reshape(mesh.elementRes[1] + 1, mesh.elementRes[0] + 1).max(axis=1)\n",
    "\n",
    "###################\n",
    "#Plot\n",
    "###################\n",
    "import matplotlib.pylab as pyplt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = pyplt.subplots()\n",
    "#ax .plot(avDf, label = 'diff')\n",
    "#ax .plot(avDs, label = 'dis')\n",
    "ax .plot(eff, label = 'eff')\n",
    "ax .plot(effMax, label = 'effMax')\n",
    "ax .plot(effMin, label = 'effMin')\n",
    "#ax .plot(umantle, label = 'uman')\n",
    "#ax .plot(lmantle, label = 'lman')\n",
    "ax.set_yscale(\"log\", nonposy='clip')\n",
    "ax.legend(loc = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig= glucifer.Figure()\n",
    "#fig.append( glucifer.objects.Points(gSwarm,materialVariable))\n",
    "#fig.append( glucifer.objects.Points(gSwarm,viscosityMapFn, logScale=True))\n",
    "#fig.append( glucifer.objects.Surface(mesh, ndfp, logScale=True))\n",
    "\n",
    "fig.append( glucifer.objects.Surface(mesh,mantleviscosityFn, logScale=True))\n",
    "fig.show()\n",
    "#fig.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndsp.evaluate(mesh).min(), ndfp.evaluate(mesh).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fig= glucifer.Figure()\n",
    "#fig.append( glucifer.objects.Points(gSwarm,tracerVariable, colours= 'white black'))\n",
    "#fig.append( glucifer.objects.Points(gSwarm,materialVariable))\n",
    "#fig.append( glucifer.objects.Surface(mesh, ndfp/ndsp , logScale=True))\n",
    "\n",
    "#fig.append( glucifer.objects.Surface(mesh, strainRate_2ndInvariant/ndp.SR))\n",
    "#fig.show()\n",
    "#fig.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stokes system setup\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this accounts for the decreas in expansivity\n",
    "alphaRatio = 1.2/3\n",
    "taFn = 1. - (1. - depthFn)*(1. - alphaRatio) \n",
    "raylieghFn = ndp.RA*temperatureField*taFn \n",
    "\n",
    "\n",
    "if WeakZone:\n",
    "    print(1)\n",
    "    viscosityMapFn = fn.branching.map( fn_key = materialVariable,\n",
    "                         mapping = {crustIndex:combmantleviscosityFn,\n",
    "                                    mantleIndex:combmantleviscosityFn,\n",
    "                                    harzIndex:combmantleviscosityFn} )\n",
    "else: #Use weak crust\n",
    "    print(2)\n",
    "    viscosityMapFn = fn.branching.map( fn_key = materialVariable,\n",
    "                         mapping = {crustIndex:ndp.eta_crust,\n",
    "                                    mantleIndex:mantleviscosityFn,\n",
    "                                    harzIndex:mantleviscosityFn} )\n",
    "\n",
    "densityMapFn = fn.branching.map( fn_key = materialVariable,\n",
    "                         mapping = {airIndex:ndp.StRA,\n",
    "                                    crustIndex:raylieghFn, \n",
    "                                    mantleIndex:raylieghFn,\n",
    "                                    harzIndex:raylieghFn} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define our vertical unit vector using a python tuple (this will be automatically converted to a function).\n",
    "gravity = ( 0.0, 1.0 )\n",
    "\n",
    "# Now create a buoyancy force vector using the density and the vertical unit vector. \n",
    "buoyancyFn = densityMapFn * gravity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stokesPIC = uw.systems.Stokes(velocityField=velocityField, \n",
    "                              pressureField=pressureField,\n",
    "                              conditions=[freeslipBC,],\n",
    "                              fn_viscosity=linearVisc, \n",
    "                              fn_bodyforce=buoyancyFn )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solver = uw.systems.Solver(stokesPIC)\n",
    "if not checkpointLoad:\n",
    "    solver.solve() #A solve on the linear visocisty is unhelpful unless we're starting from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add the non-linear viscosity to the Stokes system\n",
    "stokesPIC.fn_viscosity = viscosityMapFn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solver.set_inner_method(\"mumps\")\n",
    "solver.options.scr.ksp_type=\"cg\"\n",
    "solver.set_penalty(1.0e7)\n",
    "solver.options.scr.ksp_rtol = 1.0e-4\n",
    "solver.solve(nonLinearIterate=True)\n",
    "solver.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check which particles are yielding\n",
    "#yieldingCheck.data[:] = 0\n",
    "\n",
    "#yieldconditions = [ ( mantleviscosityFn < Visc , 1), \n",
    "#               ( True                                           , 0) ]\n",
    "\n",
    "# use the branching conditional function to set each particle's index\n",
    "#yieldingCheck.data[:] = fn.branching.conditional( yieldconditions ).evaluate(gSwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fig= glucifer.Figure()\n",
    "#fig.append( glucifer.objects.Points(gSwarm,yieldingCheck))\n",
    "\n",
    "#fig.append( glucifer.objects.Surface(mesh,ndflm, logScale=True))\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advection-diffusion System setup\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "advDiff = uw.systems.AdvectionDiffusion( phiField       = temperatureField, \n",
    "                                         phiDotField    = temperatureDotField, \n",
    "                                         velocityField  = velocityField,\n",
    "                                         fn_sourceTerm    = 0.0,\n",
    "                                         fn_diffusivity = 1.0, \n",
    "                                         #conditions     = [neumannTempBC, dirichTempBC] )\n",
    "                                         conditions     = [ dirichTempBC] )\n",
    "\n",
    "passiveadvector = uw.systems.SwarmAdvector( swarm         = gSwarm, \n",
    "                                     velocityField = velocityField, \n",
    "                                     order         = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "population_control = uw.swarm.PopulationControl(gSwarm,deleteThreshold=0.2,splitThreshold=1.,maxDeletions=3,maxSplits=0, aggressive=True, particlesPerCell=ppc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis functions / routines\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#These are functions we can use to evuate integrals over restricted parts of the domain\n",
    "# For instance, we can exclude the thermal lithosphere from integrals\n",
    "\n",
    "def temprestrictionFn(lithval = 0.9):\n",
    "\n",
    "    tempMM = fn.view.min_max(temperatureField)\n",
    "    tempMM.evaluate(mesh)\n",
    "    TMAX = tempMM.max_global()\n",
    "    mantleconditions = [ (                                  temperatureField > lithval*TMAX, 1.),\n",
    "                   (                                                   True , 0.) ]\n",
    "\n",
    "\n",
    "    return fn.branching.conditional(mantleconditions)\n",
    "\n",
    "mantlerestrictFn = temprestrictionFn(lithval = 0.85)\n",
    "\n",
    "\n",
    "\n",
    "def platenessFn(val = 0.1):\n",
    "    normgradV = fn.math.abs(velocityField.fn_gradient[0]/fn.math.sqrt(velocityField[0]*velocityField[0])) #[du*/dx]/sqrt(u*u)\n",
    "\n",
    "\n",
    "\n",
    "    srconditions = [ (                                  normgradV < val, 1.),\n",
    "                   (                                                   True , 0.) ]\n",
    "\n",
    "\n",
    "    return fn.branching.conditional(srconditions)\n",
    "\n",
    "srrestrictFn = platenessFn(val = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setup volume integrals \n",
    "\n",
    "tempint = uw.utils.Integral( temperatureField, mesh )\n",
    "areaint = uw.utils.Integral( 1.,               mesh )\n",
    "\n",
    "v2int   = uw.utils.Integral( fn.math.dot(velocityField,velocityField), mesh )\n",
    "\n",
    "dwint   = uw.utils.Integral( temperatureField*velocityField[1], mesh )\n",
    "\n",
    "sinner = fn.math.dot( strainRate_2ndInvariant, strainRate_2ndInvariant )\n",
    "vdint = uw.utils.Integral( (2.*viscosityMapFn*sinner), mesh ) #Is it two or four here?\n",
    "\n",
    "mantleArea   = uw.utils.Integral( mantlerestrictFn, mesh )\n",
    "mantleTemp = uw.utils.Integral( temperatureField*mantlerestrictFn, mesh )\n",
    "mantleVisc = uw.utils.Integral( mantleviscosityFn*mantlerestrictFn, mesh )\n",
    "mantleVd = uw.utils.Integral( (2.*viscosityMapFn*sinner*mantlerestrictFn), mesh ) #these now work on MappingFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setup surface integrals\n",
    "\n",
    "rmsSurfInt = uw.utils.Integral( fn=velocityField[0]*velocityField[0], mesh=mesh, integrationType='Surface', \n",
    "                          surfaceIndexSet=mesh.specialSets[\"MaxJ_VertexSet\"])\n",
    "nuTop      = uw.utils.Integral( fn=temperatureField.fn_gradient[1],    mesh=mesh, integrationType='Surface', \n",
    "                          surfaceIndexSet=mesh.specialSets[\"MaxJ_VertexSet\"])\n",
    "nuBottom   = uw.utils.Integral( fn=temperatureField.fn_gradient[1],    mesh=mesh, integrationType='Surface', \n",
    "                          surfaceIndexSet=mesh.specialSets[\"MinJ_VertexSet\"])\n",
    "\n",
    "plateint  = uw.utils.Integral( fn=srrestrictFn, mesh=mesh, integrationType='Surface', #Integrate the plateness function\n",
    "                          surfaceIndexSet=mesh.specialSets[\"MaxJ_VertexSet\"]) \n",
    "\n",
    "surfint  = uw.utils.Integral( fn=1., mesh=mesh, integrationType='Surface',   #Surface length function (i.e. domain width)\n",
    "                          surfaceIndexSet=mesh.specialSets[\"MaxJ_VertexSet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define functions for the evaluation of integrals\n",
    "\n",
    "def basic_int(ourIntegral):           #This one just hands back the evaluated integral\n",
    "    return ourIntegral.evaluate()[0]\n",
    "\n",
    "def avg_temp():\n",
    "    return tempint.evaluate()[0]/areaint.evaluate()[0]\n",
    "\n",
    "def nusseltTB(temp_field, mesh):\n",
    "    return -nuTop.evaluate()[0], -nuBottom.evaluate()[0]\n",
    "\n",
    "def rms():\n",
    "    return math.sqrt(v2int.evaluate()[0]/areaint.evaluate()[0])\n",
    "\n",
    "def rms_surf():\n",
    "    return math.sqrt(rmsSurfInt.evaluate()[0])\n",
    "\n",
    "def max_vx_surf(velfield, mesh):\n",
    "    vuvelxfn = fn.view.min_max(velfield[0])\n",
    "    vuvelxfn.evaluate(mesh.specialSets[\"MaxJ_VertexSet\"])\n",
    "    return vuvelxfn.max_global()\n",
    "\n",
    "\n",
    "def visc_extr(viscfn):\n",
    "    vuviscfn = fn.view.min_max(viscfn)\n",
    "    vuviscfn.evaluate(mesh)\n",
    "    return vuviscfn.max_global(), vuviscfn.min_global()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#v2sum_integral  = uw.utils.Integral( mesh=mesh, fn=fn.math.dot( velocityField, velocityField ) )\n",
    "#volume_integral = uw.utils.Integral( mesh=mesh, fn=1. )\n",
    "#Vrms = math.sqrt( v2sum_integral.evaluate()[0] )/volume_integral.evaluate()[0]\n",
    "\n",
    "\n",
    "\n",
    "#if(uw.rank()==0):\n",
    "#    print('Initial Vrms = {0:.3f}'.format(Vrms))\n",
    "\n",
    "# Check the Metrics\n",
    "\n",
    "#Avg_temp = avg_temp()\n",
    "#Rms = rms()\n",
    "#Rms_surf = rms_surf()\n",
    "#Max_vx_surf = max_vx_surf(velocityField, mesh)\n",
    "#Gravwork = basic_int(dwint)\n",
    "#Viscdis = basic_int(vdint)\n",
    "#nu1, nu0 = nusseltTB(temperatureField, mesh) # return top then bottom\n",
    "#etamax, etamin = visc_extr(mantleviscosityFn)\n",
    "\n",
    "#Area_mantle = basic_int(mantleArea)\n",
    "#Viscmantle = basic_int(mantleVisc)\n",
    "#Tempmantle = basic_int(mantleTemp)\n",
    "#Viscdismantle = basic_int(mantleVd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viz.\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "viscVariable = gSwarm.add_variable( dataType=\"float\", count=1 )\n",
    "viscVariable.data[:] = viscosityMapFn.evaluate(gSwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Pack some stuff into a database as well\n",
    "figDb = glucifer.Figure()\n",
    "#figDb.append( glucifer.objects.Mesh(mesh))\n",
    "figDb.append( glucifer.objects.VectorArrows(mesh,velocityField, scaling=0.0005))\n",
    "#figDb.append( glucifer.objects.Points(gSwarm,tracerVariable, colours= 'white black'))\n",
    "figDb.append( glucifer.objects.Points(gSwarm,materialVariable))\n",
    "\n",
    "figDb.append( glucifer.objects.Points(gSwarm,viscosityMapFn, logScale=True))\n",
    "figDb.append( glucifer.objects.Surface(mesh, strainRate_2ndInvariant, logScale=True))\n",
    "figDb.append( glucifer.objects.Surface(mesh, temperatureField))\n",
    "#figDb.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#Create a numpy array at the surface to get surface information on (using parallel-friendly evaluate_global)\n",
    "##############\n",
    "\n",
    "surface_xs = np.linspace(mesh.minCoord[0], mesh.maxCoord[0], mesh.elementRes[0] + 1)\n",
    "surface_nodes = np.array(zip(surface_xs, np.ones(len(surface_xs)*mesh.maxCoord[1]))) #For evaluation surface velocity\n",
    "normgradV = velocityField.fn_gradient[0]/fn.math.sqrt(velocityField[0]*velocityField[0])\n",
    "\n",
    "tempMM = fn.view.min_max(temperatureField)\n",
    "dummy = tempMM.evaluate(mesh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Miscellania**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#These functions handle checkpointing\n",
    "##############\n",
    "\n",
    "\n",
    "def checkpoint1(step, checkpointPath,filename, filewrites):\n",
    "    path = checkpointPath + str(step) \n",
    "    os.mkdir(path)\n",
    "    ##Write and save the file, if not already a writing step\n",
    "    if not step % filewrites == 0:\n",
    "        filename.write((17*'%-15s ' + '\\n') % (realtime, Viscdis, float(nu0), float(nu1), Avg_temp,\n",
    "                                              Tempmantle,TMAX,\n",
    "                                              Rms,Rms_surf,Max_vx_surf,Gravwork, etamax, etamin, \n",
    "                                              Area_mantle, Viscmantle,  Viscdismantle,Plateness ))\n",
    "    filename.close()\n",
    "    shutil.copyfile(os.path.join(outputPath, outputFile), os.path.join(path, outputFile))\n",
    "\n",
    "\n",
    "def checkpoint2(step, checkpointPath, swarm, filename, varlist = [materialVariable], varnames = ['materialVariable']):\n",
    "    path = checkpointPath + str(step) \n",
    "    velfile = \"velocityField\" + \".hdf5\"\n",
    "    tempfile = \"temperatureField\" + \".hdf5\"\n",
    "    pressfile = \"pressureField\" + \".hdf5\"\n",
    "    velocityField.save(os.path.join(path, velfile))\n",
    "    temperatureField.save(os.path.join(path, tempfile))\n",
    "    pressureField.save(os.path.join(path, pressfile))\n",
    "    swarm.save(os.path.join(path, \"swarm.h5\") ) \n",
    "    for ix in range(len(varlist)):\n",
    "        varb = varlist[ix]\n",
    "        varb.save(os.path.join(path,varnames[ix] + \".h5\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#This will allow us to evaluate viscous shear heating, and add the result directly to the temperature field\n",
    "##############\n",
    "\n",
    "viscDisMapFn = 2.*viscosityMapFn*sinner\n",
    "viscDisFnmesh = uw.mesh.MeshVariable(mesh,nodeDofCount=1)\n",
    "viscDisProj = uw.utils.MeshVariable_Projection( viscDisFnmesh, viscDisMapFn)\n",
    "viscDisProj.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialise timer for computation\n",
    "start = time.clock()\n",
    "# setup summary output file (name above)\n",
    "if checkpointLoad:\n",
    "    if uw.rank() == 0:\n",
    "        shutil.copyfile(os.path.join(checkpointLoadDir, outputFile), outputPath+outputFile)\n",
    "    comm.Barrier()\n",
    "    f_o = open(os.path.join(outputPath, outputFile), 'a')\n",
    "    prevdata = np.genfromtxt(os.path.join(outputPath, outputFile), skip_header=0, skip_footer=0)\n",
    "    if len(prevdata.shape) == 1: #this is in case there is only one line in previous file\n",
    "        realtime = prevdata[0]\n",
    "    else:\n",
    "        realtime = prevdata[prevdata.shape[0]-1, 0]\n",
    "    step = int(checkpointLoadDir.split('/')[-1])\n",
    "    timevals = [0.]\n",
    "else:\n",
    "    f_o = open(outputPath+outputFile, 'w')\n",
    "    realtime = 0.\n",
    "    step = 0\n",
    "    timevals = [0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main simulation loop\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#while step < 21:\n",
    "while realtime < 1.:\n",
    "\n",
    "    # solve Stokes and advection systems\n",
    "    solver.solve(nonLinearIterate=True)\n",
    "    dt = advDiff.get_max_dt()\n",
    "    if step == 0:\n",
    "        dt = 0.\n",
    "    advDiff.integrate(dt)\n",
    "    passiveadvector.integrate(dt)\n",
    "    \n",
    "    #Add the adiabatic adjustment:\n",
    "    temperatureField.data[:] += dt*abHeatFn.evaluate(mesh)\n",
    "    \n",
    "    #Add the viscous heating term\n",
    "    viscDisProj = uw.utils.MeshVariable_Projection( viscDisFnmesh, viscDisMapFn)\n",
    "    viscDisProj.solve()\n",
    "    temperatureField.data[:] += dt*viscDisFnmesh.evaluate(mesh)\n",
    "    \n",
    "\n",
    "    # Increment\n",
    "    realtime += dt\n",
    "    step += 1\n",
    "    timevals.append(realtime)\n",
    "    ################\n",
    "    #Update temperature field in the air region\n",
    "    #Do this better...\n",
    "    ################\n",
    "    if (step % sticky_air_temp == 0):\n",
    "        for index, coord in enumerate(mesh.data):\n",
    "            if coord[1] >= 1.:\n",
    "                temperatureField.data[index] = ndp.TSP\n",
    "\n",
    "    # Calculate the Metrics, only on 1 of the processors:\n",
    "    ################\n",
    "    if (step % metric_output == 0):\n",
    "        ###############\n",
    "        #Swarm - based Metrics\n",
    "        ###############\n",
    "        # Calculate the RMS velocity and Nusselt number.\n",
    "        # Calculate the Metrics, only on 1 of the processors:\n",
    "        mantlerestrictFn = temprestrictionFn() #rebuild the mantle restriction function (but these should be dynamic?)\n",
    "        srrestrictFn = platenessFn(val = 0.1) #rebuild the plateness restriction function\n",
    "        dummy = tempMM.evaluate(mesh) #Re-evaluate any fn.view.min_max guys\n",
    "        #Rebuild these integrals (a test because metrics changes after a restart)\n",
    "        mantleArea   = uw.utils.Integral( mantlerestrictFn, mesh )\n",
    "        mantleTemp = uw.utils.Integral( temperatureField*mantlerestrictFn, mesh )\n",
    "        mantleVisc = uw.utils.Integral( mantleviscosityFn*mantlerestrictFn, mesh )\n",
    "        mantleVd = uw.utils.Integral( (4.*viscosityMapFn*sinner*mantlerestrictFn), mesh ) #these now work on MappingFunctions\n",
    "        ###\n",
    "        Avg_temp = avg_temp()\n",
    "        Rms = rms()\n",
    "        Rms_surf = rms_surf()\n",
    "        Max_vx_surf = max_vx_surf(velocityField, mesh)\n",
    "        Gravwork = basic_int(dwint)\n",
    "        Viscdis = basic_int(vdint)\n",
    "        nu1, nu0 = nusseltTB(temperatureField, mesh) # return top then bottom\n",
    "        etamax, etamin = visc_extr(mantleviscosityFn)\n",
    "        Area_mantle = basic_int(mantleArea)\n",
    "        Viscmantle = basic_int(mantleVisc)\n",
    "        Tempmantle = basic_int(mantleTemp)\n",
    "        Viscdismantle = basic_int(mantleVd)\n",
    "        Plateness = basic_int(plateint)/basic_int(surfint)\n",
    "        TMAX = tempMM.max_global()\n",
    "        # output to summary text file\n",
    "        if uw.rank()==0:\n",
    "            f_o.write((17*'%-15s ' + '\\n') % (realtime, Viscdis, float(nu0), float(nu1), Avg_temp,\n",
    "                                              Tempmantle,TMAX,\n",
    "                                              Rms,Rms_surf,Max_vx_surf,Gravwork, etamax, etamin, \n",
    "                                              Area_mantle, Viscmantle,  Viscdismantle,Plateness ))\n",
    "    ################\n",
    "    #Also repopulate entire swarm periodically\n",
    "    ################\n",
    "    #if step % swarm_repop == 0:\n",
    "    population_control.repopulate()   \n",
    "    ################\n",
    "    #Checkpoint\n",
    "    ################\n",
    "    if step % checkpoint_every == 0:\n",
    "        if uw.rank() == 0:\n",
    "            checkpoint1(step, checkpointPath,f_o, metric_output)           \n",
    "        checkpoint2(step, checkpointPath, gSwarm, f_o, varlist = varlist, varnames = varnames)\n",
    "        f_o = open(os.path.join(outputPath, outputFile), 'a') #is this line supposed to be here?\n",
    "    ################\n",
    "    #Gldb output\n",
    "    ################ \n",
    "    if (step % gldbs_output == 0):\n",
    "        #Rebuild any necessary swarm variables\n",
    "        viscVariable.data[:] = viscosityMapFn.evaluate(gSwarm)\n",
    "        #Write gldbs\n",
    "        fnamedb = \"dbFig\" + \"_\" + str(ModIt) + \"_\" + str(step) + \".gldb\"\n",
    "        fullpath = os.path.join(outputPath + \"gldbs/\" + fnamedb)\n",
    "        #figDb.show()\n",
    "        figDb.save_database(fullpath)\n",
    "    ################\n",
    "    #Files output\n",
    "    ################ \n",
    "    if (step % files_output == 0):\n",
    "\n",
    "        vel_surface = velocityField.evaluate_global(surface_nodes)\n",
    "        norm_surface_sr = normgradV.evaluate_global(surface_nodes)\n",
    "        if uw.rank() == 0:\n",
    "            fnametemp = \"velsurface\" + \"_\" + str(ModIt) + \"_\" + str(step)\n",
    "            fullpath = os.path.join(outputPath + \"files/\" + fnametemp)\n",
    "            np.save(fullpath, vel_surface)\n",
    "            fnametemp = \"norm_surface_sr\" + \"_\" + str(ModIt) + \"_\" + str(step)\n",
    "            fullpath = os.path.join(outputPath + \"files/\" + fnametemp)\n",
    "            np.save(fullpath, norm_surface_sr)\n",
    "    ################\n",
    "    #Particle update\n",
    "    ###############    \n",
    "    #ageVariable.data[:] += dt #increment the ages (is this efficient?)\n",
    "    ageDT += dt\n",
    "    \n",
    "    if step % swarm_update == 0:\n",
    "        #Increment age stuff. \n",
    "        ageEval = fn.branching.conditional( ageConditions ).evaluate(gSwarm)\n",
    "        ageVariable.data[np.where(ageEval == 0)] = 0 #If below the critical depth, age is set to zero\n",
    "        ageVariable.data[np.where(ageEval != 0)] += ageDT #If age above critical depth, increment age\n",
    "        ageDT = 0. #reset the age incrementer\n",
    "        \n",
    "        #Apply any materialVariable changes\n",
    "        for i in range(2): #Need to go through twice first time through\n",
    "            materialVariable.data[:] = fn.branching.conditional(DG.condition_list).evaluate(gSwarm)\n",
    "\n",
    "    \n",
    "f_o.close()\n",
    "print 'step =',step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "viscVariable = gSwarm.add_variable( dataType=\"float\", count=1 )\n",
    "viscVariable.data[:] = viscosityMapFn.evaluate(gSwarm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
