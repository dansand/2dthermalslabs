{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korenaga 2011\n",
    "======\n",
    "\n",
    "Temperature dependent convection\n",
    "----\n",
    "\n",
    "This Notebooks implements the case of two-dimensional, incompressible, internally-heated fmantle convection.\n",
    "\n",
    "\n",
    "**Keywords:** Stokes system, advective diffusive systems, analysis tools, tools for post analysis, rheologies\n",
    "\n",
    "\n",
    "**References**\n",
    "\n",
    "Korenaga, Jun. \"Scaling of plate tectonic convection with pseudoplastic rheology.\" Journal of Geophysical Research: Solid Earth 115.B11 (2010).\n",
    "http://onlinelibrary.wiley.com/doi/10.1029/2010JB007670/full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import underworld as uw\n",
    "import math\n",
    "from underworld import function as fn\n",
    "import glucifer\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import natsort\n",
    "import shutil\n",
    "from easydict import EasyDict as edict\n",
    "import operator\n",
    "import pint\n",
    "import time\n",
    "import operator\n",
    "from slippy2 import boundary_layer2d\n",
    "from slippy2 import material_graph\n",
    "from slippy2 import spmesh\n",
    "\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model name and directories\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############\n",
    "#Model letter and number\n",
    "############\n",
    "\n",
    "\n",
    "#Model letter identifier default\n",
    "Model = \"T\"\n",
    "\n",
    "#Model number identifier default:\n",
    "ModNum = 0\n",
    "\n",
    "#Any isolated letter / integer command line args are interpreted as Model/ModelNum\n",
    "\n",
    "if len(sys.argv) == 1:\n",
    "    ModNum = ModNum \n",
    "elif sys.argv[1] == '-f': #\n",
    "    ModNum = ModNum \n",
    "else:\n",
    "    for farg in sys.argv[1:]:\n",
    "        if not '=' in farg: #then Assume it's a not a paramter argument\n",
    "            try:\n",
    "                ModNum = int(farg) #try to convert everingthing to a float, else remains string\n",
    "            except ValueError:\n",
    "                Model  = farg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Standard output directory setup\n",
    "###########\n",
    "\n",
    "outputPath = \"results\" + \"/\" +  str(Model) + \"/\" + str(ModNum) + \"/\" \n",
    "imagePath = outputPath + 'images/'\n",
    "filePath = outputPath + 'files/'\n",
    "checkpointPath = outputPath + 'checkpoint/'\n",
    "dbPath = outputPath + 'gldbs/'\n",
    "outputFile = 'results_model' + Model + '_' + str(ModNum) + '.dat'\n",
    "\n",
    "if uw.rank()==0:\n",
    "    # make directories if they don't exist\n",
    "    if not os.path.isdir(outputPath):\n",
    "        os.makedirs(outputPath)\n",
    "    if not os.path.isdir(checkpointPath):\n",
    "        os.makedirs(checkpointPath)\n",
    "    if not os.path.isdir(imagePath):\n",
    "        os.makedirs(imagePath)\n",
    "    if not os.path.isdir(dbPath):\n",
    "        os.makedirs(dbPath)\n",
    "    if not os.path.isdir(filePath):\n",
    "        os.makedirs(filePath)\n",
    "\n",
    "        \n",
    "comm.Barrier() #Barrier here so no procs run the check in the next cell too early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/T/0/checkpoint/ is empty\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "#Check if starting from checkpoint\n",
    "###########\n",
    "\n",
    "checkdirs = []\n",
    "for dirpath, dirnames, files in os.walk(checkpointPath):\n",
    "    if files:\n",
    "        print dirpath, 'has files'\n",
    "        checkpointLoad = True\n",
    "        checkdirs.append(dirpath)\n",
    "    if not files:\n",
    "        print dirpath, 'is empty'\n",
    "        checkpointLoad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup summary output file (name above)\n",
    "if checkpointLoad:\n",
    "    checkpointLoadDir = natsort.natsort(checkdirs)[-1]\n",
    "    if uw.rank() == 0:\n",
    "        shutil.copyfile(os.path.join(checkpointLoadDir, outputFile), outputPath+outputFile)\n",
    "    comm.Barrier()\n",
    "    f_o = open(os.path.join(outputPath, outputFile), 'a')\n",
    "    prevdata = np.genfromtxt(os.path.join(outputPath, outputFile), skip_header=0, skip_footer=0)\n",
    "    if len(prevdata.shape) == 1: #this is in case there is only one line in previous file\n",
    "        realtime = prevdata[-1]  #This corresponds to the column you write time data to\n",
    "    else:\n",
    "        realtime = prevdata[prevdata.shape[0]-1, -1]\n",
    "    step = int(checkpointLoadDir.split('/')[-1])\n",
    "    timevals = [0.]\n",
    "else:\n",
    "    f_o = open(outputPath+outputFile, 'w')\n",
    "    realtime = 0.\n",
    "    step = 0\n",
    "    timevals = [0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup parameters\n",
    "-----\n",
    "\n",
    "Set simulation parameters for test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use pint to setup any unit conversions we'll need**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:92: DeprecationWarning: DisplayFormatter._ipython_display_formatter_default is deprecated: use @default decorator instead.\n",
      "  def _ipython_display_formatter_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:98: DeprecationWarning: DisplayFormatter._formatters_default is deprecated: use @default decorator instead.\n",
      "  def _formatters_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "10000.0 meter/megayear"
      ],
      "text/latex": [
       "$10000.0 \\frac{meter}{megayear}$"
      ],
      "text/plain": [
       "<Quantity(10000.0, 'meter / megayear')>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = pint.UnitRegistry()\n",
    "cmpery = 1.*u.cm/u.year\n",
    "mpermy = 1.*u.m/u.megayear\n",
    "year = 1.*u.year\n",
    "spery = year.to(u.sec)\n",
    "cmpery.to(mpermy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#box_half_width =4000e3\n",
    "#age_at_trench = 100e6\n",
    "#cmperyear = box_half_width / age_at_trench #m/y\n",
    "#mpersec = cmperyear*(cmpery.to(u.m/u.second)).magnitude #m/sec\n",
    "#print(cmperyear, mpersec )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set parameter dictionaries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Parameter / settings dictionaries get saved&loaded using pickle\n",
    "###########\n",
    " \n",
    "dp = edict({}) #dimensional parameters\n",
    "sf = edict({}) #scaling factors\n",
    "ndp = edict({}) #dimensionless paramters\n",
    "md = edict({}) #model paramters, flags etc\n",
    "#od = edict({}) #output frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_list = [dp, sf, ndp, md]\n",
    "dict_names = ['dp.pkl', 'sf.pkl', 'ndp.pkl', 'md.pkl']\n",
    "\n",
    "def save_pickles(dict_list, dict_names, dictPath):\n",
    "    import pickle\n",
    "    counter = 0\n",
    "    for pdict in dict_list:\n",
    "        myfile = os.path.join(dictPath, dict_names[counter])\n",
    "        with open(myfile, 'wb') as f:\n",
    "            pickle.dump(pdict, f)\n",
    "        counter+=1\n",
    "\n",
    "\n",
    "#ended up having to pretty much write a hard-coded function\n",
    "#All dictionaries we want checkpointed will have to  be added here \n",
    "#and where the function is called\n",
    "#Fortunately, this function is only called ONCE\n",
    "\n",
    "def load_pickles():\n",
    "    import pickle\n",
    "    dirpath = os.path.join(checkpointPath, str(step))\n",
    "    dpfile = open(os.path.join(dirpath, 'dp.pkl'), 'r')\n",
    "    dp = pickle.load(dpfile)\n",
    "#    #\n",
    "    ndpfile = open(os.path.join(dirpath, 'ndp.pkl'), 'r')\n",
    "    ndp = edict(pickle.load(ndpfile))\n",
    "    #\n",
    "    sffile = open(os.path.join(dirpath, 'sf.pkl'), 'r')\n",
    "    sf = edict(pickle.load(sffile))\n",
    "    #\n",
    "    mdfile = open(os.path.join(dirpath, 'md.pkl'), 'r')\n",
    "    md = edict(pickle.load(mdfile))\n",
    "    return dp, ndp, sf, md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dimensional parameter dictionary\n",
    "dp = edict({'LS':2900.*1e3,\n",
    "           'rho':3300,\n",
    "           'g':9.8, \n",
    "           'eta0':5e20,\n",
    "           #'eta0':1e21,    #This will give Ra ~ 2e7, closer to models by Van Hunen, Billen etc.\n",
    "           #'eta0': 2.12e22, #This will give Ra = 1e6 as quoted on Korenaga's paper\n",
    "           'k':1e-6,\n",
    "           'a':2e-5, \n",
    "           'deltaT':1350, #Hunen\n",
    "           'TS':273.,\n",
    "           'cohesion':1e7, #Not sure where this one came from...\n",
    "           'fc':0.1,        #This is the value from \n",
    "           'E':320000.,\n",
    "           'V':1.*(10**-6), #this is a value from Crameri and Tackley (2015)\n",
    "           'R':8.314,\n",
    "           'StALS':100e3,\n",
    "            'subzone':0.0   #X position of subduction zone...km\n",
    "           })\n",
    "\n",
    "dp['TI'] = dp.TS + dp.deltaT\n",
    "\n",
    "\n",
    "#scale_factors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Modelling and Physics switches\n",
    "\n",
    "md = edict({'refineMesh':True,\n",
    "            'stickyAir':False,\n",
    "            'subductionFault':False,\n",
    "            'symmetricIcs':False,\n",
    "            'velBcs':False,\n",
    "            'aspectRatio':4,\n",
    "            'compBuoyancy':False, #use compositional & phase buoyancy, or simply thermal\n",
    "            'periodicBcs':True,\n",
    "            'melt_viscosity_reduction':True,\n",
    "            'lower_mantle':True,\n",
    "            'RES':48,\n",
    "            'elementType':\"Q2/DPC1\"\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#If starting from a checkpoint load params from file\n",
    "###########\n",
    "\n",
    "if checkpointLoad:\n",
    "    dp, ndp, sf, md = load_pickles()  #remember to add any extra dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#If command line args are given, overwrite\n",
    "#Note that this assumes that params as commans line args/\n",
    "#only append to the 'dimensional' and 'model' dictionary (not the non-dimensional)\n",
    "###########    \n",
    "\n",
    "\n",
    "###########\n",
    "#If extra arguments are provided to the script\" eg:\n",
    "### >>> uw.py 2 dp.arg1=1 dp.arg2=foo dp.arg3=3.0\n",
    "###\n",
    "###This would assign ModNum = 2, all other values go into the dp dictionary, under key names provided\n",
    "###\n",
    "###Two operators are searched for, = & *=\n",
    "###\n",
    "###If =, parameter is re-assigned to givn value\n",
    "###If *=, parameter is multipled by given value\n",
    "###\n",
    "### >>> uw.py 2 dp.arg1=1 dp.arg2=foo dp.arg3*=3.0\n",
    "###########\n",
    "\n",
    "for farg in sys.argv[1:]:\n",
    "    try:\n",
    "        (dicitem,val) = farg.split(\"=\") #Split on equals operator\n",
    "        (dic,arg) = dicitem.split(\".\") #colon notation\n",
    "        if '*=' in farg:\n",
    "            (dicitem,val) = farg.split(\"*=\") #If in-place multiplication, split on '*='\n",
    "            (dic,arg) = dicitem.split(\".\")\n",
    "            \n",
    "        if val == 'True': \n",
    "            val = True\n",
    "        elif val == 'False':     #First check if args are boolean\n",
    "            val = False\n",
    "        else:\n",
    "            try:\n",
    "                val = float(val) #next try to convert  to a float,\n",
    "            except ValueError:\n",
    "                pass             #otherwise leave as string\n",
    "        #Update the dictionary\n",
    "        if farg.startswith('dp'):\n",
    "            if '*=' in farg:\n",
    "                dp[arg] = dp[arg]*val #multiply parameter by given factor\n",
    "            else:\n",
    "                dp[arg] = val    #or reassign parameter by given value\n",
    "        if farg.startswith('md'):\n",
    "            if '*=' in farg:\n",
    "                md[arg] = md[arg]*val #multiply parameter by given factor\n",
    "            else:\n",
    "                md[arg] = val    #or reassign parameter by given value\n",
    "                \n",
    "    except:\n",
    "        pass\n",
    "            \n",
    "\n",
    "comm.barrier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not checkpointLoad:\n",
    "    sf = edict({'stress':dp.LS**2/(dp.k*dp.eta0),\n",
    "            'lith_grad':dp.rho*dp.g*(dp.LS)**3/(dp.eta0*dp.k) ,\n",
    "            'vel':dp.LS/dp.k,\n",
    "            'SR':dp.LS**2/dp.k,\n",
    "            'W':(dp.rho*dp.g*dp.LS)/(dp.R*dp.deltaT), #This is the activation energy scale, in terms of depth (not pressure)\n",
    "            'E': 1./(dp.R*dp.deltaT)}) #To scale E, V, we used a guesstimated adiabatic deltaT\n",
    "\n",
    "    #dimensionless parameters\n",
    "\n",
    "\n",
    "    ndp = edict({'RA':(dp.g*dp.rho*dp.a*dp.deltaT*(dp.LS)**3)/(dp.k*dp.eta0),\n",
    "                'cohesion':dp.cohesion*sf.stress,\n",
    "                'fcd':dp.fc*sf.lith_grad,\n",
    "                'gamma':dp.fc/(dp.a*dp.deltaT),\n",
    "                'E':dp.E*sf.E,\n",
    "                'W':dp.V*sf.W,\n",
    "                'TSP':0., \n",
    "                'TIP':1.,\n",
    "                'n':1.,\n",
    "                'TS':dp.TS/dp.deltaT,\n",
    "                'TI':dp.TI/dp.deltaT,\n",
    "                'eta_min':1e-3,\n",
    "                'eta_max':1e5,\n",
    "                'H':20.,\n",
    "                'Tmvp':0.6,\n",
    "                 'Steta0':1e2,\n",
    "                'subzone':dp.subzone/dp.LS,   #X position of subduction zone..\n",
    "                })\n",
    "\n",
    "\n",
    "\n",
    "    #ndp.RA = 1e6 #this is what Korenaga sets it to\n",
    "\n",
    "#Some final derived values go into the Dictionaries\n",
    "dp.VR = (0.1*(dp.k/dp.LS)*ndp.RA**(2/3.)) #characteristic velocity\n",
    "dp.SR = dp.VR/dp.LS #characteristic strain rate\n",
    "ndp.VR = dp.VR*sf.vel #characteristic velocity\n",
    "ndp.SR = dp.SR*sf.SR #characteristic strain rate\n",
    "ndp.StRA = (3300.*dp.g*(dp.LS)**3)/(dp.eta0 *dp.k) #Composisitional Rayleigh number for rock-air buoyancy force\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setup parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.643997342075707"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(dp.E*ndp.W)\n",
    "#(dp.R*(dp.TS + dp.deltaT) ))\n",
    "\n",
    "math.exp((dp.E + dp.V *dp.rho*dp.g*dp.LS)/dp.E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1043.5616309272725"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns = math.exp( (dp.E + dp.V *dp.rho*dp.g*0) / (dp.R*(dp.TS + dp.deltaT))  )\n",
    "nb = math.exp( (dp.E + dp.V *dp.rho*dp.g*dp.LS) / (dp.R*(dp.TS + dp.deltaT))  )\n",
    "nb/ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Model setup parameters\n",
    "###########\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MINX = -0.5*(md.aspectRatio)\n",
    "MAXX = 0.5*(md.aspectRatio)\n",
    "MINY = 0.\n",
    "MAXY = 1.\n",
    "\n",
    "    \n",
    "    \n",
    "dim = 2          # number of spatial dimensions\n",
    "\n",
    "\n",
    "#MESH STUFF\n",
    "\n",
    "Xres = int(md.RES*8)\n",
    "\n",
    "\n",
    "if md.stickyAir:\n",
    "    Yres = int(md.RES)\n",
    "    MAXY = 1. + dp.StALS/dp.LS #150km\n",
    "    \n",
    "else:\n",
    "    Yres = int(md.RES)\n",
    "    MAXY = 1.\n",
    "\n",
    "\n",
    "periodic = [False, False]\n",
    "if md.periodicBcs:\n",
    "    periodic = [True, False]\n",
    "\n",
    "\n",
    "\n",
    "#System/Solver stuff\n",
    "\n",
    "PIC_integration=True\n",
    "ppc = 25\n",
    "\n",
    "#Output and safety stuff\n",
    "\n",
    "\n",
    "\n",
    "#Metric output stuff\n",
    "figures =  'gldb' #glucifer Store won't work on all machines, if not, set to 'gldb' \n",
    "swarm_repop, swarm_update = 10, 10\n",
    "gldbs_output = 20\n",
    "checkpoint_every, files_output = 20, 20\n",
    "metric_output = 10\n",
    "sticky_air_temp = 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create mesh and finite element variables\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mesh = uw.mesh.FeMesh_Cartesian( elementType = (md.elementType),\n",
    "                                 elementRes  = (Xres, Yres), \n",
    "                                 minCoord    = (MINX, MINY), \n",
    "                                 maxCoord    = (MAXX, MAXY), periodic=periodic)\n",
    "\n",
    "velocityField       = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=2 )\n",
    "pressureField       = uw.mesh.MeshVariable( mesh=mesh.subMesh, nodeDofCount=1 )\n",
    "temperatureField    = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=1 )\n",
    "temperatureDotField = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coordinate = fn.input()\n",
    "depthFn = MAXY - coordinate[1] #a function providing the depth\n",
    "\n",
    "\n",
    "xFn = coordinate[0]  #a function providing the x-coordinate\n",
    "yFn = coordinate[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesh refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mesh shape is :', (8481, 2))\n"
     ]
    }
   ],
   "source": [
    "print(\"mesh shape is :\", mesh.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mesh.reset()\n",
    "\n",
    "jWalls = mesh.specialSets[\"MinJ_VertexSet\"] + mesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "yFn = coordinate[1]\n",
    "yField = uw.mesh.MeshVariable( mesh=mesh, nodeDofCount=1 )\n",
    "yField.data[:] = 0.\n",
    "yBC = uw.conditions.DirichletCondition( variable=yField, indexSetsPerDof=(jWalls,) )\n",
    "\n",
    "# set bottom wall temperature bc\n",
    "for index in mesh.specialSets[\"MinJ_VertexSet\"]:\n",
    "    yField.data[index] = mesh.minCoord[1]\n",
    "# set top wall temperature bc\n",
    "for index in mesh.specialSets[\"MaxJ_VertexSet\"]:\n",
    "    yField.data[index] = mesh.maxCoord[1]\n",
    "    \n",
    "    \n",
    "intensityFac = 4.\n",
    "intensityFn = ((yFn)*intensityFac)\n",
    "intensityFn += 1.\n",
    "\n",
    "yLaplaceEquation = uw.systems.SteadyStateHeat(temperatureField=yField, fn_diffusivity=intensityFn, conditions=[yBC,])\n",
    "\n",
    "# get the default heat equation solver\n",
    "yLaplaceSolver = uw.systems.Solver(yLaplaceEquation)\n",
    "# solve\n",
    "yLaplaceSolver.solve()\n",
    "\n",
    "\n",
    "#Get the array of Y positions - copy may be necessary, not sure. \n",
    "newYpos = yField.data.copy() \n",
    "\n",
    "uw.barrier()\n",
    "with mesh.deform_mesh():\n",
    "     mesh.data[:,1] = newYpos[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig= glucifer.Figure()\n",
    "fig.append( glucifer.objects.Surface(mesh, yField))\n",
    "#fig.append(glucifer.objects.Mesh(mesh))\n",
    "#fig.append( glucifer.objects.Points(gSwarm, temperatureField))\n",
    "#fig.show()\n",
    "#fig.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial conditions\n",
    "-------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Sinusoidal initial condition\n",
    "#A = 0.2\n",
    "#sinFn = depthFn + A*(fn.math.cos( math.pi * coordinate[0])  * fn.math.sin( math.pi * coordinate[1] ))        \n",
    "    \n",
    "#Boundary layer/slab initial condition\n",
    "#w0 = 0.05\n",
    "w0 = 0.1\n",
    "delX = -1.*fn.math.abs((coordinate[0]/MINX))   + 1.\n",
    "w = w0*fn.math.sqrt(delX + 1e-10)\n",
    "tempBL = (ndp.TIP - ndp.TSP) *fn.math.erf((depthFn)/w) + ndp.TSP\n",
    "#\n",
    "                   \n",
    "tempSlab = (ndp.TIP - ndp.TSP) *fn.math.erf((fn.math.abs(xFn)*2.)/w0) + ndp.TSP       \n",
    "\n",
    "tempFn1 =  fn.misc.min(tempBL, tempSlab)\n",
    "                   \n",
    "blFn = fn.branching.conditional([(coordinate[1] > 0.5, tempFn1), \n",
    "                                    (True, 1.)])\n",
    "\n",
    "\n",
    "tempFn = blFn #partition the temp between these two fuctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not checkpointLoad:\n",
    "    temperatureField.data[:] = tempFn.evaluate(mesh)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(20)#set seed for reproducibility\n",
    "temperatureField.data[:,0] += (np.random.rand(mesh.data.shape[0]) -  0.5)*1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make sure material in stick air region is at the surface temperature.\n",
    "for index, coord in enumerate(mesh.data):\n",
    "            if coord[1] >= 1.:\n",
    "                temperatureField.data[index] = ndp.TSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig= glucifer.Figure()\n",
    "fig.append( glucifer.objects.Surface(mesh, temperatureField))\n",
    "#fig.append( glucifer.objects.Points(gSwarm, temperatureField))\n",
    "#fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boundary conditions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index in mesh.specialSets[\"MinJ_VertexSet\"]:\n",
    "    temperatureField.data[index] = ndp.TIP\n",
    "for index in mesh.specialSets[\"MaxJ_VertexSet\"]:\n",
    "    temperatureField.data[index] = ndp.TSP\n",
    "    \n",
    "iWalls = mesh.specialSets[\"MinI_VertexSet\"] + mesh.specialSets[\"MaxI_VertexSet\"]\n",
    "jWalls = mesh.specialSets[\"MinJ_VertexSet\"] + mesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "tWalls = mesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "bWalls =mesh.specialSets[\"MinJ_VertexSet\"]\n",
    "\n",
    "\n",
    "freeslipBC = uw.conditions.DirichletCondition( variable      = velocityField, \n",
    "                                               indexSetsPerDof = ( iWalls, jWalls) )\n",
    "\n",
    "\n",
    "#if md.periodicBcs:\n",
    "#    freeslipBC = uw.conditions.DirichletCondition( variable      = velocityField, \n",
    " #                                              indexSetsPerDof = ( None, jWalls) )\n",
    "\n",
    "# also set dirichlet for temp field\n",
    "dirichTempBC = uw.conditions.DirichletCondition(     variable=temperatureField, \n",
    "                                              indexSetsPerDof=(tWalls,) )\n",
    "dT_dy = [0.,0.]\n",
    "\n",
    "# also set dirichlet for temp field\n",
    "neumannTempBC = uw.conditions.NeumannCondition( dT_dy, variable=temperatureField, \n",
    "                                         nodeIndexSet=bWalls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Particles\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Material Swarm and variables\n",
    "###########\n",
    "\n",
    "#create material swarm\n",
    "gSwarm = uw.swarm.Swarm(mesh=mesh, particleEscape=True)\n",
    "\n",
    "#create swarm variables\n",
    "#yieldingCheck = gSwarm.add_variable( dataType=\"int\", count=1 )\n",
    "#materialVariable = gSwarm.add_variable( dataType=\"int\", count=1 )\n",
    "#ageVariable = gSwarm.add_variable( dataType=\"double\", count=1 )\n",
    "\n",
    "\n",
    "#these lists  are part of the checkpointing implementation\n",
    "varlist = []\n",
    "varnames = []\n",
    "#varlist = [materialVariable, yieldingCheck, ageVariable]\n",
    "#varnames = ['materialVariable', 'yieldingCheck', 'ageVariable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#For starters, we're not going to worry about checkpointing the swarm, as no materials. Maybe add this later\n",
    "\n",
    "layout = uw.swarm.layouts.PerCellRandomLayout(swarm=gSwarm, particlesPerCell=ppc)\n",
    "# Now use it to populate.\n",
    "gSwarm.populate_using_layout( layout=layout )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "if checkpointLoad:\n",
    "    checkpointLoadDir = natsort.natsort(checkdirs)[-1]\n",
    "    temperatureField.load(os.path.join(checkpointLoadDir, \"temperatureField\" + \".hdf5\"))\n",
    "    pressureField.load(os.path.join(checkpointLoadDir, \"pressureField\" + \".hdf5\"))\n",
    "    velocityField.load(os.path.join(checkpointLoadDir, \"velocityField\" + \".hdf5\"))\n",
    "    gSwarm.load(os.path.join(checkpointLoadDir, \"swarm\" + \".h5\"))\n",
    "    for ix in range(len(varlist)):\n",
    "        varb = varlist[ix]\n",
    "        varb.load(os.path.join(checkpointLoadDir,varnames[ix] + \".h5\"))\n",
    "\n",
    "else:\n",
    "\n",
    "    # Layouts are used to populate the swarm across the whole domain\n",
    "    # Create the layout object\n",
    "    layout = uw.swarm.layouts.PerCellRandomLayout(swarm=gSwarm, particlesPerCell=ppc)\n",
    "    # Now use it to populate.\n",
    "    gSwarm.populate_using_layout( layout=layout )\n",
    "\n",
    "    # Swarm variables\n",
    "    materialVariable.data[:] = mantleIndex\n",
    "    tracerVariable.data[:] = 1\n",
    "    yieldingCheck.data[:] = 0\n",
    "    timeVariable.data[:] = 0.\n",
    "    \n",
    "    #Set initial air and crust materials (allow the graph to take care of lithsophere)\n",
    "    #########\n",
    "    #This initial material setup will be model dependent\n",
    "    #########\n",
    "    for particleID in range(gSwarm.particleCoordinates.data.shape[0]):\n",
    "        if (1. - gSwarm.particleCoordinates.data[particleID][1]) < MANTLETOCRUST:\n",
    "                 materialVariable.data[particleID] = crustIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Passive tracer layout**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Material swarm and graphs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up material parameters and functions\n",
    "-----\n",
    "\n",
    "Setup the viscosity to be a function of the temperature. Recall that these functions and values are preserved for the entire simulation time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The yeilding of the upper slab is dependent on the strain rate.\n",
    "strainRate_2ndInvariant = fn.tensor.second_invariant( \n",
    "                            fn.tensor.symmetric( \n",
    "                            velocityField.fn_gradient ))\n",
    "\n",
    "\n",
    "#dp.fc = 0.02\n",
    "thetaT = (dp.E*dp.deltaT)/(dp.R*(dp.TS + dp.deltaT)**2)\n",
    "thetaZ = 3.\n",
    "\n",
    "#gamma = dp.fc/(dp.a*dp.deltaT)\n",
    "#print(thetaT, thetaZ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dp.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7037037037037033"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.fc/(dp.a*dp.deltaT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#overide these parameters to match the reference case quoted on page 5\n",
    "#theta = 15.\n",
    "#gamma = 0.6\n",
    "#ndp.E = 11.\n",
    "#ndp.W = 3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############\n",
    "#Rheology\n",
    "#############\n",
    "#\n",
    "#The final mantle rheology is composed as follows*:\n",
    "# \n",
    "#\n",
    "# mantleviscosityFn = max{  min{(1/omega*nonlinearVisc + 1/eta_p)**-1,\n",
    "#                           eta_max},\n",
    "#                           eta_min}\n",
    "#                      \n",
    "#nonlinearVisc => FK viscosity (could be linear or non linear)\n",
    "#eta_p   => stress-limiting effective viscosity\n",
    "#\n",
    "\n",
    "\n",
    "omega = fn.misc.constant(1.)\n",
    "\n",
    "if md.melt_viscosity_reduction:\n",
    "    mvr =  fn.branching.conditional( [ (temperatureField > (ndp.Tmvp + 7.5*(1. - coordinate[1])) , 0.1 ),   (         True, 1.) ] )\n",
    "    omega = omega*mvr\n",
    "\n",
    "\n",
    "#implementation of the lower mantle viscosity increase, similar to Bello et al. 2015\n",
    "a = 1.\n",
    "B = 30.\n",
    "d0 = 660e3/dp.LS  \n",
    "ds = d0/10.\n",
    "if md.lower_mantle:\n",
    "    inner1 = 1. - 0.5*(1. - fn.math.tanh(((1. - d0)-(coordinate[1]))/(ds)))\n",
    "    modfac = a*fn.math.exp(np.log(B)*inner1)\n",
    "    omega = omega*modfac\n",
    "\n",
    "\n",
    "\n",
    "linearVisc = fn.math.exp(thetaT*(1. - temperatureField) + thetaZ*(depthFn))\n",
    "\n",
    "\n",
    "\n",
    "ys =  ndp.cohesion + ndp.fcd*depthFn #tau_1 * 1e-5 is the cohesion value used in the paper\n",
    "\n",
    "yielding = ys/(strainRate_2ndInvariant/math.sqrt(0.5) + 1e-15) #extra factor to account for underworld second invariant form\n",
    "\n",
    "\n",
    "mantleviscosityFn = fn.misc.max(fn.misc.min(1./(((1./linearVisc) + (1./yielding))), ndp.eta_max), ndp.eta_min)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fig= glucifer.Figure()\n",
    "#fig.append( glucifer.objects.Surface(mesh, mantleviscosityFn, logScale=True))\n",
    "#fig.append( glucifer.objects.VectorArrows(mesh, velocityField, scaling = 0.001))\n",
    "\n",
    "#fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System setup\n",
    "-----\n",
    "\n",
    "Since we are using a previously constructed temperature field, we will use a single Stokes solve to get consistent velocity and pressure fields.\n",
    "\n",
    "**Setup a Stokes system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here we set a viscosity value of '1.' for both materials\n",
    "#viscosityMapFn = fn.branching.map( fn_key = materialVariable,\n",
    "#                         mapping = {lithosphereIndex:mantleviscosityFn, \n",
    "#                                    crustIndex:10.,\n",
    "#                                    mantleIndex:mantleviscosityFn, \n",
    "#                                    eclIndex:mantleviscosityFn,\n",
    "#                                    airIndex:ndp.Steta0} )\n",
    "\n",
    "#densityMapFn = fn.branching.map( fn_key = materialVariable,\n",
    "#                         mapping = {airIndex:ndp.StRA, \n",
    "#                                    lithosphereIndex:ndp.RA*temperatureField, \n",
    "#                                    crustIndex:ndp.RA*temperatureField, \n",
    "#                                    mantleIndex:ndp.RA*temperatureField} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.03703703703704"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndp.StRA/ndp.RA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct our density function.\n",
    "densityFn = ndp.RA * temperatureField\n",
    "\n",
    "# Define our vertical unit vector using a python tuple (this will be automatically converted to a function).\n",
    "gravity = ( 0.0, 1.0 )\n",
    "\n",
    "# Now create a buoyancy force vector using the density and the vertical unit vector. \n",
    "buoyancyFn = densityFn * gravity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stokesPIC = uw.systems.Stokes(velocityField=velocityField, \n",
    "                              pressureField=pressureField,\n",
    "                              conditions=[freeslipBC,],\n",
    "                              fn_viscosity=mantleviscosityFn, \n",
    "                              fn_bodyforce=buoyancyFn )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up and solve the Stokes system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solver = uw.systems.Solver(stokesPIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add the non-linear viscosity to the Stokes system**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m\n",
      " \n",
      "Pressure iterations:   4\n",
      "Velocity iterations:   1 (presolve)      \n",
      "Velocity iterations:  -1 (pressure solve)\n",
      "Velocity iterations:   1 (backsolve)     \n",
      "Velocity iterations:   1 (total solve)   \n",
      " \n",
      "SCR RHS  solve time: 2.9532e+00\n",
      "Pressure solve time: 2.4575e-01\n",
      "Velocity solve time: 2.9523e+00 (backsolve)\n",
      "Total solve time   : 6.6727e+00\n",
      " \n",
      "Velocity solution min/max: 0.0000e+00/0.0000e+00\n",
      "Pressure solution min/max: 0.0000e+00/0.0000e+00\n",
      " \n",
      "\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "solver.set_inner_method(\"mumps\")\n",
    "solver.options.scr.ksp_type=\"cg\"\n",
    "solver.set_penalty(1.0e7)\n",
    "solver.options.scr.ksp_rtol = 1.0e-4\n",
    "solver.solve(nonLinearIterate=True)\n",
    "solver.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create an advective diffusive system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "advDiff = uw.systems.AdvectionDiffusion( phiField       = temperatureField, \n",
    "                                         phiDotField    = temperatureDotField, \n",
    "                                         velocityField  = velocityField,\n",
    "                                         fn_sourceTerm    = 20.0,\n",
    "                                         fn_diffusivity = 1.0, \n",
    "                                         conditions     = [neumannTempBC, dirichTempBC] )\n",
    "\n",
    "passiveadvector = uw.systems.SwarmAdvector( swarm         = gSwarm, \n",
    "                                     velocityField = velocityField, \n",
    "                                     order         = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "population_control = uw.swarm.PopulationControl(gSwarm,deleteThreshold=0.2,splitThreshold=1.,maxDeletions=3,maxSplits=0, aggressive=True, particlesPerCell=ppc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis functions / routines\n",
    "-----\n",
    "\n",
    "Most of the metrics we want to calculate are either:\n",
    "\n",
    "* extrema of some field / function\n",
    "* integral of some field / function\n",
    "* average value of some function (integral divide by area)\n",
    "\n",
    "In addition, we also want to be able to determine these metrics over some restricted part of the domain, where the restriction may either be due some value of a field, a material type, or something more arbitrary.\n",
    "\n",
    "Much of he challenge lies in defining these restriction functions in an efficient and robust way (i.e they don't break down as the model evolves)\n",
    "\n",
    "For volume integrals, and extrema, we build a hierarchy of restriction functions, each borrowing from the previous, until we have divided the domain into a number of sub regions of interest. \n",
    "\n",
    "In general, averages are found afterwards by combining the integral and the area of the relavent subregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###################\n",
    "#Volume Restriction functions\n",
    "###################\n",
    "\n",
    "#Level 1. Global\n",
    "globRestFn = fn.misc.constant(1.)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Level 2. lithosphere - mantle:\n",
    "tempMM = fn.view.min_max(temperatureField)\n",
    "tempMM.evaluate(mesh)\n",
    "TMAX = tempMM.max_global()\n",
    "mantleconditions = [ (                                  temperatureField < 0.9*TMAX, 1.),\n",
    "                   (                                                   True , 0.) ]\n",
    "lithRestFn = fn.branching.conditional(mantleconditions)\n",
    "lithRestFn*=globRestFn #Add next level up in heirarchy\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################\n",
    "#Surface Restriction functions\n",
    "###################\n",
    "\n",
    "def platenessFn(val = 0.1):\n",
    "    normgradV = fn.math.abs(velocityField.fn_gradient[0]/fn.math.sqrt(velocityField[0]*velocityField[0])) #[du*/dx]/sqrt(u*u)\n",
    "\n",
    "\n",
    "\n",
    "    srconditions = [ (                                  normgradV < val, 1.),\n",
    "                   (                                                   True , 0.) ]\n",
    "\n",
    "\n",
    "    return fn.branching.conditional(srconditions)\n",
    "\n",
    "srRestFn = platenessFn(val = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###################\n",
    "#Setup any Functions to be integrated\n",
    "###################\n",
    "\n",
    "sqrtv2 = fn.math.sqrt(fn.math.dot(velocityField,velocityField))\n",
    "vx = velocityField[0]\n",
    "v2x = fn.math.dot(velocityField[0],velocityField[0])\n",
    "sqrtv2x = fn.math.sqrt(fn.math.dot(velocityField[0],velocityField[0]))\n",
    "dw = temperatureField*velocityField[1]\n",
    "sinner = fn.math.dot( strainRate_2ndInvariant, strainRate_2ndInvariant )\n",
    "vd = 2.*mantleviscosityFn*sinner\n",
    "dTdZ = temperatureField.fn_gradient[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################\n",
    "#Create integral, max/min templates \n",
    "###################\n",
    "\n",
    "def volumeint(Fn = 1., rFn=globRestFn):\n",
    "    return uw.utils.Integral( Fn*rFn,  mesh )\n",
    "\n",
    "def surfint(Fn = 1., rFn=globRestFn, surfaceIndexSet=mesh.specialSets[\"MaxJ_VertexSet\"]):\n",
    "    return uw.utils.Integral( Fn*rFn, mesh=mesh, integrationType='Surface', surfaceIndexSet=surfaceIndexSet)\n",
    "\n",
    "def maxMin(Fn = 1.):\n",
    "    #maxMin(Fn = 1., rFn=globRestFn\n",
    "    #vuFn = fn.view.min_max(Fn*rFn) #the restriction functions don't work with the view.min_max fn yet\n",
    "    vuFn = fn.view.min_max(Fn)\n",
    "    return vuFn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setup volume integrals on different sub regions\n",
    "\n",
    "##Whole rock domain\n",
    "\n",
    "_areaintRock = volumeint(globRestFn)\n",
    "_tempintRock = volumeint(temperatureField, globRestFn)\n",
    "_rmsintRock = volumeint(sqrtv2, globRestFn)\n",
    "_dwintRock = volumeint(dw, globRestFn)\n",
    "_vdintRock = volumeint(vd, globRestFn)\n",
    "\n",
    "##Lith \n",
    "\n",
    "_areaintLith  = volumeint(lithRestFn)\n",
    "_tempintLith  = volumeint(temperatureField, lithRestFn)\n",
    "_rmsintLith  = volumeint(sqrtv2,lithRestFn)\n",
    "_dwintLith  = volumeint(dw,lithRestFn)\n",
    "_vdintLith  = volumeint(vd,lithRestFn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setup surface integrals\n",
    "\n",
    "_surfLength = surfint()\n",
    "_rmsSurf = surfint(v2x)\n",
    "_nuTop = surfint(dTdZ)\n",
    "_nuBottom = surfint(dTdZ, surfaceIndexSet=mesh.specialSets[\"MinJ_VertexSet\"])\n",
    "_plateness = surfint(srRestFn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_maxMinVel = maxMin(velocityField) \n",
    "dummyFn = _maxMinVel.evaluate(mesh)\n",
    "\n",
    "_maxMinSr = maxMin(strainRate_2ndInvariant) \n",
    "dummyFn = _maxMinSr.evaluate(mesh)\n",
    "\n",
    "\n",
    "#Surface extrema\n",
    "_maxMinVxSurf = maxMin(vx)\n",
    "dummyFn = _maxMinVxSurf.evaluate(tWalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Volume Ints\n",
    "areaintRock = _areaintRock.evaluate()[0]\n",
    "tempintRock = _tempintRock.evaluate()[0]\n",
    "rmsintRock = _rmsintRock.evaluate()[0]\n",
    "dwintRock = _dwintRock.evaluate()[0]\n",
    "vdintRock = _vdintRock.evaluate()[0]\n",
    "areaintLith = _areaintLith.evaluate()[0]\n",
    "tempintLith = _tempintLith.evaluate()[0]\n",
    "rmsintLith = _rmsintLith.evaluate()[0]\n",
    "dwintLith = _dwintLith.evaluate()[0]\n",
    "vdintLith = _vdintLith.evaluate()[0]\n",
    "\n",
    "\n",
    "#Surface Ints\n",
    "surfLength = _surfLength.evaluate()[0]\n",
    "rmsSurf = _rmsSurf.evaluate()[0]\n",
    "nuTop = _nuTop.evaluate()[0]\n",
    "nuBottom = _nuBottom.evaluate()[0]\n",
    "plateness = _plateness.evaluate()[0]\n",
    "\n",
    "#Max mins\n",
    "maxVel = _maxMinVel.max_global()\n",
    "minVel = _maxMinVel.min_global() \n",
    "maxSr = _maxMinSr.max_global()\n",
    "minSr = _maxMinSr.min_global()\n",
    "maxVxsurf = _maxMinVxSurf.max_global()\n",
    "minVxsurf = _maxMinVxSurf.min_global()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "3.84398417101\n",
      "139.504595786\n",
      "-0.4315512626\n",
      "44372726.5295\n",
      "0.353501693105\n",
      "0.190095394984\n",
      "18.9696864372\n",
      "-2.26239248666\n",
      "43148778.3803\n",
      "4.0\n",
      "9671.91192953\n",
      "-93.2162803362\n",
      "3.38422276137\n",
      "3.10115396516\n",
      "184.622816194\n",
      "0.0\n",
      "7234.48552674\n",
      "0.0325389215321\n",
      "51.4939810532\n",
      "-51.4939812812\n"
     ]
    }
   ],
   "source": [
    "print(areaintRock)\n",
    "print(tempintRock)\n",
    "print(rmsintRock)\n",
    "print(dwintRock)\n",
    "print(vdintRock)\n",
    "print(areaintLith)\n",
    "print(tempintLith )\n",
    "print(rmsintLith)\n",
    "print(dwintLith)\n",
    "print(vdintLith)\n",
    "\n",
    "print(surfLength)\n",
    "print(rmsSurf)\n",
    "print(nuTop)\n",
    "print(nuBottom)\n",
    "print(plateness)\n",
    "\n",
    "\n",
    "print(maxVel)\n",
    "print(minVel)\n",
    "print(maxSr)\n",
    "print(minSr)\n",
    "print(maxVxsurf)\n",
    "print(minVxsurf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viz.\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if figures == 'store':\n",
    "    fullpath = os.path.join(outputPath + \"gldbs/\")\n",
    "    store = glucifer.Store(fullpath + 'subduction.gldb')\n",
    "\n",
    "    figTemp = glucifer.Figure(store,figsize=(300*np.round(md.aspectRatio,2),300))\n",
    "    figTemp.append( glucifer.objects.Points(gSwarm,temperatureField))\n",
    "\n",
    "    figVisc= glucifer.Figure(store, figsize=(300*np.round(md.aspectRatio,2),300))\n",
    "    figVisc.append( glucifer.objects.Points(gSwarm,mantleviscosityFn, logScale=True, valueRange =[1e-3,1e5]))\n",
    "    \n",
    "    figSr= glucifer.Figure(store, figsize=(300*np.round(md.aspectRatio,2),300))\n",
    "    figSr.append( glucifer.objects.Points(gSwarm,strainRate_2ndInvariant, logScale=True))\n",
    "    figSr.append( glucifer.objects.VectorArrows(mesh,velocityField, scaling=0.0005))\n",
    "    \n",
    "if figures == 'gldb':\n",
    "    #Pack some stuff into a database as well\n",
    "    figDb = glucifer.Figure()\n",
    "    #figDb.append( glucifer.objects.Mesh(mesh))\n",
    "    figDb.append( glucifer.objects.VectorArrows(mesh,velocityField, scaling=0.0005))\n",
    "    #figDb.append( glucifer.objects.Points(gSwarm,tracerVariable, colours= 'white black'))\n",
    "    #figDb.append( glucifer.objects.Points(gSwarm,materialVariable))\n",
    "    #figDb.append( glucifer.objects.Points(gSwarm,viscMinVariable))\n",
    "    #figDb.append( glucifer.objects.Points(gSwarm,fnViscMin))\n",
    "    figDb.append( glucifer.objects.Points(gSwarm, mantleviscosityFn, logScale=True))\n",
    "    figDb.append( glucifer.objects.Points(gSwarm, strainRate_2ndInvariant, logScale=True))\n",
    "    figDb.append( glucifer.objects.Points(gSwarm,temperatureField))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Miscellania\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/core/numeric.py:190: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  a = empty(shape, dtype, order)\n"
     ]
    }
   ],
   "source": [
    "##############\n",
    "#Create a numpy array at the surface to get surface information on (using parallel-friendly evaluate_global)\n",
    "##############\n",
    "\n",
    "surface_xs = np.linspace(mesh.minCoord[0], mesh.maxCoord[0], mesh.elementRes[0] + 1)\n",
    "surface_nodes = np.array(zip(surface_xs, np.ones(len(surface_xs)*mesh.maxCoord[1]))) #For evaluation surface velocity\n",
    "normgradV = velocityField.fn_gradient[0]/fn.math.sqrt(velocityField[0]*velocityField[0])\n",
    "\n",
    "tempMM = fn.view.min_max(temperatureField)\n",
    "dummy = tempMM.evaluate(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#Simple function to return info about location of plate boundaries\n",
    "##############\n",
    "\n",
    "def getnearpos(array,value):\n",
    "    idx = (np.abs(array-value)).argmin()\n",
    "    return idx \n",
    "\n",
    "def plate_info(srfilename, minx, maxx,  searchdx, oldszloc = 0.0):\n",
    "    \"\"\"\n",
    "    Use the surface strain rate field to find the location of the subduction zone in 2d\n",
    "    \n",
    "    \"\"\"\n",
    "    if type(srfilename) == str: #read surface strain rate points from file\n",
    "        sr = np.load(srfilename)\n",
    "    else:\n",
    "        sr =  srfilename        #read surface strain rates directly from array\n",
    "    xs = np.linspace(minx,maxx,sr.shape[0] )\n",
    "    #infs at the ends of the SR data...replace with adjacent values\n",
    "    sr[0] = sr[1] \n",
    "    sr[-1] = sr[2]\n",
    "    #Normalize\n",
    "    srx = (sr- sr.mean()) /(sr.max() - sr.min())\n",
    "    #reduce the search domain, to near the previous PB location\n",
    "    lx, rx = getnearpos(xs, oldszloc - searchdx),  getnearpos(xs, oldszloc + searchdx)\n",
    "    red_xs, red_sr = xs[lx:rx], srx[lx:rx]\n",
    "    #return the minima\n",
    "    newszLoc = red_xs[np.argmin(red_sr)]\n",
    "    return newszLoc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#These functions handle checkpointing\n",
    "##############\n",
    "\n",
    "\n",
    "#Subzone = ndp.subzone\n",
    "\n",
    "\n",
    "def checkpoint1(step, checkpointPath,filename, filewrites):\n",
    "    path = checkpointPath + str(step) \n",
    "    os.mkdir(path)\n",
    "    ##Write and save the file, if not already a writing step\n",
    "    if not step % filewrites == 0:\n",
    "        f_o.write((16*'%-15s ' + '\\n') % (areaintRock, tempintRock, rmsintRock, dwintRock, vdintRock,\n",
    "                                  areaintLith, tempintLith,rmsintLith, dwintLith, vdintLith,\n",
    "                                  rmsSurf, nuTop, nuBottom, plateness, ndp.subzone, realtime))\n",
    "    filename.close()\n",
    "    shutil.copyfile(os.path.join(outputPath, outputFile), os.path.join(path, outputFile))\n",
    "\n",
    "\n",
    "def checkpoint2(step, checkpointPath, swarm, filename, varlist = [], varnames = []):\n",
    "    path = checkpointPath + str(step) \n",
    "    velfile = \"velocityField\" + \".hdf5\"\n",
    "    tempfile = \"temperatureField\" + \".hdf5\"\n",
    "    pressfile = \"pressureField\" + \".hdf5\"\n",
    "    velocityField.save(os.path.join(path, velfile))\n",
    "    temperatureField.save(os.path.join(path, tempfile))\n",
    "    pressureField.save(os.path.join(path, pressfile))\n",
    "    swarm.save(os.path.join(path, \"swarm.h5\") ) \n",
    "    for ix in range(len(varlist)):\n",
    "        varb = varlist[ix]\n",
    "        varb.save(os.path.join(path,varnames[ix] + \".h5\"))\n",
    "    \n",
    "    #Save the parameters\n",
    "    dict_list = [dp, sf, ndp, md] #if any of the dictionaries have changed, this list needs to be rebuilt\n",
    "    save_pickles(dict_list, dict_names, path)\n",
    "    \n",
    "#Simple Checkpoint function for the faults / interfaces (markerLine2D)\n",
    "def checkpoint3(step,  checkpointPath, interfaces,interfacenames ):\n",
    "    path = checkpointPath + str(step)\n",
    "    for ix in range(len(interfaces)):\n",
    "        intf = interfaces[ix]\n",
    "        intf.swarm.save(os.path.join(path,interfacenames[ix] + \".h5\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tempMM.max_global(), temperatureField.data.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main simulation loop\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialise timer for computation\n",
    "start = time.clock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error encountered. Full restart recommended as exception safety not guaranteed. Error message:\nSomething went wrong in _PCDVC_Calculate2D: Problem has an under resolved cell (Cell Id = 0).\nYou may need to check your initial particle layout configuration. A per cell layout might give better results than a global layout, especially where you have a deformed mesh. Also, if particles are able to escape the domain, you can enable aggressive population control by setting the 'particleEscape' swarm constructor parameter.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-134-dbe34ebaf2ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;31m################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;31m#if step % swarm_repop == 0:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[0mpopulation_control\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepopulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m     \u001b[1;31m################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;31m#Gldb output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/root/underworld2/underworld/swarm/_population_control.pyc\u001b[0m in \u001b[0;36mrepopulate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mThis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mrepopulates\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mswarm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \"\"\"\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swarm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_voronoi_swarm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepopulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_calculator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m         \u001b[1;31m# repopulation potentially adds/removes particles... so we need to increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;31m# the swarm id.  note that this should occur *after* the repopulate call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/root/underworld2/underworld/swarm/_integration_swarm.pyc\u001b[0m in \u001b[0;36mrepopulate\u001b[1;34m(self, weights_calculator)\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;31m# if weights calculator is PCDVC, then we need to always run as it potentially performs population control\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappedToState\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mappedSwarm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateId\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_calculator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswarm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_weights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPCDVC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0mlibUnderworld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPICellerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWeightsCalculator_CalculateAll\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mweights_calculator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cself\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m             \u001b[0mlibUnderworld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPICellerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIntegrationPointsSwarm_ClearSwarmMaps\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cself\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error encountered. Full restart recommended as exception safety not guaranteed. Error message:\nSomething went wrong in _PCDVC_Calculate2D: Problem has an under resolved cell (Cell Id = 0).\nYou may need to check your initial particle layout configuration. A per cell layout might give better results than a global layout, especially where you have a deformed mesh. Also, if particles are able to escape the domain, you can enable aggressive population control by setting the 'particleEscape' swarm constructor parameter."
     ]
    }
   ],
   "source": [
    "#while step < 21:\n",
    "while realtime < 1.:\n",
    "\n",
    "    # solve Stokes and advection systems\n",
    "    solver.solve(nonLinearIterate=True)\n",
    "    dt = advDiff.get_max_dt()\n",
    "    if step == 0:\n",
    "        dt = 0.\n",
    "    advDiff.integrate(dt)\n",
    "    #passiveadvector.integrate(dt)\n",
    "    #for f in interfaces:\n",
    "    #    f.advection(dt)\n",
    "    \n",
    "\n",
    "    # Increment\n",
    "    realtime += dt\n",
    "    step += 1\n",
    "    timevals.append(realtime)\n",
    "    \n",
    "    ################\n",
    "    #Update temperature field in the air region\n",
    "    #Do this better...\n",
    "    ################\n",
    "    if (step % sticky_air_temp == 0):\n",
    "        for index, coord in enumerate(mesh.data):\n",
    "            if coord[1] >= 1.:\n",
    "                temperatureField.data[index] = ndp.TSP\n",
    "                \n",
    "                \n",
    "    ################\n",
    "    # Calculate the Metrics\n",
    "    ################\n",
    "    if (step % metric_output == 0):\n",
    "        \n",
    "        ###############\n",
    "        #Metrics\n",
    "        ###############\n",
    "        areaintRock = _areaintRock.evaluate()[0] #trivial except when using sticky air\n",
    "        tempintRock = _tempintRock.evaluate()[0]\n",
    "        rmsintRock = _rmsintRock.evaluate()[0]\n",
    "        dwintRock = _dwintRock.evaluate()[0]\n",
    "        vdintRock = _vdintRock.evaluate()[0]\n",
    "        areaintLith = _areaintLith.evaluate()[0]\n",
    "        tempintLith = _tempintLith.evaluate()[0]\n",
    "        rmsintLith = _rmsintLith.evaluate()[0]\n",
    "        dwintLith = _dwintLith.evaluate()[0]\n",
    "        vdintLith = _vdintLith.evaluate()[0]\n",
    "    \n",
    "        #Surface integrals\n",
    "        rmsSurf = _rmsSurf.evaluate()[0]\n",
    "        nuTop = _nuTop.evaluate()[0]\n",
    "        nuBottom = _nuBottom.evaluate()[0]\n",
    "        plateness = _plateness.evaluate()[0]\n",
    "        #extrema\n",
    "        maxVel = _maxMinVel.max_global()\n",
    "        minVel = _maxMinVel.min_global() \n",
    "        maxSr = _maxMinSr.max_global()\n",
    "        minSr = _maxMinSr.min_global()\n",
    "        maxVxsurf = _maxMinVxSurf.max_global()\n",
    "        minVxsurf = _maxMinVxSurf.min_global()\n",
    "        # output to summary text file\n",
    "        if uw.rank()==0:\n",
    "            f_o.write((16*'%-15s ' + '\\n') % (areaintRock, tempintRock, rmsintRock, dwintRock, vdintRock,\n",
    "                                  areaintLith, tempintLith,rmsintLith, dwintLith, vdintLith,\n",
    "                                  rmsSurf, nuTop, nuBottom, plateness, ndp.subzone, realtime))\n",
    "\n",
    "    ################\n",
    "    #Also repopulate entire swarm periodically\n",
    "    ################\n",
    "    #if step % swarm_repop == 0:\n",
    "    population_control.repopulate()   \n",
    "    ################\n",
    "    #Gldb output\n",
    "    ################ \n",
    "    if (step % gldbs_output == 0): \n",
    "        if figures == 'gldb':\n",
    "            #Remember to rebuild any necessary swarm variables\n",
    "            fnamedb = \"dbFig\" + \"_\" + str(step) + \".gldb\"\n",
    "            fullpath = os.path.join(outputPath + \"gldbs/\" + fnamedb)\n",
    "            figDb.save_database(fullpath)\n",
    "            \n",
    "            #Temp figure\n",
    "            #fnamedb = \"restrictFig\" + \"_\" + str(step) + \".gldb\"\n",
    "            #fullpath = os.path.join(outputPath + \"gldbs/\" + fnamedb)\n",
    "            #figRestrict.save_database(fullpath)\n",
    "        elif figures == 'store':      \n",
    "            fullpath = os.path.join(outputPath + \"gldbs/\")\n",
    "            store.step = step\n",
    "            #Save figures to store\n",
    "            figVisc.save( fullpath + \"Visc\" + str(step).zfill(4))\n",
    "            #figMech.save( fullPath + \"Mech\" + str(step).zfill(4))\n",
    "            figTemp.save( fullpath + \"Temp\"    + str(step).zfill(4))\n",
    "            figSr.save( fullpath + \"Str_rte\"    + str(step).zfill(4))\n",
    "            \n",
    "    ################\n",
    "    #Files output\n",
    "    ################ \n",
    "    if (step % files_output == 0):\n",
    "\n",
    "        vel_surface = velocityField.evaluate_global(surface_nodes)\n",
    "        norm_surface_sr = normgradV.evaluate_global(surface_nodes)\n",
    "        if uw.rank() == 0:\n",
    "            fnametemp = \"velsurface\" + \"_\" + str(step)\n",
    "            fullpath = os.path.join(outputPath + \"files/\" + fnametemp)\n",
    "            np.save(fullpath, vel_surface)\n",
    "            fnametemp = \"norm_surface_sr\" + \"_\" + str(step)\n",
    "            fullpath = os.path.join(outputPath + \"files/\" + fnametemp)\n",
    "            np.save(fullpath, norm_surface_sr)\n",
    "            \n",
    "    ################\n",
    "    #Update the subduction zone / plate information\n",
    "    ################ \n",
    "    \n",
    "    comm.barrier()\n",
    "    if (step % files_output == 0):\n",
    "        \n",
    "        if uw.rank() == 0:\n",
    "            fnametemp = \"norm_surface_sr\" + \"_\" + str(step) + \".npy\"\n",
    "            fullpath = os.path.join(outputPath + \"files/\" + fnametemp)\n",
    "            ndp.subzone = plate_info(fullpath, MINX, MAXX,  800e3/dp.LS, oldszloc = ndp.subzone)\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    ################\n",
    "    #Checkpoint\n",
    "    ################\n",
    "    if step % checkpoint_every == 0:\n",
    "        if uw.rank() == 0:\n",
    "            checkpoint1(step, checkpointPath,f_o, metric_output)           \n",
    "        checkpoint2(step, checkpointPath, gSwarm, f_o, varlist = varlist, varnames = varnames)\n",
    "        #checkpoint3(step,  checkpointPath, interfaces,interfacenames )\n",
    "        f_o = open(os.path.join(outputPath, outputFile), 'a') #is this line supposed to be here?    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "f_o.close()\n",
    "print 'step =',step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0035152338272530807]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xvelMean = uw.utils.Integral(velocityField[0],  mesh )\n",
    "xvelMean.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "velocityField[0].evaluate(iWalls).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figVisc= glucifer.Figure(figsize=(300*np.round(md.aspectRatio,2),300))\n",
    "figVisc.append( glucifer.objects.Points(gSwarm,mantleviscosityFn, logScale=True, valueRange =[1e-3,1e5]))\n",
    "figVisc.append(glucifer.objects.VectorArrows(mesh, velocityField))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test.gldb'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#figVisc.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='data:image/png;base64,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'>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'test.gldb'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig= glucifer.Figure()\n",
    "#fig.append( glucifer.objects.Surface(mesh, temperatureField))\n",
    "fig.append(glucifer.objects.Mesh(mesh))\n",
    "#fig.append( glucifer.objects.Points(gSwarm, temperatureField))\n",
    "fig.show()\n",
    "fig.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
