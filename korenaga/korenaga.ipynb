{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korenaga 2011\n",
    "======\n",
    "\n",
    "Temperature dependent convection\n",
    "----\n",
    "\n",
    "This Notebooks implements the case of two-dimensional, incompressible, internally-heated fmantle convection.\n",
    "\n",
    "\n",
    "**Keywords:** Stokes system, advective diffusive systems, analysis tools, tools for post analysis, rheologies\n",
    "\n",
    "\n",
    "**References**\n",
    "\n",
    "Korenaga, Jun. \"Scaling of plate tectonic convection with pseudoplastic rheology.\" Journal of Geophysical Research: Solid Earth 115.B11 (2010).\n",
    "http://onlinelibrary.wiley.com/doi/10.1029/2010JB007670/full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import underworld as uw\n",
    "import math\n",
    "from underworld import function as fn\n",
    "import glucifer\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import natsort\n",
    "import shutil\n",
    "from easydict import EasyDict as edict\n",
    "import operator\n",
    "import pint\n",
    "import time\n",
    "import operator\n",
    "from slippy2 import boundary_layer2d\n",
    "from slippy2 import material_graph\n",
    "\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model name and directories\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############\n",
    "#Model name.  \n",
    "############\n",
    "Model = \"T\"\n",
    "ModNum = 2\n",
    "\n",
    "if len(sys.argv) == 1:\n",
    "    ModIt = \"Base\"\n",
    "elif sys.argv[1] == '-f':\n",
    "    ModIt = \"Base\"\n",
    "else:\n",
    "    ModIt = str(sys.argv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Standard output directory setup\n",
    "###########\n",
    "\n",
    "\n",
    "outputPath = \"results\" + \"/\" +  str(Model) + \"/\" + str(ModNum) + \"/\" + str(ModIt) + \"/\"\n",
    "imagePath = outputPath + 'images/'\n",
    "filePath = outputPath + 'files/'\n",
    "checkpointPath = outputPath + 'checkpoint/'\n",
    "dbPath = outputPath + 'gldbs/'\n",
    "outputFile = 'results_model' + Model + '_' + str(ModNum) + '_' + str(ModIt) + '.dat'\n",
    "\n",
    "if uw.rank()==0:\n",
    "    # make directories if they don't exist\n",
    "    if not os.path.isdir(outputPath):\n",
    "        os.makedirs(outputPath)\n",
    "    if not os.path.isdir(checkpointPath):\n",
    "        os.makedirs(checkpointPath)\n",
    "    if not os.path.isdir(imagePath):\n",
    "        os.makedirs(imagePath)\n",
    "    if not os.path.isdir(dbPath):\n",
    "        os.makedirs(dbPath)\n",
    "    if not os.path.isdir(filePath):\n",
    "        os.makedirs(filePath)\n",
    "        \n",
    "comm.Barrier() #Barrier here so no procs run the check in the next cell too early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/T/2/Base/checkpoint/ is empty\n",
      "results/T/2/Base/checkpoint/1600 has files\n",
      "results/T/2/Base/checkpoint/1000 has files\n",
      "results/T/2/Base/checkpoint/2800 has files\n",
      "results/T/2/Base/checkpoint/700 has files\n",
      "results/T/2/Base/checkpoint/200 has files\n",
      "results/T/2/Base/checkpoint/1350 has files\n",
      "results/T/2/Base/checkpoint/100 has files\n",
      "results/T/2/Base/checkpoint/950 has files\n",
      "results/T/2/Base/checkpoint/500 has files\n",
      "results/T/2/Base/checkpoint/3350 has files\n",
      "results/T/2/Base/checkpoint/3550 has files\n",
      "results/T/2/Base/checkpoint/2550 has files\n",
      "results/T/2/Base/checkpoint/3050 has files\n",
      "results/T/2/Base/checkpoint/600 has files\n",
      "results/T/2/Base/checkpoint/3700 has files\n",
      "results/T/2/Base/checkpoint/1950 has files\n",
      "results/T/2/Base/checkpoint/1500 has files\n",
      "results/T/2/Base/checkpoint/2300 has files\n",
      "results/T/2/Base/checkpoint/2250 has files\n",
      "results/T/2/Base/checkpoint/2100 has files\n",
      "results/T/2/Base/checkpoint/2150 has files\n",
      "results/T/2/Base/checkpoint/450 has files\n",
      "results/T/2/Base/checkpoint/400 has files\n",
      "results/T/2/Base/checkpoint/3200 has files\n",
      "results/T/2/Base/checkpoint/3400 has files\n",
      "results/T/2/Base/checkpoint/300 has files\n",
      "results/T/2/Base/checkpoint/1150 has files\n",
      "results/T/2/Base/checkpoint/1800 has files\n",
      "results/T/2/Base/checkpoint/1450 has files\n",
      "results/T/2/Base/checkpoint/50 has files\n",
      "results/T/2/Base/checkpoint/900 has files\n",
      "results/T/2/Base/checkpoint/1300 has files\n",
      "results/T/2/Base/checkpoint/1750 has files\n",
      "results/T/2/Base/checkpoint/2200 has files\n",
      "results/T/2/Base/checkpoint/2650 has files\n",
      "results/T/2/Base/checkpoint/2900 has files\n",
      "results/T/2/Base/checkpoint/3250 has files\n",
      "results/T/2/Base/checkpoint/2050 has files\n",
      "results/T/2/Base/checkpoint/3100 has files\n",
      "results/T/2/Base/checkpoint/2350 has files\n",
      "results/T/2/Base/checkpoint/3000 has files\n",
      "results/T/2/Base/checkpoint/2000 has files\n",
      "results/T/2/Base/checkpoint/1850 has files\n",
      "results/T/2/Base/checkpoint/550 has files\n",
      "results/T/2/Base/checkpoint/3500 has files\n",
      "results/T/2/Base/checkpoint/1250 has files\n",
      "results/T/2/Base/checkpoint/1550 has files\n",
      "results/T/2/Base/checkpoint/800 has files\n",
      "results/T/2/Base/checkpoint/3600 has files\n",
      "results/T/2/Base/checkpoint/1400 has files\n",
      "results/T/2/Base/checkpoint/1650 has files\n",
      "results/T/2/Base/checkpoint/1900 has files\n",
      "results/T/2/Base/checkpoint/1200 has files\n",
      "results/T/2/Base/checkpoint/850 has files\n",
      "results/T/2/Base/checkpoint/3300 has files\n",
      "results/T/2/Base/checkpoint/1700 has files\n",
      "results/T/2/Base/checkpoint/2750 has files\n",
      "results/T/2/Base/checkpoint/150 has files\n",
      "results/T/2/Base/checkpoint/750 has files\n",
      "results/T/2/Base/checkpoint/3150 has files\n",
      "results/T/2/Base/checkpoint/2700 has files\n",
      "results/T/2/Base/checkpoint/2500 has files\n",
      "results/T/2/Base/checkpoint/3650 has files\n",
      "results/T/2/Base/checkpoint/2400 has files\n",
      "results/T/2/Base/checkpoint/650 has files\n",
      "results/T/2/Base/checkpoint/2850 has files\n",
      "results/T/2/Base/checkpoint/2600 has files\n",
      "results/T/2/Base/checkpoint/2950 has files\n",
      "results/T/2/Base/checkpoint/350 has files\n",
      "results/T/2/Base/checkpoint/250 has files\n",
      "results/T/2/Base/checkpoint/3450 has files\n",
      "results/T/2/Base/checkpoint/1050 has files\n",
      "results/T/2/Base/checkpoint/2450 has files\n",
      "results/T/2/Base/checkpoint/1100 has files\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "#Check if starting from checkpoint\n",
    "###########\n",
    "\n",
    "checkdirs = []\n",
    "for dirpath, dirnames, files in os.walk(checkpointPath):\n",
    "    if files:\n",
    "        print dirpath, 'has files'\n",
    "        checkpointLoad = True\n",
    "        checkdirs.append(dirpath)\n",
    "    if not files:\n",
    "        print dirpath, 'is empty'\n",
    "        checkpointLoad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup parameters\n",
    "-----\n",
    "\n",
    "Set simulation parameters for test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use pint to setup any unit conversions we'll need**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#u = pint.UnitRegistry()\n",
    "#cmpery = u.cm/u.year\n",
    "#mpermy = u.m/u.megayear\n",
    "\n",
    "#cmpery.to(mpermy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set parameter dictionaries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dimensional parameter dictionary\n",
    "dp = edict({'LS':2900.*1e3,\n",
    "           'rho':3300,\n",
    "           'g':9.8, \n",
    "           #'eta0':1e21,    #This will give Ra ~ 2e7, closer to models by Van Hunen, Billen etc.\n",
    "           'eta0': 2.12e22, #This will give Ra = 1e6 as quoted on Korenaga's paper\n",
    "           'k':1e-6,\n",
    "           'a':2e-5, \n",
    "           'deltaT':1350, #Hunen\n",
    "           'TS':273.,\n",
    "           'cohesion':21e6,\n",
    "           'fc':0.02,\n",
    "           'E':240000.,\n",
    "           'R':8.314})\n",
    "\n",
    "dp['TI'] = dp.TS + dp.deltaT\n",
    "\n",
    "\n",
    "#scale_factors\n",
    "\n",
    "sf = edict({'stress':dp.LS**2/(dp.k*dp.eta0),\n",
    "            'lith_grad':dp.rho*dp.g*(dp.LS)**3/(dp.eta0*dp.k) ,\n",
    "            'vel':dp.LS/dp.k,\n",
    "            'SR':dp.LS**2/dp.k,\n",
    "            'W':(dp.rho*dp.g*dp.LS)/(dp.R*dp.deltaT), #This is the activation energy scale, in terms of depth (not pressure)\n",
    "            'E': 1./(dp.R*dp.deltaT)})\n",
    "\n",
    "#dimensionless parameters\n",
    "\n",
    "\n",
    "ndp = edict({'RA':(dp.g*dp.rho*dp.a*dp.deltaT*(dp.LS)**3)/(dp.k*dp.eta0),\n",
    "            'cohesion':dp.cohesion*sf.stress,\n",
    "            'fcd':dp.fc*sf.lith_grad,\n",
    "            'gamma':dp.fc/(dp.a*dp.deltaT),\n",
    "            'E':dp.E*sf.E,\n",
    "            'TSP':0., \n",
    "            'TIP':1.,\n",
    "            'n':1.,\n",
    "            'TS':dp.TS/dp.deltaT,\n",
    "            'TI':dp.TI/dp.deltaT,\n",
    "            'eta_min':1e-3,\n",
    "            'eta_max':1e5,\n",
    "            'H':20.,\n",
    "            'Tmvp':0.6})\n",
    "\n",
    "\n",
    "\n",
    "#ndp.RA = 1e6 #this is what Korenaga sets it to\n",
    "\n",
    "dp.VR = (0.1*(dp.k/dp.LS)*ndp.RA**(2/3.)) #characteristic velocity\n",
    "dp.SR = dp.VR/dp.LS #characteristic strain rate\n",
    "\n",
    "ndp.VR = dp.VR*sf.vel #characteristic velocity\n",
    "ndp.SR = dp.SR*sf.SR #characteristic strain rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1004527.6896226417"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(dp.g*dp.rho*dp.a*dp.deltaT*(dp.LS)**3)/(dp.k*1e6)\n",
    "ndp.RA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hDim = 5.44e-12 #crameri and tackley\n",
    "#hDim = 2.47e-11 #Turcott and Schubert\n",
    "#tc = 3\n",
    "#Ts = (dp.rho*hDim*dp.LS**2)/tc\n",
    "\n",
    "#RAh = Ts*(dp.a*dp.g*dp.rho*(dp.LS**3))/(dp.k*dp.eta0)\n",
    "#print(Ts, RAh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#A few parameters defining lengths scales, affects materal transistions etc.\n",
    "MANTLETOCRUST = (20.*1e3)/dp.LS #Crust depth\n",
    "CRUSTTOMANTLE = (900.*1e3)/dp.LS \n",
    "LITHTOMANTLE = (900.*1e3)/dp.LS \n",
    "MANTLETOLITH = (200.*1e3)/dp.LS \n",
    "TOPOHEIGHT = (0.*1e3)/dp.LS  #rock-air topography limits\n",
    "CRUSTTOECL  = (100.*1e3)/dp.LS\n",
    "AVGTEMP = ndp.TIP #Used to define lithosphere\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setup parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Model setup parameters\n",
    "###########\n",
    "\n",
    "refineMesh = False\n",
    "stickyAir = False \n",
    "arrhenius = False\n",
    "lower_mantle = False\n",
    "melt_viscosity_reduction= False\n",
    "\n",
    "\n",
    "\n",
    "MINX = -2.\n",
    "MINY = 0.\n",
    "MAXX = 2.\n",
    "\n",
    "#MAXY = 1.035\n",
    "MAXY = 1.\n",
    "\n",
    "if MINX == 0.:\n",
    "    squareModel = True\n",
    "else: \n",
    "    squareModel = False\n",
    "    \n",
    "    \n",
    "dim = 2          # number of spatial dimensions\n",
    "\n",
    "\n",
    "#MESH STUFF\n",
    "\n",
    "RES = 92\n",
    "\n",
    "\n",
    "Xres = int(RES*4)\n",
    "\n",
    "\n",
    "if stickyAir:\n",
    "    Yres = RES\n",
    "    MAXY = 1. + dp.StALS/dp.LS #150km\n",
    "    \n",
    "else:\n",
    "    Yres = RES\n",
    "    MAXY = 1.\n",
    "\n",
    "\n",
    "periodic = [True, False]\n",
    "#elementType = \"Q1/dQ0\"\n",
    "elementType =\"Q2/DPC1\"\n",
    "\n",
    "\n",
    "#System/Solver stuff\n",
    "\n",
    "PIC_integration=True\n",
    "ppc = 25\n",
    "\n",
    "#Output and safety stuff\n",
    "\n",
    "swarm_repop, swarm_update = 10, 10\n",
    "gldbs_output = 50\n",
    "checkpoint_every, files_output = 50, 50\n",
    "metric_output = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create mesh and finite element variables\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mesh = uw.mesh.FeMesh_Cartesian( elementType = (\"Q1/dQ0\"),\n",
    "                                 elementRes  = (Xres, Yres), \n",
    "                                 minCoord    = (MINX, MINY), \n",
    "                                 maxCoord    = (MAXX, MAXY))\n",
    "velocityField       = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=2 )\n",
    "pressureField       = uw.mesh.MeshVariable( mesh=mesh.subMesh, nodeDofCount=1 )\n",
    "temperatureField    = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=1 )\n",
    "temperatureDotField = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial conditions\n",
    "-------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot initial temperature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coordinate = fn.input()\n",
    "depthFn = 1. - coordinate[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not checkpointLoad:\n",
    "    # Setup temperature initial condition via numpy arrays\n",
    "    A = 0.2\n",
    "    #Note that width = height = 1\n",
    "    pertCoeff = depthFn + A*(fn.math.cos( math.pi * coordinate[0])  * fn.math.sin( math.pi * coordinate[1] ))        \n",
    "    temperatureField.data[:] = pertCoeff.evaluate(mesh)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not checkpointLoad:\n",
    "    random_temp_fac = 0.05\n",
    "    for index, coord in enumerate(mesh.data):\n",
    "        pertCoeff = (random_temp_fac *(np.random.rand(1)[0] - 0.5)) #this should create values between [-0.5,0.5] from uniform dist.\n",
    "        temperatureField.data[index] += pertCoeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test.gldb'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figtemp = glucifer.Figure()\n",
    "figtemp.append( glucifer.objects.Surface(mesh, temperatureField) )\n",
    "\n",
    "#figtemp.show()\n",
    "figtemp.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boundary conditions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index in mesh.specialSets[\"MinJ_VertexSet\"]:\n",
    "    temperatureField.data[index] = ndp.TIP\n",
    "for index in mesh.specialSets[\"MaxJ_VertexSet\"]:\n",
    "    temperatureField.data[index] = ndp.TSP\n",
    "    \n",
    "iWalls = mesh.specialSets[\"MinI_VertexSet\"] + mesh.specialSets[\"MaxI_VertexSet\"]\n",
    "jWalls = mesh.specialSets[\"MinJ_VertexSet\"] + mesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "tWalls = mesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "bWalls =mesh.specialSets[\"MinJ_VertexSet\"]\n",
    "\n",
    "\n",
    "freeslipBC = uw.conditions.DirichletCondition( variable      = velocityField, \n",
    "                                               indexSetsPerDof = ( iWalls, jWalls) )\n",
    "# also set dirichlet for temp field\n",
    "dirichTempBC = uw.conditions.DirichletCondition(     variable=temperatureField, \n",
    "                                              indexSetsPerDof=(tWalls,) )\n",
    "dT_dy = [0.,0.]\n",
    "\n",
    "# also set dirichlet for temp field\n",
    "neumannTempBC = uw.conditions.NeumannCondition( dT_dy, variable=temperatureField, \n",
    "                                         nodeIndexSet=bWalls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Particles\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Material Swarm and variables\n",
    "###########\n",
    "\n",
    "\n",
    "gSwarm = uw.swarm.Swarm(mesh=mesh, particleEscape=True)\n",
    "\n",
    "yieldingCheck = gSwarm.add_variable( dataType=\"int\", count=1 )\n",
    "tracerVariable = gSwarm.add_variable( dataType=\"int\", count=1)\n",
    "materialVariable = gSwarm.add_variable( dataType=\"int\", count=1 )\n",
    "timeVariable = gSwarm.add_variable( dataType=\"float\", count=1 )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "varlist = [tracerVariable, tracerVariable, yieldingCheck]\n",
    "\n",
    "varlist = [materialVariable, yieldingCheck, timeVariable]\n",
    "varnames = ['materialVariable', 'yieldingCheck', 'timeVariable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mantleIndex = 0\n",
    "lithosphereIndex = 1\n",
    "crustIndex = 2\n",
    "eclIndex = 3\n",
    "\n",
    "\n",
    "if checkpointLoad:\n",
    "    checkpointLoadDir = natsort.natsorted(checkdirs)[-1]\n",
    "    temperatureField.load(os.path.join(checkpointLoadDir, \"temperatureField\" + \".hdf5\"))\n",
    "    pressureField.load(os.path.join(checkpointLoadDir, \"pressureField\" + \".hdf5\"))\n",
    "    velocityField.load(os.path.join(checkpointLoadDir, \"velocityField\" + \".hdf5\"))\n",
    "    gSwarm.load(os.path.join(checkpointLoadDir, \"swarm\" + \".h5\"))\n",
    "    for ix in range(len(varlist)):\n",
    "        varb = varlist[ix]\n",
    "        varb.load(os.path.join(checkpointLoadDir,varnames[ix] + \".h5\"))\n",
    "\n",
    "else:\n",
    "\n",
    "    # Layouts are used to populate the swarm across the whole domain\n",
    "    # Create the layout object\n",
    "    layout = uw.swarm.layouts.PerCellRandomLayout(swarm=gSwarm, particlesPerCell=ppc)\n",
    "    # Now use it to populate.\n",
    "    gSwarm.populate_using_layout( layout=layout )\n",
    "\n",
    "    # Swarm variables\n",
    "    materialVariable.data[:] = mantleIndex\n",
    "    tracerVariable.data[:] = 1\n",
    "    yieldingCheck.data[:] = 0\n",
    "    timeVariable.data[:] = 0.\n",
    "    \n",
    "    #Set initial air and crust materials (allow the graph to take care of lithsophere)\n",
    "    #########\n",
    "    #This initial material setup will be model dependent\n",
    "    #########\n",
    "    for particleID in range(gSwarm.particleCoordinates.data.shape[0]):\n",
    "        if (1. - gSwarm.particleCoordinates.data[particleID][1]) < MANTLETOCRUST:\n",
    "                 materialVariable.data[particleID] = crustIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Passive tracer layout**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Passive tracers are not included in checkpoint - Probably best to remove this once models are properly bugchecked\n",
    "\n",
    "square_size = 0.1\n",
    "\n",
    "xlist = np.arange(mesh.minCoord[0] + square_size/2., mesh.maxCoord[0] + square_size/2., square_size)\n",
    "xlist = zip(xlist[:], xlist[1:])[::2]\n",
    "ylist = np.arange(mesh.minCoord[1] + square_size/2., mesh.maxCoord[1] + square_size/2., square_size)\n",
    "ylist = zip(ylist[:], ylist[1:])[::2]\n",
    "xops = []\n",
    "for vals in xlist:\n",
    "    xops.append( (operator.and_(   operator.gt(coordinate[0],vals[0]),   operator.lt(coordinate[0],vals[1])  ),0.) )\n",
    "xops.append((True,1.))\n",
    "\n",
    "testfunc = fn.branching.conditional(xops) \n",
    "\n",
    "yops = []\n",
    "for vals in ylist:\n",
    "    yops.append( (operator.and_(   operator.gt(coordinate[1],vals[0]),   operator.lt(coordinate[1],vals[1])  ),0.) )\n",
    "yops.append((True,testfunc))\n",
    "\n",
    "testfunc2 = fn.branching.conditional(yops) \n",
    "\n",
    "tracerVariable.data[:] = testfunc.evaluate(gSwarm)\n",
    "tracerVariable.data[:] = testfunc2.evaluate(gSwarm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Material swarm and graphs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "##############\n",
    "#Important: This is a quick fix for a bug that arises in parallel runs\n",
    "##############\n",
    "material_list = [0,1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#All depth conditions are given as (km/D) where D is the length scale,\n",
    "#note that 'model depths' are used, e.g. 1-z, where z is the vertical Underworld coordinate\n",
    "#All temp conditions are in dimensionless temp. [0. - 1.]\n",
    "\n",
    "materialVariable.data[:] = 0\n",
    "\n",
    "#######Graph object\n",
    "#DG = nx.DiGraph(field=\"Depth\")\n",
    "DG = material_graph.MatGraph()\n",
    "\n",
    "#Important: First thing to do is to add all the material types to the graph (i.e add nodes)\n",
    "DG.add_nodes_from(material_list)\n",
    "\n",
    "\n",
    "#Anything to mantle\n",
    "DG.add_transition((crustIndex,mantleIndex), depthFn, operator.gt, CRUSTTOMANTLE)\n",
    "\n",
    "#Anything to crust\n",
    "DG.add_transition((mantleIndex,crustIndex), depthFn, operator.lt, MANTLETOCRUST)\n",
    "\n",
    "#Anything to lithsphere\n",
    "#DG.add_transition((mantleIndex,lithosphereIndex), depthFn, operator.lt, MANTLETOLITH)\n",
    "#DG.add_transition((mantleIndex,lithosphereIndex), temperatureField, operator.lt, 0.85*AVGTEMP)\n",
    "\n",
    "\n",
    "#crust to eclogite\n",
    "#DG.add_edges_from([(3,2)])\n",
    "#DG[3][2]['depthcondition'] =CRUSTTOECL\n",
    "#DG.add_transition((3,2), depthFn, operator.gt, CRUSTTOECL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dummyData = np.copy(materialVariable.data)#This is part of a hack that resets ages when a material type changes\n",
    "\n",
    "DG.build_condition_list(materialVariable)\n",
    "for i in range(2): #Need to go through twice first time through\n",
    "    materialVariable.data[:] = fn.branching.conditional(DG.condition_list).evaluate(gSwarm)\n",
    "    \n",
    "#timeVariable.data[np.where(dummyData[:] != materialVariable.data[:])] = 0. #resets those ages when a material type change\n",
    "#np.unique(timeVariable.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig= glucifer.Figure()\n",
    "#fig.append( glucifer.objects.Points(gSwarm,tracerVariable, colours= 'white black'))\n",
    "fig.append( glucifer.objects.Points(gSwarm,materialVariable))\n",
    "#fig.append( glucifer.objects.Surface(mesh, dummyField))\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up material parameters and functions\n",
    "-----\n",
    "\n",
    "Setup the viscosity to be a function of the temperature. Recall that these functions and values are preserved for the entire simulation time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14.794420225563012, 0.7407407407407407)\n"
     ]
    }
   ],
   "source": [
    "# The yeilding of the upper slab is dependent on the strain rate.\n",
    "strainRate_2ndInvariant = fn.tensor.second_invariant( \n",
    "                            fn.tensor.symmetric( \n",
    "                            velocityField.fn_gradient ))\n",
    "\n",
    "\n",
    "theta = (dp.E *dp.deltaT)/(dp.R*(dp.TS + dp.deltaT)**2)\n",
    "\n",
    "gamma = dp.fc/(dp.a*dp.deltaT)\n",
    "print(theta, gamma )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#overide these parameters to match the reference case quoted on page 5\n",
    "theta = 15.\n",
    "gamma = 0.6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ndp.E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############\n",
    "#Rheology\n",
    "#############\n",
    "#\n",
    "#The final mantle rheology is composed as follows*:\n",
    "# \n",
    "#\n",
    "# mantleviscosityFn = max{  min{(1/omega*nonlinearVisc + 1/eta_p)**-1,\n",
    "#                           eta_max},\n",
    "#                           eta_min}\n",
    "#                      \n",
    "#nonlinearVisc => FK viscosity (could be linear or non linear)\n",
    "#eta_p   => stress-limiting effective viscosity\n",
    "#\n",
    "\n",
    "\n",
    "omega = fn.misc.constant(1.)\n",
    "\n",
    "if melt_viscosity_reduction:\n",
    "    mvr =  fn.branching.conditional( [ (temperatureField > (ndp.Tmvp + 7.5*(1. - coordinate[1])) , 0.1 ),   (         True, 1.) ] )\n",
    "    omega = omega*mvr\n",
    "\n",
    "\n",
    "#implementation of the lower mantle viscosity increase, similar to Bello et al. 2015\n",
    "a = 1.\n",
    "B = 30.\n",
    "d0 = 660e3/dp.LS  \n",
    "ds = d0/10.\n",
    "if lower_mantle:\n",
    "    inner1 = 1. - 0.5*(1. - fn.math.tanh(((1. - d0)-(coordinate[1]))/(ds)))\n",
    "    modfac = a*fn.math.exp(np.log(B)*inner1)\n",
    "    omega = omega*modfac\n",
    "\n",
    "\n",
    "\n",
    "linearVisc = fn.math.exp(theta*(1. - temperatureField))\n",
    "nl_correction = (strainRate_2ndInvariant/ndp.SR)**((1.-ndp.n)/(ndp.n))\n",
    "nonlinearVisc = omega*nl_correction*linearVisc\n",
    "if arrhenius:\n",
    "    nonlinearVisc = fn.misc.min(ndp.eta_max, omega*fn.math.exp(((ndp.E)/(ndp.n*(temperatureField + ndp.TS))) \n",
    "                                                        - ((ndp.E )/(ndp.n*(ndp.TIP + ndp.TS)))))\n",
    "\n",
    "ys =  (gamma*ndp.RA*1e-5) + (depthFn*gamma*ndp.RA) #tau_1 * 1e-5 is the cohesion value used in the paper\n",
    "if arrhenius:\n",
    "    ys =  ndp.cohesion + (depthFn*gamma*ndp.RA) #In this case we'll use a more standard cohesion\n",
    "yielding = ys/(strainRate_2ndInvariant/math.sqrt(0.5)) #extra factor to account for underworld second invariant form\n",
    "\n",
    "\n",
    "mantleviscosityFn = fn.misc.max(fn.misc.min(1./(((1./nonlinearVisc) + (1./yielding))), ndp.eta_max), ndp.eta_min)\n",
    "\n",
    "\n",
    "##Crust rheology\n",
    "ysc = ys\n",
    "#ysc = ys*0.1\n",
    "crust_yielding = ys/(strainRate_2ndInvariant/math.sqrt(0.5)) #extra factor to account for underworld second invariant form\n",
    "crustviscosityFn = fn.misc.max(fn.misc.min(1./(((1./nonlinearVisc) + (1./crust_yielding))), ndp.eta_max), ndp.eta_min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the initial viscosity**\n",
    "\n",
    "Plot the viscosity, which is a function of temperature, using the initial temperature conditions set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figEta = glucifer.Figure()\n",
    "figEta.append( glucifer.objects.Surface(mesh, mantleviscosityFn, logScale=True) )\n",
    "#figEta.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1004527.6896226417"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndp.RA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System setup\n",
    "-----\n",
    "\n",
    "Since we are using a previously constructed temperature field, we will use a single Stokes solve to get consistent velocity and pressure fields.\n",
    "\n",
    "**Setup a Stokes system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here we set a viscosity value of '1.' for both materials\n",
    "viscosityMapFn = fn.branching.map( fn_key = materialVariable,\n",
    "                         mapping = {lithosphereIndex:mantleviscosityFn, \n",
    "                                    crustIndex:crustviscosityFn,\n",
    "                                    mantleIndex:mantleviscosityFn, \n",
    "                                    eclIndex:mantleviscosityFn} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct our density function.\n",
    "densityFn = ndp.RA * temperatureField\n",
    "\n",
    "# Define our vertical unit vector using a python tuple (this will be automatically converted to a function).\n",
    "gravity = ( 0.0, 1.0 )\n",
    "\n",
    "# Now create a buoyancy force vector using the density and the vertical unit vector. \n",
    "buoyancyFn = densityFn * gravity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stokesPIC = uw.systems.Stokes(velocityField=velocityField, \n",
    "                              pressureField=pressureField,\n",
    "                              conditions=[freeslipBC,],\n",
    "                              fn_viscosity=linearVisc, \n",
    "                              fn_bodyforce=buoyancyFn )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set up and solve the Stokes system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solver = uw.systems.Solver(stokesPIC)\n",
    "solver.solve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add the non-linear viscosity to the Stokes system**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stokesPIC.fn_viscosity = viscosityMapFn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m\n",
      " \n",
      "Pressure iterations:   3\n",
      "Velocity iterations:   1 (presolve)      \n",
      "Velocity iterations:  -1 (pressure solve)\n",
      "Velocity iterations:   1 (backsolve)     \n",
      "Velocity iterations:   1 (total solve)   \n",
      " \n",
      "SCR RHS  solve time: 7.9431e-01\n",
      "Pressure solve time: 1.0783e-01\n",
      "Velocity solve time: 8.3108e-01 (backsolve)\n",
      "Total solve time   : 1.8745e+00\n",
      " \n",
      "Velocity solution min/max: 0.0000e+00/0.0000e+00\n",
      "Pressure solution min/max: 0.0000e+00/0.0000e+00\n",
      " \n",
      "\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "solver.set_inner_method(\"mumps\")\n",
    "solver.options.scr.ksp_type=\"cg\"\n",
    "solver.set_penalty(1.0e7)\n",
    "solver.options.scr.ksp_rtol = 1.0e-4\n",
    "solver.solve(nonLinearIterate=True)\n",
    "solver.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create an advective diffusive system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "advDiff = uw.systems.AdvectionDiffusion( phiField       = temperatureField, \n",
    "                                         phiDotField    = temperatureDotField, \n",
    "                                         velocityField  = velocityField,\n",
    "                                         fn_sourceTerm    = 20.0,\n",
    "                                         fn_diffusivity = 1.0, \n",
    "                                         conditions     = [neumannTempBC, dirichTempBC] )\n",
    "\n",
    "passiveadvector = uw.systems.SwarmAdvector( swarm         = gSwarm, \n",
    "                                     velocityField = velocityField, \n",
    "                                     order         = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "population_control = uw.swarm.PopulationControl(gSwarm,deleteThreshold=0.2,splitThreshold=1.,maxDeletions=3,maxSplits=0, aggressive=True, particlesPerCell=ppc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis tools\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#These are functions we can use to evuate integrals over restricted parts of the domain\n",
    "# For instance, we can exclude the thermal lithosphere from integrals\n",
    "\n",
    "def temprestrictionFn(lithval = 0.9):\n",
    "\n",
    "    tempMM = fn.view.min_max(temperatureField)\n",
    "    tempMM.evaluate(mesh)\n",
    "    TMAX = tempMM.max_global()\n",
    "    mantleconditions = [ (                                  temperatureField > lithval*TMAX, 1.),\n",
    "                   (                                                   True , 0.) ]\n",
    "\n",
    "\n",
    "    return fn.branching.conditional(mantleconditions)\n",
    "\n",
    "mantlerestrictFn = temprestrictionFn()\n",
    "\n",
    "\n",
    "\n",
    "def platenessFn(val = 0.1):\n",
    "    normgradV = velocityField.fn_gradient[0]/fn.math.sqrt(velocityField[0]*velocityField[0]) #[du*/dx]/sqrt(u*u)\n",
    "\n",
    "\n",
    "\n",
    "    srconditions = [ (                                  normgradV < val, 1.),\n",
    "                   (                                                   True , 0.) ]\n",
    "\n",
    "\n",
    "    return fn.branching.conditional(srconditions)\n",
    "\n",
    "srrestrictFn = platenessFn(val = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setup volume integrals \n",
    "\n",
    "tempint = uw.utils.Integral( temperatureField, mesh )\n",
    "areaint = uw.utils.Integral( 1.,               mesh )\n",
    "\n",
    "v2int   = uw.utils.Integral( fn.math.dot(velocityField,velocityField), mesh )\n",
    "\n",
    "dwint   = uw.utils.Integral( temperatureField*velocityField[1], mesh )\n",
    "\n",
    "sinner = fn.math.dot( strainRate_2ndInvariant, strainRate_2ndInvariant )\n",
    "vdint = uw.utils.Integral( (4.*viscosityMapFn*sinner), mesh )\n",
    "\n",
    "mantleArea   = uw.utils.Integral( mantlerestrictFn, mesh )\n",
    "mantleTemp = uw.utils.Integral( temperatureField*mantlerestrictFn, mesh )\n",
    "mantleVisc = uw.utils.Integral( mantleviscosityFn*mantlerestrictFn, mesh )\n",
    "mantleVd = uw.utils.Integral( (4.*viscosityMapFn*sinner*mantlerestrictFn), mesh ) #these now work on MappingFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setup surface integrals\n",
    "\n",
    "rmsSurfInt = uw.utils.Integral( fn=velocityField[0]*velocityField[0], mesh=mesh, integrationType='Surface', \n",
    "                          surfaceIndexSet=mesh.specialSets[\"MaxJ_VertexSet\"])\n",
    "nuTop      = uw.utils.Integral( fn=temperatureField.fn_gradient[1],    mesh=mesh, integrationType='Surface', \n",
    "                          surfaceIndexSet=mesh.specialSets[\"MaxJ_VertexSet\"])\n",
    "nuBottom   = uw.utils.Integral( fn=temperatureField.fn_gradient[1],    mesh=mesh, integrationType='Surface', \n",
    "                          surfaceIndexSet=mesh.specialSets[\"MinJ_VertexSet\"])\n",
    "\n",
    "plateint  = uw.utils.Integral( fn=srrestrictFn, mesh=mesh, integrationType='Surface', #Integrate the plateness function\n",
    "                          surfaceIndexSet=mesh.specialSets[\"MaxJ_VertexSet\"]) \n",
    "\n",
    "surfint  = uw.utils.Integral( fn=1., mesh=mesh, integrationType='Surface',   #Surface length function (i.e. domain width)\n",
    "                          surfaceIndexSet=mesh.specialSets[\"MaxJ_VertexSet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define functions for the evaluation of integrals\n",
    "\n",
    "def basic_int(ourIntegral):           #This one just hands back the evaluated integral\n",
    "    return ourIntegral.evaluate()[0]\n",
    "\n",
    "def avg_temp():\n",
    "    return tempint.evaluate()[0]/areaint.evaluate()[0]\n",
    "\n",
    "def nusseltTB(temp_field, mesh):\n",
    "    return -nuTop.evaluate()[0], -nuBottom.evaluate()[0]\n",
    "\n",
    "def rms():\n",
    "    return math.sqrt(v2int.evaluate()[0]/areaint.evaluate()[0])\n",
    "\n",
    "def rms_surf():\n",
    "    return math.sqrt(rmsSurfInt.evaluate()[0])\n",
    "\n",
    "def max_vx_surf(velfield, mesh):\n",
    "    vuvelxfn = fn.view.min_max(velfield[0])\n",
    "    vuvelxfn.evaluate(mesh.specialSets[\"MaxJ_VertexSet\"])\n",
    "    return vuvelxfn.max_global()\n",
    "\n",
    "\n",
    "def visc_extr(viscfn):\n",
    "    vuviscfn = fn.view.min_max(viscfn)\n",
    "    vuviscfn.evaluate(mesh)\n",
    "    return vuviscfn.max_global(), vuviscfn.min_global()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#v2sum_integral  = uw.utils.Integral( mesh=mesh, fn=fn.math.dot( velocityField, velocityField ) )\n",
    "#volume_integral = uw.utils.Integral( mesh=mesh, fn=1. )\n",
    "#Vrms = math.sqrt( v2sum_integral.evaluate()[0] )/volume_integral.evaluate()[0]\n",
    "\n",
    "\n",
    "\n",
    "#if(uw.rank()==0):\n",
    "#    print('Initial Vrms = {0:.3f}'.format(Vrms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check the Metrics\n",
    "\n",
    "#Avg_temp = avg_temp()\n",
    "#Rms = rms()\n",
    "#Rms_surf = rms_surf()\n",
    "#Max_vx_surf = max_vx_surf(velocityField, mesh)\n",
    "#Gravwork = basic_int(dwint)\n",
    "#Viscdis = basic_int(vdint)\n",
    "#nu1, nu0 = nusseltTB(temperatureField, mesh) # return top then bottom\n",
    "#etamax, etamin = visc_extr(mantleviscosityFn)\n",
    "\n",
    "#Area_mantle = basic_int(mantleArea)\n",
    "#Viscmantle = basic_int(mantleVisc)\n",
    "#Tempmantle = basic_int(mantleTemp)\n",
    "#Viscdismantle = basic_int(mantleVd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.02904435202995, 0.6934461863496111)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tempmantle/Area_mantle, Viscmantle/Area_mantle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viz.\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tracerVariable.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Pack some stuff into a database as well\n",
    "figDb = glucifer.Figure()\n",
    "#figDb.append( glucifer.objects.Mesh(mesh))\n",
    "figDb.append( glucifer.objects.VectorArrows(mesh,velocityField, scaling=0.0005))\n",
    "figDb.append( glucifer.objects.Points(gSwarm,tracerVariable, colours= 'white black'))\n",
    "figDb.append( glucifer.objects.Surface(mesh, mantleviscosityFn, logScale=True))\n",
    "figDb.append( glucifer.objects.Surface(mesh, temperatureField))\n",
    "#figDb.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def checkpoint1(step, checkpointPath,filename, filewrites):\n",
    "    path = checkpointPath + str(step) \n",
    "    os.mkdir(path)\n",
    "    ##Write and save the file, if not already a writing step\n",
    "    if not step % filewrites == 0:\n",
    "        filename.write((17*'%-15s ' + '\\n') % (realtime, Viscdis, float(nu0), float(nu1), Avg_temp,\n",
    "                                              Tempmantle,TMAX,\n",
    "                                              Rms,Rms_surf,Max_vx_surf,Gravwork, etamax, etamin, \n",
    "                                              Area_mantle, Viscmantle,  Viscdismantle,Plateness ))\n",
    "    filename.close()\n",
    "    shutil.copyfile(os.path.join(outputPath, outputFile), os.path.join(path, outputFile))\n",
    "\n",
    "\n",
    "def checkpoint2(step, checkpointPath, swarm, filename, varlist = [materialVariable], varnames = ['materialVariable']):\n",
    "    path = checkpointPath + str(step) \n",
    "    velfile = \"velocityField\" + \".hdf5\"\n",
    "    tempfile = \"temperatureField\" + \".hdf5\"\n",
    "    pressfile = \"pressureField\" + \".hdf5\"\n",
    "    velocityField.save(os.path.join(path, velfile))\n",
    "    temperatureField.save(os.path.join(path, tempfile))\n",
    "    pressureField.save(os.path.join(path, pressfile))\n",
    "    swarm.save(os.path.join(path, \"swarm.h5\") ) \n",
    "    for ix in range(len(varlist)):\n",
    "        varb = varlist[ix]\n",
    "        varb.save(os.path.join(path,varnames[ix] + \".h5\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Miscellania**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "surface_xs = np.linspace(mesh.minCoord[0], mesh.maxCoord[0], mesh.elementRes[0] + 1)\n",
    "surface_nodes = np.array(zip(surface_xs, np.ones(len(surface_xs)*mesh.maxCoord[1]))) #For evaluation surface velocity\n",
    "\n",
    "\n",
    "normgradV = velocityField.fn_gradient[0]/fn.math.sqrt(velocityField[0]*velocityField[0])\n",
    "\n",
    "tempMM = fn.view.min_max(temperatureField)\n",
    "dummy = tempMM.evaluate(mesh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0890113793298568, 1.0890113793298568)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempMM.max_global(), temperatureField.data.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main simulation loop\n",
    "-----\n",
    "\n",
    "Run a few advection and Stokes solver steps to make sure we are in, or close to, equilibrium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialise timer for computation\n",
    "start = time.clock()\n",
    "# setup summary output file (name above)\n",
    "if checkpointLoad:\n",
    "    if uw.rank() == 0:\n",
    "        shutil.copyfile(os.path.join(checkpointLoadDir, outputFile), outputPath+outputFile)\n",
    "    comm.Barrier()\n",
    "    f_o = open(os.path.join(outputPath, outputFile), 'a')\n",
    "    prevdata = np.genfromtxt(os.path.join(outputPath, outputFile), skip_header=0, skip_footer=0)\n",
    "    if len(prevdata.shape) == 1: #this is in case there is only one line in previous file\n",
    "        realtime = prevdata[0]\n",
    "    else:\n",
    "        realtime = prevdata[prevdata.shape[0]-1, 0]\n",
    "    step = int(checkpointLoadDir.split('/')[-1])\n",
    "    timevals = [0.]\n",
    "else:\n",
    "    f_o = open(outputPath+outputFile, 'w')\n",
    "    realtime = 0.\n",
    "    step = 0\n",
    "    timevals = [0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-459-ca241600c9cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             f_o.write((11*'%-15s ' + '\\n') % (realtime, Viscdis, float(nu0), float(nu1), Avg_temp, \n\u001b[0;32m---> 56\u001b[0;31m                                               Rms,Rms_surf,Max_vx_surf,Gravwork, etamax, etamin))\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;31m################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m#Also repopulate entire swarm periodically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file"
     ]
    }
   ],
   "source": [
    "#while step < 21:\n",
    "while realtime < 1.:\n",
    "\n",
    "    # solve Stokes and advection systems\n",
    "    solver.solve(nonLinearIterate=True)\n",
    "    dt = advDiff.get_max_dt()\n",
    "    if step == 0:\n",
    "        dt = 0.\n",
    "    advDiff.integrate(dt)\n",
    "    passiveadvector.integrate(dt)\n",
    "    \n",
    "\n",
    "    # Increment\n",
    "    realtime += dt\n",
    "    step += 1\n",
    "    timevals.append(realtime)\n",
    "    ################\n",
    "    #Gldb output\n",
    "    ################ \n",
    "    if (step % gldbs_output == 0):\n",
    "        #Rebuild any necessary swarm variables\n",
    "        #Write gldbs\n",
    "        fnamedb = \"dbFig\" + \"_\" + str(ModIt) + \"_\" + str(step) + \".gldb\"\n",
    "        fullpath = os.path.join(outputPath + \"gldbs/\" + fnamedb)\n",
    "        #figDb.show()\n",
    "        figDb.save_database(fullpath)\n",
    "    ################\n",
    "    #Files output\n",
    "    ################ \n",
    "    if (step % files_output == 0):\n",
    "\n",
    "        vel_surface = velocityField.evaluate_global(surface_nodes)\n",
    "        norm_surface_sr = normgradV.evaluate_global(surface_nodes)\n",
    "        if uw.rank() == 0:\n",
    "            fnametemp = \"velsurface\" + \"_\" + str(ModIt) + \"_\" + str(step)\n",
    "            fullpath = os.path.join(outputPath + \"files/\" + fnametemp)\n",
    "            np.save(fullpath, vel_surface)\n",
    "            fnametemp = \"norm_surface_sr\" + \"_\" + str(ModIt) + \"_\" + str(step)\n",
    "            fullpath = os.path.join(outputPath + \"files/\" + fnametemp)\n",
    "            np.save(fullpath, norm_surface_sr)\n",
    "    ################            \n",
    "    # Calculate the Metrics, only on 1 of the processors:\n",
    "    ################\n",
    "    if (step % metric_output == 0):\n",
    "        ###############\n",
    "        #Swarm - based Metrics\n",
    "        ###############\n",
    "        # Calculate the RMS velocity and Nusselt number.\n",
    "        # Calculate the Metrics, only on 1 of the processors:\n",
    "        mantlerestrictFn = temprestrictionFn() #rebuild the mantle restriction function (but these should be dynamic?)\n",
    "        srrestrictFn = platenessFn(val = 0.1) #rebuild the plateness restriction function\n",
    "        dummy = tempMM.evaluate(mesh) #Re-evaluate any fn.view.min_max guys\n",
    "        ###\n",
    "        Avg_temp = avg_temp()\n",
    "        Rms = rms()\n",
    "        Rms_surf = rms_surf()\n",
    "        Max_vx_surf = max_vx_surf(velocityField, mesh)\n",
    "        Gravwork = basic_int(dwint)\n",
    "        Viscdis = basic_int(vdint)\n",
    "        nu1, nu0 = nusseltTB(temperatureField, mesh) # return top then bottom\n",
    "        etamax, etamin = visc_extr(mantleviscosityFn)\n",
    "        Area_mantle = basic_int(mantleArea)\n",
    "        Viscmantle = basic_int(mantleVisc)\n",
    "        Tempmantle = basic_int(mantleTemp)\n",
    "        Viscdismantle = basic_int(mantleVd)\n",
    "        Plateness = basic_int(plateint)/basic_int(surfint)\n",
    "        TMAX = tempMM.max_global()\n",
    "        # output to summary text file\n",
    "        if uw.rank()==0:\n",
    "            f_o.write((17*'%-15s ' + '\\n') % (realtime, Viscdis, float(nu0), float(nu1), Avg_temp,\n",
    "                                              Tempmantle,TMAX,\n",
    "                                              Rms,Rms_surf,Max_vx_surf,Gravwork, etamax, etamin, \n",
    "                                              Area_mantle, Viscmantle,  Viscdismantle,Plateness ))\n",
    "    ################\n",
    "    #Also repopulate entire swarm periodically\n",
    "    ################\n",
    "    #if step % swarm_repop == 0:\n",
    "    population_control.repopulate()\n",
    "    \n",
    "    ################\n",
    "    #Checkpoint\n",
    "    ################\n",
    "    if step % checkpoint_every == 0:\n",
    "        if uw.rank() == 0:\n",
    "            checkpoint1(step, checkpointPath,f_o, metric_output)           \n",
    "        checkpoint2(step, checkpointPath, gSwarm, f_o, varlist = varlist, varnames = varnames)\n",
    "        f_o = open(os.path.join(outputPath, outputFile), 'a') #is this line supposed to be here?\n",
    "    ################\n",
    "    #Particle update\n",
    "    ###############\n",
    "    timeVariable.data[:] += dt #increment the ages (is this efficient?)\n",
    "    dummyData = np.copy(materialVariable.data)#This is part of a hack that resets ages when a material type changes\n",
    "    if step % swarm_update == 0:\n",
    "        for i in range(2): #Need to go through twice first time through\n",
    "            materialVariable.data[:] = fn.branching.conditional(DG.condition_list).evaluate(gSwarm)\n",
    "    timeVariable.data[np.where(dummyData[:] != materialVariable.data[:])] = 0. #resets those ages when a material type change\n",
    "    \n",
    "f_o.close()\n",
    "print 'step =',step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
