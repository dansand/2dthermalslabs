{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thermal subduction, linear rheology:\n",
    "\n",
    "\n",
    "The viscous rheology in this model is similar to the models described in the PhD thesis of Micheal Kaplan\n",
    "\n",
    "\n",
    "\n",
    "**Keywords:** subduction, thermally-activated creep, \n",
    "\n",
    "\n",
    "**References:**\n",
    "\n",
    "\n",
    "Kaplan, Michael. Numerical Geodynamics of Solid Planetary Deformation. Diss. University of Southern California, 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import underworld as uw\n",
    "import math\n",
    "from underworld import function as fn\n",
    "import glucifer\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import natsort\n",
    "import shutil\n",
    "from easydict import EasyDict as edict\n",
    "import operator\n",
    "import pint\n",
    "import time\n",
    "import operator\n",
    "from slippy2 import boundary_layer2d\n",
    "from slippy2 import material_graph\n",
    "from slippy2 import spmesh\n",
    "from slippy2 import phase_function\n",
    "\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model name and directories\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############\n",
    "#Model name.  \n",
    "############\n",
    "Model = \"T\"\n",
    "ModNum = 0\n",
    "\n",
    "if len(sys.argv) == 1:\n",
    "    ModIt = \"Base\"\n",
    "elif sys.argv[1] == '-f':\n",
    "    ModIt = \"Base\"\n",
    "else:\n",
    "    ModIt = str(sys.argv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Standard output directory setup\n",
    "###########\n",
    "\n",
    "\n",
    "outputPath = \"results\" + \"/\" +  str(Model) + \"/\" + str(ModNum) + \"/\" + str(ModIt) + \"/\"\n",
    "imagePath = outputPath + 'images/'\n",
    "filePath = outputPath + 'files/'\n",
    "checkpointPath = outputPath + 'checkpoint/'\n",
    "dbPath = outputPath + 'gldbs/'\n",
    "outputFile = 'results_model' + Model + '_' + str(ModNum) + '_' + str(ModIt) + '.dat'\n",
    "\n",
    "if uw.rank()==0:\n",
    "    # make directories if they don't exist\n",
    "    if not os.path.isdir(outputPath):\n",
    "        os.makedirs(outputPath)\n",
    "    if not os.path.isdir(checkpointPath):\n",
    "        os.makedirs(checkpointPath)\n",
    "    if not os.path.isdir(imagePath):\n",
    "        os.makedirs(imagePath)\n",
    "    if not os.path.isdir(dbPath):\n",
    "        os.makedirs(dbPath)\n",
    "    if not os.path.isdir(filePath):\n",
    "        os.makedirs(filePath)\n",
    "        \n",
    "comm.Barrier() #Barrier here so no procs run the check in the next cell too early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/T/0/Base/checkpoint/ is empty\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "#Check if starting from checkpoint\n",
    "###########\n",
    "\n",
    "checkdirs = []\n",
    "for dirpath, dirnames, files in os.walk(checkpointPath):\n",
    "    if files:\n",
    "        print dirpath, 'has files'\n",
    "        checkpointLoad = True\n",
    "        checkdirs.append(dirpath)\n",
    "    if not files:\n",
    "        print dirpath, 'is empty'\n",
    "        checkpointLoad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup parameters\n",
    "-----\n",
    "\n",
    "Set simulation parameters for test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use pint to setup any unit conversions we'll need**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "10000.0 meter/megayear"
      ],
      "text/latex": [
       "$10000.0 \\frac{meter}{megayear}$"
      ],
      "text/plain": [
       "<Quantity(10000.0, 'meter / megayear')>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = pint.UnitRegistry()\n",
    "cmpery = 1.*u.cm/u.year\n",
    "mpermy = 1.*u.m/u.megayear\n",
    "year = 1.*u.year\n",
    "spery = year.to(u.sec)\n",
    "cmpery.to(mpermy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.04, 1.2675505856327397e-11)\n"
     ]
    }
   ],
   "source": [
    "box_half_width =4000e3\n",
    "age_at_trench = 100e6\n",
    "cmperyear = box_half_width / age_at_trench #m/y\n",
    "mpersec = cmperyear*(cmpery.to(u.m/u.second)).magnitude #m/sec\n",
    "print(cmperyear, mpersec )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set parameter dictionaries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Store the physical parameters, scale factors and dimensionless pramters in easyDicts\n",
    "#Mainly helps with avoiding overwriting variables\n",
    "###########\n",
    "\n",
    "\n",
    "#Style => parameters_like_this\n",
    "\n",
    "dp = edict({'LS':670*1e3, #Scaling Length scale\n",
    "            'depth':670*1e3, #Depth of domain\n",
    "           'rho':3300.,  #reference density\n",
    "           'g':9.8, #surface gravity\n",
    "           'eta0':5e20, #\n",
    "           'k':1e-6, #thermal diffusivity\n",
    "           'a':3e-5, #surface thermal expansivity\n",
    "           'TP':1673., #mantle potential temp (K)\n",
    "           'TS':273., #surface temp (K)\n",
    "           'cohesion':40e6, #cohesion in scalar yield function\n",
    "           'fc':0.03,   #friction coefficient in yield function(tan(phi))\n",
    "           'Adf':3e-11, #pre-exp factor for diffusion creep\n",
    "           'Edf':1e5,\n",
    "           #'Vdf':4e-6,\n",
    "           #'Elm':2.0e5,\n",
    "           #'Vlm':1.1e-6,\n",
    "           #'SR':1e-15,\n",
    "           #'rDepth':250e3, #reference depth (used to scale / normalize the flow laws)\n",
    "           'R':8.314, #gas constant\n",
    "           #'Cp':1250., #Specific heat (Jkg-1K-1)\n",
    "           'StALS':100e3, #depth of sticky air layer\n",
    "           'plate_vel':4})\n",
    "\n",
    "#Adiabatic heating stuff\n",
    "#dp.dTa = (dp.a*dp.g*(dp.TP))/dp.Cp #adibatic gradient, at Tp\n",
    "#dp.deltaTa = (dp.TP + dp.dTa*dp.LS) - dp.TS  #Adiabatic Temp at base of mantle, minus Ts\n",
    "dp.deltaT = dp.TP - dp.TS\n",
    "#dp.rTemp= dp.TP + dp.rDepth*dp.dTa #reference temp, (potential temp + adiabat)\n",
    "\n",
    "\n",
    "#scale_factors\n",
    "\n",
    "sf = edict({'stress':dp.LS**2/(dp.k*dp.eta0),\n",
    "            'lith_grad':dp.rho*dp.g*(dp.LS)**3/(dp.eta0*dp.k) , \n",
    "            'vel':dp.LS/dp.k,\n",
    "            'SR':dp.LS**2/dp.k,\n",
    "            #'W':(-1./dp.Ba)*(np.log(1.-dp.rho*dp.g*dp.Ba*dp.LS))/(dp.R*dp.deltaTa), #Including adiabatic compression, and deltaTa\n",
    "            #'E': 1./(dp.R*dp.deltaT), #using deltaTa, the guesstimated adiabatic temp differnnce to scale these paramters\n",
    "            #'Ads':(dp.eta0**(ndp.n-2))*((dp.k)**(ndp.n-1))*((dp.LS)**(2. - 2*ndp.n))       \n",
    "           })\n",
    "\n",
    "#dimensionless parameters\n",
    "\n",
    "ndp = edict({'RA':(dp.g*dp.rho*dp.a*(dp.TP - dp.TS)*(dp.LS)**3)/(dp.k*dp.eta0),\n",
    "            'cohesion':dp.cohesion*sf.stress,\n",
    "            'fcd':dp.fc*sf.lith_grad,\n",
    "            'gamma':dp.fc/(dp.a*dp.deltaT),\n",
    "            #'Wdf':dp.Vdf*sf.W,\n",
    "            'Edf':math.log(dp.Edf),\n",
    "            #'Wps':dp.Vpr*sf.W,\n",
    "            #'Eps':dp.Epr*sf.E,\n",
    "            #'Wds':dp.Vds*sf.W,\n",
    "            #'Eds':dp.Eds*sf.E,\n",
    "            #'Elm':dp.Elm*sf.E,\n",
    "            #'Elm':dp.Elm*sf.E,\n",
    "            #'Wlm':dp.Vlm*sf.W,\n",
    "            'TSP':0., \n",
    "            'TBP':1.,\n",
    "            'TPP':(dp.TP - dp.TS)/dp.deltaT, #dimensionless potential temp\n",
    "            #'rDepth':dp.rDepth/dp.LS,\n",
    "            #'rTemp':(dp.rTemp- dp.TS)/dp.deltaT,\n",
    "            #'n':3.5, #Dislocation creep stress exponent\n",
    "            'np':20., #Peierls creep stress exponent\n",
    "            'TS':dp.TS/dp.deltaT,\n",
    "            'TP':dp.TP/dp.deltaT,\n",
    "            'eta_min':1e-3, \n",
    "            'eta_max':1e5, #viscosity max in the mantle material\n",
    "            #'eta_min_crust':1e-3, #crust viscosity, if using isoviscous weak crust\n",
    "            'eta_max_crust':10., #viscosity max in the weak-crust material\n",
    "             'eta_max_interface':1., #viscosity max in the weak-crust material\n",
    "            #'H':0.,\n",
    "            #'Tmvp':0.6,\n",
    "            #'Di': dp.a*dp.g*dp.LS/dp.Cp, #Dissipation number\n",
    "            'Steta0':5e-2,\n",
    "            'plate_vel':sf.vel*dp.plate_vel*(cmpery.to(u.m/u.second)).magnitude,\n",
    "            'low_mantle_visc_fac':10.,\n",
    "            'crust_cohesion_fac':0.5,\n",
    "            'crust_fc_fac':0.5,\n",
    "            'interface_cohesion_fac':0.1,\n",
    "            'interface_fc_fac':0.1,\n",
    "            })\n",
    "\n",
    "\n",
    "\n",
    "#Make some further additions to paramter dictionaries\n",
    "\n",
    "#dp.VR = (0.1*(dp.k/dp.LS)*ndp.RA**(2/3.)) #characteristic velocity from a scaling relationship\n",
    "#dp.SR = dp.VR/dp.LS #characteristic strain rate\n",
    "#ndp.VR = dp.VR*sf.vel #characteristic velocity\n",
    "#ndp.SR = dp.SR*sf.SR #characteristic strain rate\n",
    "\n",
    "\n",
    "#ndp.SR = dp.SR*sf.SR #characteristic strain rate\n",
    "\n",
    "ndp.StRA = (3300.*dp.g*(dp.LS)**3)/(dp.eta0 *dp.k) #Composisitional Rayleigh number for rock-air buoyancy force\n",
    "#ndp.TaP = 1. - ndp.TPP,  #Dimensionles adiabtic component of delta t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "583600.5252"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = 2918002.6260000006\n",
    "ndp.fcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "817040.7352800001"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#40000./sf.vel, \n",
    "ndp.RA\n",
    "#ndp.plate_vel\n",
    "#ndp.Edf\n",
    "#3404336."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#(4.0065172577e-06*sf.SR)/(3600.*24*365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2263.019582399744, 849.2588923739356, 3404336.397000001, 1400.0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.CVR = (0.1*(dp.k/dp.LS)*ndp.RA**(2/3.))\n",
    "ndp.CVR = dp.CVR*sf.vel #characteristic velocity\n",
    "ndp.CVR, ndp.plate_vel, ndp.RA , (dp.TP - dp.TS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#lengths scales for various processes (material transistions etc.)\n",
    "###########\n",
    "\n",
    "MANTLETOCRUST = (10.*1e3)/dp.LS #Crust depth\n",
    "HARZBURGDEPTH = MANTLETOCRUST + (27.7e3/dp.LS)\n",
    "CRUSTTOMANTLE = (800.*1e3)/dp.LS\n",
    "LITHTOMANTLE = (900.*1e3)/dp.LS\n",
    "MANTLETOLITH = (200.*1e3)/dp.LS\n",
    "TOPOHEIGHT = (10.*1e3)/dp.LS  #rock-air topography limits\n",
    "CRUSTTOECL  = (100.*1e3)/dp.LS\n",
    "#AVGTEMP = ndp.TPP #Used to define lithosphere\n",
    "LOWMANTLEDEPTH = (660.*1e3)/dp.LS \n",
    "CRUSTVISCUTOFF = (100.*1e3)/dp.LS #Deeper than this, crust material rheology reverts to mantle rheology\n",
    "AGETRACKDEPTH = 100e3/dp.LS #above this depth we track the age of the lithsphere (below age is assumed zero)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#MINX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setup parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Model setup parameters\n",
    "###########\n",
    "\n",
    "#Modelling and Physics switches\n",
    "refineMesh = True\n",
    "stickyAir = False\n",
    "meltViscosityReduction = False\n",
    "symmetricIC = False\n",
    "VelBC = False\n",
    "aspectRatio = 4\n",
    "compBuoyancy = False #use compositional & phase buoyancy, or simply thermal\n",
    "viscMechs = ['diffusion', 'dislocation', 'peierls', 'yielding']\n",
    "viscCombine = 'harmonic' #'harmonic', 'min', 'mixed'....\n",
    "\n",
    "#Domain and Mesh paramters\n",
    "dim = 2          # number of spatial dimensions\n",
    "\n",
    "tot_depth = np.round(dp.depth/dp.LS, 3)\n",
    "\n",
    "#These options allow us to explore the choice of different length scalings\n",
    "\n",
    "if tot_depth == 1.: #Depth equal to length scale\n",
    "    MINY = 0.\n",
    "    MAXY = 1.\n",
    "elif tot_depth > 1.: #Depth larger than to length scale\n",
    "    MINY = 0.\n",
    "    MAXY = tot_depth\n",
    "    \n",
    "elif tot_depth < 1.: #Depth smaller to length scale\n",
    "    MINY = np.round(1. - tot_depth, 2)\n",
    "    MAXY = 1.\n",
    "    \n",
    "MINX = np.round(-1.*tot_depth*aspectRatio/2., 2)  #Aspect ratio is fixed, x-domain shifts according to system depth and length scale\n",
    "\n",
    "MAXX = np.round(1.*tot_depth*aspectRatio/2., 2)\n",
    "\n",
    "if MINX == 0.:\n",
    "    squareModel = True\n",
    "else: \n",
    "    squareModel = False\n",
    "    \n",
    "    \n",
    "RES = 64\n",
    "Xres = int(RES*aspectRatio)\n",
    "#if MINY == 0.5:\n",
    "#    Xres = int(2.*RES*aspectRatio)\n",
    "    \n",
    "\n",
    "if stickyAir:\n",
    "    Yres = RES\n",
    "    MAXY = np.round(MAXY + dp.StALS/dp.LS, 2)\n",
    "    \n",
    "else:\n",
    "    Yres = RES\n",
    "    MAXY = np.round(MAXY, 2)\n",
    "\n",
    "periodic = [True, False]\n",
    "elementType = \"Q1/dQ0\"\n",
    "#elementType =\"Q2/DPC1\"\n",
    "\n",
    "\n",
    "#System/Solver stuff\n",
    "PIC_integration=True\n",
    "ppc = 25\n",
    "\n",
    "#Metric output stuff\n",
    "figures =  'gldb' #glucifer Store won't work on all machines, if not, set to 'gldb' \n",
    "swarm_repop, swarm_update = 10, 10\n",
    "gldbs_output = 10\n",
    "checkpoint_every, files_output = 5, 10\n",
    "metric_output = 5\n",
    "sticky_air_temp = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MINY, MAXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0, -2.0, 2.0, 1.0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MINY, MAXY,MINX, MAXX, tot_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create mesh and finite element variables\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mesh = uw.mesh.FeMesh_Cartesian( elementType = (elementType),\n",
    "                                 elementRes  = (Xres, Yres), \n",
    "                                 minCoord    = (MINX, MINY), \n",
    "                                 maxCoord    = (MAXX, MAXY), periodic=periodic)\n",
    "\n",
    "velocityField       = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=2 )\n",
    "pressureField       = uw.mesh.MeshVariable( mesh=mesh.subMesh, nodeDofCount=1 )\n",
    "temperatureField    = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=1 )\n",
    "temperatureDotField = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mesh.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min\n",
      "(256, 0.0078140624999999998, 3.0003999999999995, 0.99960000000000093)\n",
      "('edges', 256)\n",
      "-- iteration 0 --\n",
      "| F( p_n ) |^2: 0.000123928075027\n",
      "| p_n+1 - p_n |^2: 8.53512671865\n",
      "-- iteration 1 --\n",
      "| F( p_n ) |^2: 3.29102908897e-30\n",
      "Min, Max element width: \n",
      "0.00781\n",
      "0.02344\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "#Mesh refinement\n",
    "###########\n",
    "\n",
    "#X-Axis\n",
    "\n",
    "if refineMesh:\n",
    "    mesh.reset()\n",
    "    axis = 0\n",
    "    origcoords = np.linspace(mesh.minCoord[axis], mesh.maxCoord[axis], mesh.elementRes[axis] + 1)\n",
    "    edge_rest_lengths = np.diff(origcoords)\n",
    "\n",
    "    deform_lengths = edge_rest_lengths.copy()\n",
    "    min_point =  (abs(mesh.maxCoord[axis]) - abs(mesh.minCoord[axis]))/2.\n",
    "    el_reduction = 0.5001\n",
    "    dx = mesh.maxCoord[axis] - min_point\n",
    "\n",
    "    deform_lengths = deform_lengths - \\\n",
    "                                    ((1.-el_reduction) *deform_lengths[0]) + \\\n",
    "                                    abs((origcoords[1:] - min_point))*((0.5*deform_lengths[0])/dx)\n",
    "\n",
    "    #print(edge_rest_lengths.shape, deform_lengths.shape)\n",
    "\n",
    "    spmesh.deform_1d(deform_lengths, mesh,axis = 'x',norm = 'Min', constraints = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "axis = 1\n",
    "orgs = np.linspace(mesh.minCoord[axis], mesh.maxCoord[axis], mesh.elementRes[axis] + 1)\n",
    "\n",
    "value_to_constrain = MAXY #nodes will remain along this line\n",
    "\n",
    "\n",
    "yconst = [(spmesh.find_closest(orgs, value_to_constrain), np.array([value_to_constrain,0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min\n",
      "(64, 0.0078140624999999998, 0.74619374999999988, 1.0313396825396834)\n",
      "('edges', 64)\n",
      "-- iteration 0 --\n",
      "| F( p_n ) |^2: 0.000125895187329\n",
      "| p_n+1 - p_n |^2: 0.550178754655\n",
      "-- iteration 1 --\n",
      "| F( p_n ) |^2: 3.96579068205e-31\n",
      "Min, Max element width: \n",
      "0.00781\n",
      "0.02344\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "#Mesh refinement\n",
    "###########\n",
    "\n",
    "if refineMesh:\n",
    "    #Y-Axis\n",
    "    axis = 1\n",
    "    origcoords = np.linspace(mesh.minCoord[axis], mesh.maxCoord[axis], mesh.elementRes[axis] + 1)\n",
    "    edge_rest_lengths = np.diff(origcoords)\n",
    "\n",
    "    deform_lengths = edge_rest_lengths.copy()\n",
    "    min_point =  (mesh.maxCoord[axis])\n",
    "    el_reduction = 0.5001\n",
    "    dx = mesh.maxCoord[axis]\n",
    "\n",
    "    deform_lengths = deform_lengths - \\\n",
    "                                    ((1.-el_reduction)*deform_lengths[0]) + \\\n",
    "                                    abs((origcoords[1:] - min_point))*((0.5*deform_lengths[0])/dx)\n",
    "\n",
    "    #print(edge_rest_lengths.shape, deform_lengths.shape)\n",
    "\n",
    "    spmesh.deform_1d(deform_lengths, mesh,axis = 'y',norm = 'Min', constraints = yconst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fig= glucifer.Figure()\n",
    "\n",
    "#fig.append(glucifer.objects.Mesh(mesh))\n",
    "\n",
    "#fig.show()\n",
    "#fig.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#THis is a hack for adding a sticky air domain, we refine MAXY and things like the temperature stencil work from Y = 1. \n",
    "\n",
    "if stickyAir:\n",
    "    MAXY = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial conditions\n",
    "-------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coordinate = fn.input()\n",
    "depthFn = MAXY - coordinate[1] #a function providing the depth\n",
    "\n",
    "\n",
    "xFn = coordinate[0]  #a function providing the x-coordinate\n",
    "\n",
    "#potTempFn = ndp.TPP + (depthFn)*ndp.TaP #a function providing the adiabatic temp at any depth\n",
    "#abHeatFn = -1.*velocityField[1]*temperatureField*ndp.Di #a function providing the adiabatic heating rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###########\n",
    "#Thermal initial condition:\n",
    "#if symmetricIC, we build a symmetric downwelling on top of a sinusoidal perturbation\n",
    "##########\n",
    "\n",
    "#Sinusoidal initial condition\n",
    "A = 0.2\n",
    "sinFn = depthFn + A*(fn.math.cos( math.pi * coordinate[0])  * fn.math.sin( math.pi * coordinate[1] ))        \n",
    "iD = 1000e3/dp.LS #Initial Slab depth\n",
    "dl =  2*math.sqrt(dp.k*160e6*3600*24*365) #diffusion Length at ... My\n",
    "w0 = dl/dp.LS #Boundary layer/slab initial condition\n",
    "delX1 = fn.misc.min(fn.math.abs(coordinate[0] - -0.), fn.math.abs(coordinate[0] - -2.))\n",
    "delX = fn.misc.min(delX1 , fn.math.abs(coordinate[0] - 2.))\n",
    "w = w0*fn.math.sqrt(delX + 1e-7)\n",
    "tempBL = (potTempFn) *fn.math.erf((depthFn)/w) + ndp.TSP\n",
    "delX = fn.misc.min(fn.math.abs(coordinate[0] - - 1.) , fn.math.abs(coordinate[0] - 1.))\n",
    "tempSlab = (potTempFn ) *fn.math.erf((delX*2.)/w0) + ndp.TSP       \n",
    "tempFn1 =  fn.misc.min(tempBL, tempSlab)\n",
    "blFn = fn.branching.conditional([(depthFn < iD, tempFn1), \n",
    "                                    (True, potTempFn)])\n",
    "\n",
    "tempFn = 0.*sinFn + 1.*blFn #partition the temp between these the symmetric downwelling and sinusoid\n",
    "if symmetricIC:  \n",
    "    if not checkpointLoad:\n",
    "        temperatureField.data[:] = tempFn.evaluate(mesh)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def age_fn(xFn, sz = 0.0, lMOR=MINX, rMOR=MAXX, opFac=1., conjugate_plate = False):\n",
    "    \"\"\"\n",
    "    Simple function to generate a discrete 1-d (i.e x-coordinate) function for the age of the thermal BC. \n",
    "    All paramters are dimensionless\n",
    "    sz: location of subduction zone\n",
    "    lMOR: location of left-hand MOR\n",
    "    rMOR: location of right-hand MOR\n",
    "    opFac: uniform reduce the age of the right hand plate by this factor\n",
    "    conjugate_plate: if True, build plates on the outer sides of the MORs, if False, age = 0. \n",
    "    \"\"\"\n",
    "    \n",
    "    if lMOR < MINX:\n",
    "        lMOR = MINX\n",
    "    if rMOR > MAXX:\n",
    "        rMOR = MAXX\n",
    "    r_grad =  1./(abs(rMOR-sz))\n",
    "    l_grad =  1./(abs(sz-lMOR))\n",
    "    if conjugate_plate:\n",
    "        ageFn = fn.branching.conditional([(operator.and_(xFn > lMOR, xFn < sz) , (xFn + abs(lMOR))/(abs(sz-lMOR))), \n",
    "                                      (operator.and_(xFn < rMOR, xFn >= sz), (1.-(xFn + abs(sz))/abs(rMOR-sz))*opFac),\n",
    "                                      (xFn > rMOR, r_grad*opFac*(xFn -abs(rMOR)) / (abs(MAXX-rMOR))),\n",
    "                                      (True, l_grad*fn.math.abs((((xFn + abs(lMOR)) / (abs(lMOR - MINX))))))\n",
    "                                         ])\n",
    "    else:    \n",
    "        \n",
    "        ageFn = fn.branching.conditional([(operator.and_(xFn > lMOR, xFn < sz) , (xFn + abs(lMOR))/(abs(sz-lMOR))), \n",
    "                                      (operator.and_(xFn < rMOR, xFn >= sz), (1.-(xFn + abs(sz))/abs(rMOR-sz))*opFac),\n",
    "\n",
    "                                      (True, 0.0)])\n",
    "    return ageFn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Thermal initial condition 2: \n",
    "#if symmetricIC == False, we build an asymmetric subduction-zone\n",
    "###########\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Main control paramters are:\n",
    "\n",
    "\n",
    "Roc = 250e3 #radius of curvature of slab\n",
    "theta = 70. #Angle to truncate the slab (can also do with with a cutoff depth)\n",
    "subzone = 0.0 #X position of subduction zone...in model coordinates\n",
    "slabmaxAge = 75e6 #age of subduction plate at trench\n",
    "platemaxAge = 75e6 #max age of slab (Plate model)\n",
    "ageAtTrenchSeconds = min(platemaxAge*(3600*24*365), slabmaxAge*(3600*24*365))\n",
    "lRidge = -0.5*(670e3*4)/dp.LS  #For depth = 670 km, aspect ratio of 4, this puts the ridges at MINX, MAXX\n",
    "rRidge = 0.5*(670e3*4)/dp.LS\n",
    "\n",
    "sense = 'Right' #dip direction\n",
    "op_age_fac = 0.2 #this controls the overidding plate age reduction\n",
    "\n",
    "\n",
    "#First build the top TBL\n",
    "#Create functions between zero and one, to control age distribution\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#ageFn1 = fn.misc.max(0., 1. - fn.math.abs(xFn/MAXX))\n",
    "\n",
    "#ageFn  = fn.branching.conditional([(coordinate[0] <= 0, ageFn1),\n",
    " #                                 (True, ageFn1/op_age_fac)])\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "#ageFn = age_fn(xFn, sz = -0.5, lMOR=-2., rMOR=2.)\n",
    "ageFn = age_fn(xFn, sz =subzone, lMOR=lRidge,rMOR=rRidge, conjugate_plate=True, opFac = op_age_fac)\n",
    "\n",
    "#dimensionlize the age function\n",
    "ageFn *= slabmaxAge*(3600*24*365)\n",
    "#ageFn = fn.misc.min(ageFn, platemaxAge*(3600*24*365)) #apply plate model\n",
    "\n",
    "w0 = (2.*math.sqrt(dp.k*ageAtTrenchSeconds))/dp.LS #diffusion depth of plate at the trench\n",
    "\n",
    "tempBL = (ndp.TP - ndp.TS) *fn.math.erf((depthFn*dp.LS)/(2.*fn.math.sqrt(dp.k*ageFn))) + ndp.TSP #boundary layer function\n",
    "\n",
    "tempTBL =  fn.branching.conditional([(depthFn < w0, tempBL),\n",
    "                          (True, ndp.TPP)])\n",
    "\n",
    "if not symmetricIC:\n",
    "    if not checkpointLoad:\n",
    "        out = uw.utils.MeshVariable_Projection( temperatureField, tempTBL) #apply function with projection\n",
    "        out.solve()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now build the perturbation part\n",
    "def inCircleFnGenerator(centre, radius):\n",
    "    coord = fn.input()\n",
    "    offsetFn = coord - centre\n",
    "    return fn.math.dot( offsetFn, offsetFn ) < radius**2\n",
    "\n",
    "\n",
    "\n",
    "#Setup slab perturbation params (mostly dimensionlesl / model params here)\n",
    "phi = 90. - theta\n",
    "RocM = (Roc/dp.LS)\n",
    "CrustM = MANTLETOCRUST\n",
    "Org = (subzone, MAXY-RocM)\n",
    "maxDepth = 250e3/dp.LS\n",
    "\n",
    "#We use three circles to define our slab and crust perturbation,  \n",
    "Oc = inCircleFnGenerator(Org , RocM)\n",
    "Ic = inCircleFnGenerator(Org , RocM - w0)\n",
    "Cc = inCircleFnGenerator(Org , RocM - (1.2*CrustM)) #... weak zone on 'outside' of slab\n",
    "Hc = inCircleFnGenerator(Org , RocM - HARZBURGDEPTH) #... Harzburgite layer \n",
    "dx = (RocM)/(np.math.tan((np.math.pi/180.)*phi))\n",
    "\n",
    "#We'll also create a triangle which will truncate the circles defining the slab...\n",
    "if sense == 'Left':\n",
    "    ptx = subzone - dx\n",
    "else:\n",
    "    ptx = subzone + dx\n",
    "coords = ((0.+subzone, MAXY), (0.+subzone, MAXY-RocM), (ptx, MAXY))\n",
    "Tri = fn.shape.Polygon(np.array(coords))\n",
    "\n",
    "#Actually apply the perturbation - could probably avoid particle walk here\n",
    "if not symmetricIC:\n",
    "    if not checkpointLoad:\n",
    "        sdFn = ((RocM - fn.math.sqrt((coordinate[0] - Org[0])**2. + (coordinate[1] - Org[1])**2.)))\n",
    "        slabFn = ndp.TPP*fn.math.erf((sdFn*dp.LS)/(2.*math.sqrt(dp.k*ageAtTrenchSeconds))) + ndp.TSP\n",
    "        for index, coord in enumerate(mesh.data):\n",
    "            if (\n",
    "                Oc.evaluate(tuple(coord)) and\n",
    "                Tri.evaluate(tuple(coord)) and not\n",
    "                Ic.evaluate(tuple(coord)) and\n",
    "                coord[1] > (MAXY - maxDepth)\n",
    "                ): #In the quarter-circle defining the lithosphere\n",
    "                temperatureField.data[index] = slabFn.evaluate(mesh)[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<underworld.function._function.multiply at 0x7f79192f3d90>,\n",
       " <underworld.function._function.add at 0x7f79194b8350>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdFn = ((RocM - fn.math.sqrt((coordinate[0] - Org[0])**2. + (coordinate[1] - Org[1])**2.)))\n",
    "slabFn = ndp.TPP*fn.math.erf((sdFn*dp.LS)/(2.*math.sqrt(dp.k*ageAtTrenchSeconds))) + ndp.TSP\n",
    "sdFn, slabFn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make sure material in sticky air region is at the surface temperature.\n",
    "for index, coord in enumerate(mesh.data):\n",
    "            if coord[1] >= MAXY:\n",
    "                temperatureField.data[index] = ndp.TSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.14925373134328357, 0.04477611940298507)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fn.math.erf((sdFn*dp.LS)/(2.*fn.math.sqrt(dp.k*(slabmaxAge*(3600*24*365))))) \n",
    "CRUSTVISCUTOFF, MANTLETOCRUST*3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def matplot_field(temperatureField, dp):\n",
    "    if uw.nProcs() != 1:\n",
    "        print(\"only in Serial folks\")\n",
    "    else:\n",
    "        import matplotlib.pyplot as pyplt\n",
    "        try :\n",
    "            if(__IPYTHON__) :\n",
    "                get_ipython().magic(u'matplotlib inline')\n",
    "        except NameError :\n",
    "            pass\n",
    "        field_data = temperatureField.data.reshape(mesh.elementRes[1] + 1, mesh.elementRes[0] + 1)\n",
    "        fig, ax = pyplt.subplots(figsize=(32,2))\n",
    "        ql = dp.LS/1e3\n",
    "        pyplt.ioff()\n",
    "        cax =ax.imshow(np.flipud(field_data), cmap='coolwarm', aspect = 0.5, extent=[0,ql*aspectRatio,ql, 0])\n",
    "        fig.colorbar(cax, orientation='horizontal' )\n",
    "        #ax.set_x([0,dp.LS*aspectRatio])\n",
    "        pyplt.tight_layout()\n",
    "        \n",
    "        return fig, ax\n",
    "        \n",
    "fig, ax = matplot_field(temperatureField, dp)\n",
    "fig.savefig('test.png')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperatureField.data.min(), temperatureField.data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#ageFn = age_fn(xFn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig= glucifer.Figure(quality=3)\n",
    "\n",
    "fig.append( glucifer.objects.Surface(mesh,temperatureField ))\n",
    "#fig.append( glucifer.objects.Mesh(mesh))\n",
    "#fig.show()\n",
    "\n",
    "##fig.save_database('test.gldb')\n",
    "#fig.save_image('test.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boundary conditions\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "for index in mesh.specialSets[\"MinJ_VertexSet\"]:\n",
    "    temperatureField.data[index] = ndp.TBP\n",
    "for index in mesh.specialSets[\"MaxJ_VertexSet\"]:\n",
    "    temperatureField.data[index] = ndp.TSP\n",
    "    \n",
    "iWalls = mesh.specialSets[\"MinI_VertexSet\"] + mesh.specialSets[\"MaxI_VertexSet\"]\n",
    "jWalls = mesh.specialSets[\"MinJ_VertexSet\"] + mesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "tWalls = mesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "bWalls =mesh.specialSets[\"MinJ_VertexSet\"]\n",
    "\n",
    "VelBCs = mesh.specialSets[\"Empty\"]\n",
    "\n",
    "\n",
    "\n",
    "if VelBC:\n",
    "    for index in list(tWalls.data):\n",
    "\n",
    "        if (mesh.data[int(index)][0] < (subzone - 0.05*aspectRatio) and \n",
    "            mesh.data[int(index)][0] > (mesh.minCoord[0] + 0.05*aspectRatio)): #Only push with a portion of teh overiding plate\n",
    "            #print \"first\"\n",
    "            VelBCs.add(int(index))\n",
    "            #Set the plate velocities for the kinematic phase\n",
    "            velocityField.data[index] = [ndp.plate_vel, 0.]\n",
    "        \n",
    "        elif (mesh.data[int(index)][0] > (subzone + 0.05*aspectRatio) and \n",
    "            mesh.data[int(index)][0] < (mesh.maxCoord[0] - 0.05*aspectRatio)):\n",
    "            #print \"second\"\n",
    "            VelBCs.add(int(index))\n",
    "            #Set the plate velocities for the kinematic phase\n",
    "            velocityField.data[index] = [0., 0.]\n",
    "        \n",
    "\n",
    "#If periodic, we'll fix a the x-vel at a single node - at the bottom left (index 0)\n",
    "Fixed = mesh.specialSets[\"Empty\"]\n",
    "Fixed.add(int(0))        \n",
    "        \n",
    "\n",
    "if periodic[0] == False:\n",
    "    if VelBC:\n",
    "        print(1)\n",
    "        freeslipBC = uw.conditions.DirichletCondition( variable      = velocityField, \n",
    "                                               indexSetsPerDof = ( iWalls + VelBCs, jWalls) )\n",
    "    else:\n",
    "        print(2)\n",
    "        freeslipBC = uw.conditions.DirichletCondition( variable      = velocityField, \n",
    "                                               indexSetsPerDof = ( iWalls, jWalls) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if periodic[0] == True:\n",
    "    if VelBC:\n",
    "        print(3)\n",
    "        freeslipBC = uw.conditions.DirichletCondition( variable      = velocityField, \n",
    "                                               indexSetsPerDof = ( Fixed + VelBCs , jWalls) )\n",
    "    else:\n",
    "        print(4)\n",
    "        freeslipBC = uw.conditions.DirichletCondition( variable      = velocityField, \n",
    "                                               indexSetsPerDof = ( Fixed, jWalls) )\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "# also set dirichlet for temp field\n",
    "dirichTempBC = uw.conditions.DirichletCondition(     variable=temperatureField, \n",
    "                                              indexSetsPerDof=(tWalls,) )\n",
    "dT_dy = [0.,0.]\n",
    "\n",
    "# also set dirichlet for temp field\n",
    "neumannTempBC = uw.conditions.NeumannCondition( dT_dy, variable=temperatureField, \n",
    "                                         nodeIndexSet=bWalls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check VelBCs are where we want them\n",
    "#test = np.zeros(len(tWalls.data))\n",
    "#VelBCs\n",
    "#tWalls.data\n",
    "#tWalls.data[VelBCs.data]\n",
    "#test[np.in1d(tWalls.data, VelBCs.data)] = 1.\n",
    "#test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swarm setup\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Material Swarm and variables\n",
    "###########\n",
    "\n",
    "#create material swarm\n",
    "gSwarm = uw.swarm.Swarm(mesh=mesh, particleEscape=True)\n",
    "\n",
    "#create swarm variables\n",
    "yieldingCheck = gSwarm.add_variable( dataType=\"int\", count=1 )\n",
    "#tracerVariable = gSwarm.add_variable( dataType=\"int\", count=1)\n",
    "materialVariable = gSwarm.add_variable( dataType=\"int\", count=1 )\n",
    "ageVariable = gSwarm.add_variable( dataType=\"double\", count=1 )\n",
    "#testVariable = gSwarm.add_variable( dataType=\"float\", count=1 )\n",
    "\n",
    "\n",
    "#these lists  are part of the checkpointing implementation\n",
    "varlist = [materialVariable, yieldingCheck, ageVariable]\n",
    "varnames = ['materialVariable', 'yieldingCheck', 'ageVariable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mantleIndex = 0\n",
    "crustIndex = 1\n",
    "harzIndex = 2\n",
    "airIndex = 3\n",
    "\n",
    "\n",
    "\n",
    "if checkpointLoad:\n",
    "    checkpointLoadDir = natsort.natsort(checkdirs)[-1]\n",
    "    temperatureField.load(os.path.join(checkpointLoadDir, \"temperatureField\" + \".hdf5\"))\n",
    "    pressureField.load(os.path.join(checkpointLoadDir, \"pressureField\" + \".hdf5\"))\n",
    "    velocityField.load(os.path.join(checkpointLoadDir, \"velocityField\" + \".hdf5\"))\n",
    "    gSwarm.load(os.path.join(checkpointLoadDir, \"swarm\" + \".h5\"))\n",
    "    for ix in range(len(varlist)):\n",
    "        varb = varlist[ix]\n",
    "        varb.load(os.path.join(checkpointLoadDir,varnames[ix] + \".h5\"))\n",
    "\n",
    "else:\n",
    "\n",
    "    # Layouts are used to populate the swarm across the whole domain\n",
    "    layout = uw.swarm.layouts.PerCellRandomLayout(swarm=gSwarm, particlesPerCell=ppc)\n",
    "    gSwarm.populate_using_layout( layout=layout ) # Now use it to populate.\n",
    "    # Swarm variables\n",
    "    materialVariable.data[:] = mantleIndex\n",
    "    #tracerVariable.data[:] = 1\n",
    "    yieldingCheck.data[:] = 0\n",
    "    ageVariable.data[:] = -1\n",
    "\n",
    "    #Set initial air and crust materials (allow the graph to take care of lithsophere)\n",
    "    #########\n",
    "    #This initial material setup will be model dependent\n",
    "    #########\n",
    "    for particleID in range(gSwarm.particleCoordinates.data.shape[0]):\n",
    "        if (1. - gSwarm.particleCoordinates.data[particleID][1]) < MANTLETOCRUST:\n",
    "                 materialVariable.data[particleID] = crustIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###########\n",
    "#This block sets up a checkboard layout of passive tracers\n",
    "###########\n",
    "\n",
    "square_size = 0.1\n",
    "xlist = np.arange(mesh.minCoord[0] + square_size/2., mesh.maxCoord[0] + square_size/2., square_size)\n",
    "xlist = zip(xlist[:], xlist[1:])[::2]\n",
    "ylist = np.arange(mesh.minCoord[1] + square_size/2., mesh.maxCoord[1] + square_size/2., square_size)\n",
    "ylist = zip(ylist[:], ylist[1:])[::2]\n",
    "xops = []\n",
    "for vals in xlist:\n",
    "    xops.append( (operator.and_(   operator.gt(coordinate[0],vals[0]),   operator.lt(coordinate[0],vals[1])  ),0.) )\n",
    "xops.append((True,1.))\n",
    "\n",
    "testfunc = fn.branching.conditional(xops) \n",
    "\n",
    "yops = []\n",
    "for vals in ylist:\n",
    "    yops.append( (operator.and_(   operator.gt(coordinate[1],vals[0]),   operator.lt(coordinate[1],vals[1])  ),0.) )\n",
    "yops.append((True,testfunc))\n",
    "\n",
    "testfunc2 = fn.branching.conditional(yops) \n",
    "tracerVariable.data[:] = testfunc.evaluate(gSwarm)\n",
    "tracerVariable.data[:] = testfunc2.evaluate(gSwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#Set the initial particle age for particles above the critical depth; \n",
    "#only material older than crustageCond will be transformed to crust / harzburgite\n",
    "##############\n",
    "\n",
    "ageVariable.data[:] = 0. #start with all zero\n",
    "ageVariable.data[:] = ageFn.evaluate(gSwarm)/sf.SR\n",
    "crustageCond = 2e6*(3600.*365.*24.)/sf.SR #set inital age above critical depth. (x...Ma)\n",
    "\n",
    "\n",
    "\n",
    "ageConditions = [ (depthFn < AGETRACKDEPTH, ageVariable),  #In the main loop we add ageVariable + dt here\n",
    "                  (True, 0.) ]\n",
    "                 \n",
    "#apply conditional \n",
    "ageVariable.data[:] = fn.branching.conditional( ageConditions ).evaluate(gSwarm)\n",
    "\n",
    "ageDT = 0.#this is used in the main loop for short term time increments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fig= glucifer.Figure()\n",
    "#fig.append( glucifer.objects.Points(gSwarm,ageVariable))\n",
    "#fig.append( glucifer.objects.Points(gSwarm, viscosityMapFn, logScale=True, valueRange =[1e-3,1e5]))\n",
    "\n",
    "\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#Here we set up a directed graph object that we we use to control the transformation from one material type to another\n",
    "##############\n",
    "\n",
    "#All depth conditions are given as (km/D) where D is the length scale,\n",
    "#note that 'model depths' are used, e.g. 1-z, where z is the vertical Underworld coordinate\n",
    "#All temp conditions are in dimensionless temp. [0. - 1.]\n",
    "\n",
    "#Need a list of all material indexes (safer in parallel)\n",
    "material_list = [0,1,2,3]\n",
    "\n",
    "if not checkpointLoad:\n",
    "    materialVariable.data[:] = 0 #Initialize to zero \n",
    "\n",
    "#Setup the graph object\n",
    "DG = material_graph.MatGraph()\n",
    "\n",
    "#Important: First thing to do is to add all the material types to the graph (i.e add nodes)\n",
    "DG.add_nodes_from(material_list)\n",
    "\n",
    "#Now set the conditions for transformations\n",
    "\n",
    "hs = 2e3/dp.LS  #add some hysteresis to the depths of transition\n",
    "\n",
    "#... to mantle\n",
    "DG.add_transition((crustIndex,mantleIndex), depthFn, operator.gt, CRUSTTOMANTLE + hs)\n",
    "DG.add_transition((harzIndex,mantleIndex), depthFn, operator.gt, CRUSTTOMANTLE + hs)\n",
    "DG.add_transition((airIndex,mantleIndex), depthFn, operator.gt, TOPOHEIGHT + hs)\n",
    "\n",
    "#... to crust\n",
    "DG.add_transition((mantleIndex,crustIndex), depthFn, operator.lt, MANTLETOCRUST)\n",
    "DG.add_transition((mantleIndex,crustIndex), xFn, operator.lt, subzone + 4.*MANTLETOCRUST) #No crust on the upper plate\n",
    "DG.add_transition((mantleIndex,crustIndex), ageVariable, operator.gt, crustageCond)\n",
    "\n",
    "\n",
    "DG.add_transition((harzIndex,crustIndex), depthFn, operator.lt, MANTLETOCRUST)\n",
    "DG.add_transition((harzIndex,crustIndex), xFn, operator.lt, subzone + 4.*MANTLETOCRUST) #This one sets no crust on the upper plate\n",
    "DG.add_transition((harzIndex,crustIndex), ageVariable, operator.gt, crustageCond)\n",
    "\n",
    "#... to Harzbugite\n",
    "DG.add_transition((mantleIndex,harzIndex), depthFn, operator.lt, HARZBURGDEPTH)\n",
    "DG.add_transition((mantleIndex,harzIndex), depthFn, operator.gt, MANTLETOCRUST)\n",
    "DG.add_transition((mantleIndex,harzIndex), ageVariable, operator.gt, crustageCond) #Note we can mix functions and swarm variabls\n",
    "\n",
    "\n",
    "\n",
    "#... to air\n",
    "DG.add_transition((mantleIndex,airIndex), depthFn, operator.lt,0.)\n",
    "DG.add_transition((crustIndex,airIndex), depthFn, operator.lt, 0. )\n",
    "DG.add_transition((harzIndex,airIndex), depthFn, operator.lt, 0. )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.1940298507462686, 0.05626865671641791, 0.1044776119402985)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CRUSTTOMANTLE, HARZBURGDEPTH, 0. + 7.*MANTLETOCRUST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#gSwarm.particleCoordinates.data[particleID][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#For the slab_IC, we'll also add a crustal weak zone following the dipping perturbation\n",
    "##############\n",
    "\n",
    "if checkpointLoad != True:\n",
    "    if not symmetricIC:\n",
    "        for particleID in range(gSwarm.particleCoordinates.data.shape[0]):\n",
    "            if gSwarm.particleCoordinates.data[particleID][1] < 0.:\n",
    "                materialVariable.data[particleID] = airIndex\n",
    "                \n",
    "            elif (\n",
    "                Oc.evaluate(list(gSwarm.particleCoordinates.data[particleID])) and\n",
    "                Tri.evaluate(list(gSwarm.particleCoordinates.data[particleID])) and\n",
    "                gSwarm.particleCoordinates.data[particleID][1] > (MAXY - maxDepth) and\n",
    "                Cc.evaluate(list(gSwarm.particleCoordinates.data[particleID])) == False\n",
    "                \n",
    "                ):\n",
    "                materialVariable.data[particleID] = crustIndex\n",
    "                \n",
    "            elif (\n",
    "                Oc.evaluate(list(gSwarm.particleCoordinates.data[particleID])) and\n",
    "                Tri.evaluate(list(gSwarm.particleCoordinates.data[particleID])) and\n",
    "                gSwarm.particleCoordinates.data[particleID][1] > (MAXY - maxDepth) and\n",
    "                Hc.evaluate(list(gSwarm.particleCoordinates.data[particleID])) == False\n",
    "                \n",
    "                ):\n",
    "                materialVariable.data[particleID] = harzIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#This is how we use the material graph object to test / apply material transformations\n",
    "##############\n",
    "DG.build_condition_list(materialVariable)\n",
    "\n",
    "for i in range(2): #Need to go through a number of times\n",
    "    materialVariable.data[:] = fn.branching.conditional(DG.condition_list).evaluate(gSwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#maxDepth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig2= glucifer.Figure()\n",
    "fig2.append( glucifer.objects.Points(gSwarm,materialVariable))\n",
    "#fig2.append( glucifer.objects.Surface(mesh, depthFn))\n",
    "\n",
    "#fig2.show()\n",
    "#fig2.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## phase and compositional buoyancy\n",
    "\n",
    "This was designed for EBA models, needs a rethink for Boussinesq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#Set up phase buoyancy contributions\n",
    "#the phase function approach of Yuen and Christenson is implemented in the Slippy2 phase_function class \n",
    "##############\n",
    "\n",
    "\n",
    "#olivine\n",
    "olivinePhase = phase_function.component_phases(name = 'ol', \n",
    "                        depths=[410e3,660e3], #depths of phase transitions along adiabat\n",
    "                        temps = [1600., 1900.], #temperatures of phase transitions along adiabat\n",
    "                        widths = [20e3, 20e3], #width if transition\n",
    "                        claps=[2.e6, -2.5e6],  #Clapeyron slope of trnasition\n",
    "                        densities = [180., 400.]) #density change of phase transition\n",
    "\n",
    "olivinePhase.build_nd_dict(dp.LS, dp.rho, dp.g, dp.deltaT)\n",
    "\n",
    "\n",
    "rp = olivinePhase.nd_reduced_pressure(depthFn, \n",
    "                                   temperatureField,\n",
    "                                   olivinePhase.ndp['depths'][0],\n",
    "                                   olivinePhase.ndp['claps'][0],\n",
    "                                   olivinePhase.ndp['temps'][0])\n",
    "\n",
    "#ph_410 = olivinePhase.nd_phase(rp, test.ndp['widths'][0])\n",
    "#pf_sum = test.phase_function_sum(temperatureField, depthFn)\n",
    "\n",
    "olivine_phase_buoyancy = olivinePhase.buoyancy_sum(temperatureField, depthFn, dp.g, dp.LS, dp.k, dp.eta0)\n",
    "\n",
    "#garnet\n",
    "garnetPhase = phase_function.component_phases(name = 'grt', \n",
    "                        depths=[60e3,400e3, 720e3],\n",
    "                        temps = [1000., 1600., 1900.], \n",
    "                        widths = [20e3, 20e3, 20e3], \n",
    "                        claps=[0.e6, 1.e6, 1.e6], \n",
    "                        densities = [350., 150., 400.])\n",
    "\n",
    "garnetPhase.build_nd_dict(dp.LS, dp.rho, dp.g, dp.deltaT)\n",
    "\n",
    "\n",
    "rp = garnetPhase.nd_reduced_pressure(depthFn, \n",
    "                                   temperatureField,\n",
    "                                   garnetPhase.ndp['depths'][0],\n",
    "                                   garnetPhase.ndp['claps'][0],\n",
    "                                   garnetPhase.ndp['temps'][0])\n",
    "\n",
    "#ph_410 = olivinePhase.nd_phase(rp, test.ndp['widths'][0])\n",
    "#pf_sum = test.phase_function_sum(temperatureField, depthFn)\n",
    "\n",
    "garnet_phase_buoyancy = garnetPhase.buoyancy_sum(temperatureField, depthFn, dp.g, dp.LS, dp.k, dp.eta0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#Set up compositional buoyancy contributions\n",
    "##############\n",
    "\n",
    "bouyancy_factor = (dp.g*dp.LS**3)/(dp.eta0*dp.k)\n",
    "\n",
    "basalt_comp_buoyancy  = (dp.rho - 2940.)*bouyancy_factor\n",
    "harz_comp_buoyancy = (dp.rho - 3235.)*bouyancy_factor\n",
    "pyrolite_comp_buoyancy = (dp.rho - 3300.)*bouyancy_factor\n",
    "\n",
    "#print(basalt_comp_buoyancy, harz_comp_buoyancy, pyrolite_comp_buoyancy)\n",
    "\n",
    "\n",
    "#this function accounts for the decrease in expansivity, and acts to reduce the rayleigh number with depth\n",
    "alphaRatio = 1.2/3\n",
    "taFn = 1. - (depthFn)*(1. - alphaRatio) \n",
    "\n",
    "\n",
    "if not compBuoyancy:\n",
    "    pyrolitebuoyancyFn =  (ndp.RA*temperatureField*taFn)\n",
    "    harzbuoyancyFn =      (ndp.RA*temperatureField*taFn) \n",
    "    basaltbuoyancyFn =    (ndp.RA*temperatureField*taFn)\n",
    "\n",
    "else : \n",
    "    pyrolitebuoyancyFn =  (ndp.RA*temperatureField*taFn) -\\\n",
    "                          (0.6*olivine_phase_buoyancy + 0.4*garnet_phase_buoyancy) +\\\n",
    "                           pyrolite_comp_buoyancy\n",
    "    harzbuoyancyFn =      (ndp.RA*temperatureField*taFn) -\\\n",
    "                          (0.8*olivine_phase_buoyancy + 0.2*garnet_phase_buoyancy) +\\\n",
    "                           harz_comp_buoyancy\n",
    "    basaltbuoyancyFn =    (ndp.RA*temperatureField*taFn) -\\\n",
    "                          (1.*garnet_phase_buoyancy) +\\\n",
    "                           basalt_comp_buoyancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rheology\n",
    "-----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#Set up any functions required by the rheology\n",
    "##############\n",
    "strainRate_2ndInvariant = fn.tensor.second_invariant( \n",
    "                            fn.tensor.symmetric( \n",
    "                            velocityField.fn_gradient ))\n",
    "\n",
    "def safe_visc(func, viscmin=ndp.eta_min, viscmax=ndp.eta_max):\n",
    "    return fn.misc.max(viscmin, fn.misc.min(viscmax, func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#strainRate_2ndInvariant = fn.misc.constant(ndp.SR) #dummy fucntion to check which mechanisms are at active are reference strain rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndp.crust_cohesion_fac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temperatureField' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-ba614a903327>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m##Diffusion Creep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mdiffusion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meta_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mndp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEdf\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mndp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEdf\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtemperatureField\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'temperatureField' is not defined"
     ]
    }
   ],
   "source": [
    "############\n",
    "#Rheology: create UW2 functions for all viscous mechanisms\n",
    "#############\n",
    "\n",
    "omega = fn.misc.constant(1.) #this function can hold any arbitary viscosity modifications \n",
    "\n",
    "\n",
    "##Diffusion Creep\n",
    "\n",
    "diffusion = fn.misc.min(ndp.eta_max, fn.math.exp(-1*ndp.Edf + ndp.Edf / (temperatureField + 1e-8)))\n",
    "\n",
    "\n",
    "\n",
    "##Define the Plasticity\n",
    "ys =  ndp.cohesion + (depthFn*ndp.fcd)\n",
    "ysMax = 10e4*1e6*sf.stress\n",
    "ysf = fn.misc.min(ys, ysMax)\n",
    "yielding = ysf/(2.*(strainRate_2ndInvariant))\n",
    "\n",
    "##Crust rheology\n",
    "#crustys =  ndp.cohesion*ndp.crust_cohesion_fac + (depthFn*ndp.fcd*ndp.crust_fc_fac)\n",
    "crustys =  ndp.cohesion*ndp.crust_cohesion_fac + (ndp.crust_fc_fac*depthFn*ndp.fcd) #only weakened cohesion is discussed, not fc\n",
    "crustyielding = crustys/(2.*(strainRate_2ndInvariant)) \n",
    "\n",
    "\n",
    "##Interface rheology\n",
    "interfaceys =  ndp.cohesion*ndp.interface_cohesion_fac + (ndp.interface_fc_fac*depthFn*ndp.fcd) #only weakened cohesion is discussed, not fc\n",
    "interfaceyielding = interfaceys/(2.*(strainRate_2ndInvariant))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############\n",
    "#Rheology: combine viscous mechanisms in various ways \n",
    "#harmonic: harmonic average of all mechanims\n",
    "#min: minimum effective viscosity of the mechanims\n",
    "#mixed: takes the minimum of the harmonic and the plastic effective viscosity\n",
    "#############\n",
    "\n",
    "#linear rheology \n",
    "linearviscosityFn = safe_visc(diffusion)\n",
    "\n",
    "\n",
    "\n",
    "interfaceCond = operator.and_((depthFn < CRUSTVISCUTOFF), (depthFn > MANTLETOCRUST))    \n",
    "\n",
    "\n",
    "#combined rheology    \n",
    "\n",
    "\n",
    "finalviscosityFn  = fn.branching.conditional([(depthFn < LOWMANTLEDEPTH, safe_visc(fn.misc.min(diffusion, yielding))),\n",
    "                                  (True, safe_visc(safe_visc(diffusion*ndp.low_mantle_visc_fac)))])\n",
    "\n",
    "#crust rheology    \n",
    "#finalcrustviscosityFn = safe_visc(fn.misc.min(ndp.eta_max_crust, \n",
    "#                                              crustyielding)) #cohesion weakening factor also applies to eta_0\n",
    "\n",
    "crustviscosityFn = safe_visc(fn.misc.min(linearviscosityFn, crustyielding), ndp.eta_max_crust)\n",
    "interfaceviscosityFn = safe_visc(fn.misc.min(linearviscosityFn, interfaceyielding), ndp.eta_max_interface)\n",
    "\n",
    "\n",
    "finalcrustviscosityFn  = fn.branching.conditional([(depthFn < MANTLETOCRUST, crustviscosityFn),\n",
    "                                                     (interfaceCond, interfaceviscosityFn), #\n",
    "                                                     (True, finalviscosityFn)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fig= glucifer.Figure()\n",
    "#fig.append( glucifer.objects.Points(gSwarm,finalviscosityFn, logScale=True))\n",
    "#fig.append( glucifer.objects.Surface(mesh,finalviscosityFn, logScale=True))\n",
    "#fig.append( glucifer.objects.VectorArrows(mesh,velocityField, scaling=0.05))\n",
    "\n",
    "\n",
    "#fig.show()\n",
    "#fig.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stokes system setup\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "densityMapFn = fn.branching.map( fn_key = materialVariable,\n",
    "                         mapping = {airIndex:ndp.StRA,\n",
    "                                    crustIndex:basaltbuoyancyFn, \n",
    "                                    mantleIndex:pyrolitebuoyancyFn,\n",
    "                                    harzIndex:harzbuoyancyFn} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define our vertical unit vector using a python tuple (this will be automatically converted to a function).\n",
    "gravity = ( 0.0, 1.0 )\n",
    "\n",
    "# Now create a buoyancy force vector using the density and the vertical unit vector. \n",
    "buoyancyFn = densityMapFn * gravity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stokesPIC = uw.systems.Stokes(velocityField=velocityField, \n",
    "                              pressureField=pressureField,\n",
    "                              conditions=[freeslipBC,],\n",
    "                              fn_viscosity=linearviscosityFn, \n",
    "                              fn_bodyforce=buoyancyFn )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solver = uw.systems.Solver(stokesPIC)\n",
    "if not checkpointLoad:\n",
    "    solver.solve() #A solve on the linear visocisty is unhelpful unless we're starting from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "viscosityMapFn1 = fn.branching.map( fn_key = materialVariable,\n",
    "                         mapping = {crustIndex:finalcrustviscosityFn,\n",
    "                                    mantleIndex:finalviscosityFn,\n",
    "                                    harzIndex:finalviscosityFn,\n",
    "                                    airIndex:ndp.Steta0} )\n",
    "\n",
    "if stickyAir:\n",
    "    viscosityMapFn2 = fn.branching.map( fn_key = materialVariable,\n",
    "                         mapping = {crustIndex:0.,\n",
    "                                    mantleIndex:0.,\n",
    "                                    harzIndex:0.,\n",
    "                                    airIndex:ndp.Steta0*0.9} ) # -> \\eta_2 = 0.1 * \\eta_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# director orientation in Sticky air\n",
    "if stickyAir:\n",
    "    directorVector   = gSwarm.add_variable( dataType=\"double\", count=2)\n",
    "\n",
    "    orientation = -1.*180. * math.pi / 180.0  #vertical\n",
    "    directorVector.data[:,0] = math.cos(orientation)\n",
    "    directorVector.data[:,1] = math.sin(orientation)\n",
    "    math.cos(orientation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#orientation = -1.*90. * math.pi / 180.0  #vertical\n",
    "#math.cos(orientation), math.sin(orientation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#stickyAir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Add the non-linear viscosity to the Stokes system\n",
    "stokesPIC.fn_viscosity = viscosityMapFn1\n",
    "\n",
    "if stickyAir: #If sticky air, add the Transverse anisotropic components to Stokes\n",
    "    stokesPIC.fn_viscosity2 = viscosityMapFn2\n",
    "    stokesPIC._fn_director   = directorVector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m\n",
      " \n",
      "Pressure iterations:   3\n",
      "Velocity iterations:   1 (presolve)      \n",
      "Velocity iterations:  -1 (pressure solve)\n",
      "Velocity iterations:   1 (backsolve)     \n",
      "Velocity iterations:   1 (total solve)   \n",
      " \n",
      "SCR RHS  solve time: 4.4012e-01\n",
      "Pressure solve time: 3.2451e-02\n",
      "Velocity solve time: 4.4022e-01 (backsolve)\n",
      "Total solve time   : 9.7181e-01\n",
      " \n",
      "Velocity solution min/max: 0.0000e+00/0.0000e+00\n",
      "Pressure solution min/max: 0.0000e+00/0.0000e+00\n",
      " \n",
      "\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "solver.set_inner_method(\"mumps\")\n",
    "solver.options.scr.ksp_type=\"cg\"\n",
    "solver.set_penalty(1.0e7)\n",
    "solver.options.scr.ksp_rtol = 1.0e-4\n",
    "solver.solve(nonLinearIterate=True)\n",
    "solver.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fig= glucifer.Figure()\n",
    "#fig.append( glucifer.objects.Points(gSwarm,viscosityMapFn1, logScale=True))\n",
    "#fig.append( glucifer.objects.Surface(mesh,temperatureField))\n",
    "#fig.append( glucifer.objects.VectorArrows(mesh,velocityField, scaling=0.05))\n",
    "\n",
    "\n",
    "#fig.show()\n",
    "#fig.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check which particles are yielding\n",
    "#yieldingCheck.data[:] = 0\n",
    "\n",
    "#yieldconditions = [ ( finalviscosityFn < Visc , 1), \n",
    "#               ( True                                           , 0) ]\n",
    "\n",
    "# use the branching conditional function to set each particle's index\n",
    "#yieldingCheck.data[:] = fn.branching.conditional( yieldconditions ).evaluate(gSwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fig= glucifer.Figure()\n",
    "#fig.append( glucifer.objects.Points(gSwarm,yieldingCheck))\n",
    "\n",
    "#fig.append( glucifer.objects.Surface(mesh,ndflm, logScale=True))\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advection-diffusion System setup\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "advDiff = uw.systems.AdvectionDiffusion( phiField       = temperatureField, \n",
    "                                         phiDotField    = temperatureDotField, \n",
    "                                         velocityField  = velocityField,\n",
    "                                         fn_sourceTerm    = 0.0,\n",
    "                                         fn_diffusivity = 1.0, \n",
    "                                         #conditions     = [neumannTempBC, dirichTempBC] )\n",
    "                                         conditions     = [ dirichTempBC] )\n",
    "\n",
    "passiveadvector = uw.systems.SwarmAdvector( swarm         = gSwarm, \n",
    "                                     velocityField = velocityField, \n",
    "                                     order         = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#I was playing around with a tailored diffusivity to target the slab\n",
    "\n",
    "#inCircleFnGenerator#Now build the perturbation part\n",
    "#def htan(centre, radius, widthPh, farVal = 0.01, fac = 10.):\n",
    "#    coord = fn.input()\n",
    "#    offsetFn = coord - centre\n",
    "#    dist = fn.math.sqrt(fn.math.dot( offsetFn, offsetFn ))\n",
    "    \n",
    "    \n",
    "#    return (((fn.math.tanh(((radius - dist))/widthPh) + 1.) /2.))*fac + farVal\n",
    "\n",
    "#tfun = htan((0.1, 0.9), 0.1, 0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index in mesh.specialSets[\"MinJ_VertexSet\"]:\n",
    "    temperatureField.data[index] = ndp.TBP\n",
    "for index in mesh.specialSets[\"MaxJ_VertexSet\"]:\n",
    "    temperatureField.data[index] = ndp.TSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "velocityField.data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############\n",
    "#Slightly Diffuse the initial perturbation\n",
    "#############\n",
    "\n",
    "timetoDifffuse = 0.#Million years\n",
    "incrementtoDiffuse = 0.2 #Million years\n",
    "\n",
    "timetoDifffuse = (timetoDifffuse*1e6*(spery)/sf.SR).magnitude\n",
    "incrementtoDiffuse = (incrementtoDiffuse*1e6*(spery)/sf.SR).magnitude\n",
    "\n",
    "totAdt = 0.\n",
    "it = 0\n",
    "while totAdt < timetoDifffuse:\n",
    "    dtad = advDiff.get_max_dt()\n",
    "    print(\"step\") + str(it) \n",
    "    advDiff.integrate(incrementtoDiffuse)\n",
    "    totAdt += incrementtoDiffuse\n",
    "    it += 1\n",
    "    \n",
    "#Reset Boundary conds.   \n",
    "for index in mesh.specialSets[\"MinJ_VertexSet\"]:\n",
    "    temperatureField.data[index] = ndp.TBP\n",
    "for index in mesh.specialSets[\"MaxJ_VertexSet\"]:\n",
    "    temperatureField.data[index] = ndp.TSP\n",
    "    \n",
    "comm.Barrier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "population_control = uw.swarm.PopulationControl(gSwarm,deleteThreshold=0.2,splitThreshold=1.,maxDeletions=3,maxSplits=0, aggressive=True, particlesPerCell=ppc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis functions / routines\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#These are functions we can use to evuate integrals over restricted parts of the domain\n",
    "# For instance, we can exclude the thermal lithosphere from integrals\n",
    "\n",
    "def temprestrictionFn(lithval = 0.9):\n",
    "\n",
    "    tempMM = fn.view.min_max(temperatureField)\n",
    "    tempMM.evaluate(mesh)\n",
    "    TMAX = tempMM.max_global()\n",
    "    mantleconditions = [ (                                  temperatureField > lithval*TMAX, 1.),\n",
    "                   (                                                   True , 0.) ]\n",
    "\n",
    "\n",
    "    return fn.branching.conditional(mantleconditions)\n",
    "\n",
    "mantlerestrictFn = temprestrictionFn(lithval = 0.85)\n",
    "\n",
    "\n",
    "\n",
    "def platenessFn(val = 0.1):\n",
    "    normgradV = fn.math.abs(velocityField.fn_gradient[0]/fn.math.sqrt(velocityField[0]*velocityField[0])) #[du*/dx]/sqrt(u*u)\n",
    "\n",
    "\n",
    "\n",
    "    srconditions = [ (                                  normgradV < val, 1.),\n",
    "                   (                                                   True , 0.) ]\n",
    "\n",
    "\n",
    "    return fn.branching.conditional(srconditions)\n",
    "\n",
    "srrestrictFn = platenessFn(val = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setup volume integrals \n",
    "\n",
    "tempint = uw.utils.Integral( temperatureField, mesh )\n",
    "areaint = uw.utils.Integral( 1.,               mesh )\n",
    "\n",
    "v2int   = uw.utils.Integral( fn.math.dot(velocityField,velocityField), mesh )\n",
    "\n",
    "dwint   = uw.utils.Integral( temperatureField*velocityField[1], mesh )\n",
    "\n",
    "sinner = fn.math.dot( strainRate_2ndInvariant, strainRate_2ndInvariant )\n",
    "vdint = uw.utils.Integral( (2.*viscosityMapFn1*sinner), mesh ) #Is it two or four here?\n",
    "\n",
    "mantleArea   = uw.utils.Integral( mantlerestrictFn, mesh )\n",
    "mantleTemp = uw.utils.Integral( temperatureField*mantlerestrictFn, mesh )\n",
    "mantleVisc = uw.utils.Integral( finalviscosityFn*mantlerestrictFn, mesh )\n",
    "mantleVd = uw.utils.Integral( (2.*viscosityMapFn1*sinner*mantlerestrictFn), mesh ) #these now work on MappingFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setup surface integrals\n",
    "\n",
    "rmsSurfInt = uw.utils.Integral( fn=velocityField[0]*velocityField[0], mesh=mesh, integrationType='Surface', \n",
    "                          surfaceIndexSet=mesh.specialSets[\"MaxJ_VertexSet\"])\n",
    "nuTop      = uw.utils.Integral( fn=temperatureField.fn_gradient[1],    mesh=mesh, integrationType='Surface', \n",
    "                          surfaceIndexSet=mesh.specialSets[\"MaxJ_VertexSet\"])\n",
    "nuBottom   = uw.utils.Integral( fn=temperatureField.fn_gradient[1],    mesh=mesh, integrationType='Surface', \n",
    "                          surfaceIndexSet=mesh.specialSets[\"MinJ_VertexSet\"])\n",
    "\n",
    "plateint  = uw.utils.Integral( fn=srrestrictFn, mesh=mesh, integrationType='Surface', #Integrate the plateness function\n",
    "                          surfaceIndexSet=mesh.specialSets[\"MaxJ_VertexSet\"]) \n",
    "\n",
    "surfint  = uw.utils.Integral( fn=1., mesh=mesh, integrationType='Surface',   #Surface length function (i.e. domain width)\n",
    "                          surfaceIndexSet=mesh.specialSets[\"MaxJ_VertexSet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define functions for the evaluation of integrals\n",
    "\n",
    "def basic_int(ourIntegral):           #This one just hands back the evaluated integral\n",
    "    return ourIntegral.evaluate()[0]\n",
    "\n",
    "def avg_temp():\n",
    "    return tempint.evaluate()[0]/areaint.evaluate()[0]\n",
    "\n",
    "def nusseltTB(temp_field, mesh):\n",
    "    return -nuTop.evaluate()[0], -nuBottom.evaluate()[0]\n",
    "\n",
    "def rms():\n",
    "    return math.sqrt(v2int.evaluate()[0]/areaint.evaluate()[0])\n",
    "\n",
    "def rms_surf():\n",
    "    return math.sqrt(rmsSurfInt.evaluate()[0])\n",
    "\n",
    "def max_vx_surf(velfield, mesh):\n",
    "    vuvelxfn = fn.view.min_max(velfield[0])\n",
    "    vuvelxfn.evaluate(mesh.specialSets[\"MaxJ_VertexSet\"])\n",
    "    return vuvelxfn.max_global()\n",
    "\n",
    "\n",
    "def visc_extr(viscfn):\n",
    "    vuviscfn = fn.view.min_max(viscfn)\n",
    "    vuviscfn.evaluate(mesh)\n",
    "    return vuviscfn.max_global(), vuviscfn.min_global()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#v2sum_integral  = uw.utils.Integral( mesh=mesh, fn=fn.math.dot( velocityField, velocityField ) )\n",
    "#volume_integral = uw.utils.Integral( mesh=mesh, fn=1. )\n",
    "#Vrms = math.sqrt( v2sum_integral.evaluate()[0] )/volume_integral.evaluate()[0]\n",
    "\n",
    "\n",
    "\n",
    "#if(uw.rank()==0):\n",
    "#    print('Initial Vrms = {0:.3f}'.format(Vrms))\n",
    "\n",
    "# Check the Metrics\n",
    "\n",
    "#Avg_temp = avg_temp()\n",
    "Rms = rms()\n",
    "Rms_surf = rms_surf()\n",
    "Max_vx_surf = max_vx_surf(velocityField, mesh)\n",
    "Rms, Rms_surf, Max_vx_surf \n",
    "#Gravwork = basic_int(dwint)\n",
    "#Viscdis = basic_int(vdint)\n",
    "#nu1, nu0 = nusseltTB(temperatureField, mesh) # return top then bottom\n",
    "#etamax, etamin = visc_extr(finalviscosityFn)\n",
    "\n",
    "#Area_mantle = basic_int(mantleArea)\n",
    "#Viscmantle = basic_int(mantleVisc)\n",
    "#Tempmantle = basic_int(mantleTemp)\n",
    "#Viscdismantle = basic_int(mantleVd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viz.\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#viscVariable = gSwarm.add_variable( dataType=\"float\", count=1 )\n",
    "#viscVariable.data[:] = viscosityMapFn1.evaluate(gSwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if figures == 'gldb':\n",
    "    #Pack some stuff into a database as well\n",
    "    figDb = glucifer.Figure()\n",
    "    #figDb.append( glucifer.objects.Mesh(mesh))\n",
    "    figDb.append( glucifer.objects.VectorArrows(mesh,velocityField, scaling=0.0005))\n",
    "    #figDb.append( glucifer.objects.Points(gSwarm,tracerVariable, colours= 'white black'))\n",
    "    figDb.append( glucifer.objects.Points(gSwarm,materialVariable))\n",
    "    #figDb.append( glucifer.objects.Points(gSwarm,viscMinVariable))\n",
    "    #figDb.append( glucifer.objects.Points(gSwarm,fnViscMin))\n",
    "    figDb.append( glucifer.objects.Points(gSwarm,viscosityMapFn1, logScale=True))\n",
    "    #figDb.append( glucifer.objects.Points(gSwarm, strainRate_2ndInvariant, logScale=True))\n",
    "    figDb.append( glucifer.objects.Points(gSwarm,temperatureField))\n",
    "\n",
    "elif figures == 'store':\n",
    "    fullpath = os.path.join(outputPath + \"gldbs/\")\n",
    "    store = glucifer.Store(fullpath + 'subduction')\n",
    "\n",
    "    figTemp = glucifer.Figure(store,figsize=(300*np.round(aspectRatio,2),300))\n",
    "    figTemp.append( glucifer.objects.Points(gSwarm,temperatureField))\n",
    "\n",
    "    figVisc= glucifer.Figure(store, figsize=(300*np.round(aspectRatio,2),300))\n",
    "    figVisc.append( glucifer.objects.Points(gSwarm,viscosityMapFn1, logScale=True, valueRange =[1e-3,1e5]))\n",
    "\n",
    "    #figMech= glucifer.Figure(store, figsize=(300*np.round(aspectRatio,2),300))\n",
    "    #figMech.append( glucifer.objects.Points(gSwarm,fnViscMin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#Create a numpy array at the surface to get surface information on (using parallel-friendly evaluate_global)\n",
    "##############\n",
    "\n",
    "surface_xs = np.linspace(mesh.minCoord[0], mesh.maxCoord[0], mesh.elementRes[0] + 1)\n",
    "surface_nodes = np.array(zip(surface_xs, np.ones(len(surface_xs)*mesh.maxCoord[1]))) #For evaluation surface velocity\n",
    "normgradV = velocityField.fn_gradient[0]/fn.math.sqrt(velocityField[0]*velocityField[0])\n",
    "\n",
    "tempMM = fn.view.min_max(temperatureField)\n",
    "dummy = tempMM.evaluate(mesh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Miscellania**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#These functions handle checkpointing\n",
    "##############\n",
    "\n",
    "\n",
    "def checkpoint1(step, checkpointPath,filename, filewrites):\n",
    "    path = checkpointPath + str(step) \n",
    "    os.mkdir(path)\n",
    "    ##Write and save the file, if not already a writing step\n",
    "    if not step % filewrites == 0:\n",
    "        filename.write((18*'%-15s ' + '\\n') % (realtime, Viscdis, float(nu0), float(nu1), Avg_temp,\n",
    "                                              Tempmantle,TMAX,\n",
    "                                              Rms,Rms_surf,Max_vx_surf,Gravwork, etamax, etamin, \n",
    "                                              Area_mantle, Viscmantle,  Viscdismantle,Plateness, subzone ))\n",
    "    filename.close()\n",
    "    shutil.copyfile(os.path.join(outputPath, outputFile), os.path.join(path, outputFile))\n",
    "\n",
    "\n",
    "def checkpoint2(step, checkpointPath, swarm, filename, varlist = [materialVariable], varnames = ['materialVariable']):\n",
    "    path = checkpointPath + str(step) \n",
    "    velfile = \"velocityField\" + \".hdf5\"\n",
    "    tempfile = \"temperatureField\" + \".hdf5\"\n",
    "    pressfile = \"pressureField\" + \".hdf5\"\n",
    "    velocityField.save(os.path.join(path, velfile))\n",
    "    temperatureField.save(os.path.join(path, tempfile))\n",
    "    pressureField.save(os.path.join(path, pressfile))\n",
    "    swarm.save(os.path.join(path, \"swarm.h5\") ) \n",
    "    for ix in range(len(varlist)):\n",
    "        varb = varlist[ix]\n",
    "        varb.save(os.path.join(path,varnames[ix] + \".h5\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#These functions handle checkpointing\n",
    "##############\n",
    "\n",
    "def getnearpos(array,value):\n",
    "    idx = (np.abs(array-value)).argmin()\n",
    "    return idx \n",
    "\n",
    "def plate_info(srfilename, minx, maxx,  searchdx, oldszloc = 0.0):\n",
    "    \"\"\"\n",
    "    Use the surface strain rate field to find the location of the subduction zone in 2d\n",
    "    \n",
    "    \"\"\"\n",
    "    if type(srfilename) == str: #read surface strain rate points from file\n",
    "        sr = np.load(srfilename)\n",
    "    else:\n",
    "        sr =  srfilename        #read surface strain rates directly from array\n",
    "    xs = np.linspace(minx,maxx,sr.shape[0] )\n",
    "    #infs at the ends of the SR data...replace with adjacent values\n",
    "    sr[0] = sr[1] \n",
    "    sr[-1] = sr[2]\n",
    "    #Normalize\n",
    "    srx = (sr- sr.mean()) /(sr.max() - sr.min())\n",
    "    #reduce the search domain, to near the previous PB location\n",
    "    lx, rx = getnearpos(xs, oldszloc - searchdx),  getnearpos(xs, oldszloc + searchdx)\n",
    "    red_xs, red_sr = xs[lx:rx], srx[lx:rx]\n",
    "    #return the minima\n",
    "    newszLoc = red_xs[np.argmin(red_sr)]\n",
    "    return newszLoc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialise timer for computation\n",
    "start = time.clock()\n",
    "# setup summary output file (name above)\n",
    "if checkpointLoad:\n",
    "    if uw.rank() == 0:\n",
    "        shutil.copyfile(os.path.join(checkpointLoadDir, outputFile), outputPath+outputFile)\n",
    "    comm.Barrier()\n",
    "    f_o = open(os.path.join(outputPath, outputFile), 'a')\n",
    "    prevdata = np.genfromtxt(os.path.join(outputPath, outputFile), skip_header=0, skip_footer=0)\n",
    "    if len(prevdata.shape) == 1: #this is in case there is only one line in previous file\n",
    "        realtime = prevdata[0]\n",
    "    else:\n",
    "        realtime = prevdata[prevdata.shape[0]-1, 0]\n",
    "    step = int(checkpointLoadDir.split('/')[-1])\n",
    "    timevals = [0.]\n",
    "else:\n",
    "    f_o = open(outputPath+outputFile, 'w')\n",
    "    realtime = 0.\n",
    "    step = 0\n",
    "    timevals = [0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main simulation loop\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#while step < 6:\n",
    "while realtime < 1.:\n",
    "\n",
    "    # solve Stokes and advection systems\n",
    "    solver.solve(nonLinearIterate=True)\n",
    "    dt = advDiff.get_max_dt()\n",
    "    if step == 0:\n",
    "        dt = 0.\n",
    "    advDiff.integrate(dt)\n",
    "    passiveadvector.integrate(dt)\n",
    "    \n",
    "    # Increment\n",
    "    realtime += dt\n",
    "    step += 1\n",
    "    timevals.append(realtime)\n",
    "    ################\n",
    "    #Update temperature field in the air region\n",
    "    #Do this better...\n",
    "    ################\n",
    "    if (step % sticky_air_temp == 0):\n",
    "        for index, coord in enumerate(mesh.data):\n",
    "            if coord[1] >= 1.:\n",
    "                temperatureField.data[index] = ndp.TSP\n",
    "\n",
    "    # Calculate the Metrics, only on 1 of the processors:\n",
    "    ################\n",
    "    if (step % metric_output == 0):\n",
    "        ###############\n",
    "        #Swarm - based Metrics\n",
    "        ###############\n",
    "        # Calculate the RMS velocity and Nusselt number.\n",
    "        # Calculate the Metrics, only on 1 of the processors:\n",
    "        mantlerestrictFn = temprestrictionFn() #rebuild the mantle restriction function (but these should be dynamic?)\n",
    "        srrestrictFn = platenessFn(val = 0.1) #rebuild the plateness restriction function\n",
    "        dummy = tempMM.evaluate(mesh) #Re-evaluate any fn.view.min_max guys\n",
    "        #Rebuild these integrals (a test because metrics changes after a restart)\n",
    "        mantleArea   = uw.utils.Integral( mantlerestrictFn, mesh )\n",
    "        mantleTemp = uw.utils.Integral( temperatureField*mantlerestrictFn, mesh )\n",
    "        mantleVisc = uw.utils.Integral( finalviscosityFn*mantlerestrictFn, mesh )\n",
    "        mantleVd = uw.utils.Integral( (4.*viscosityMapFn1*sinner*mantlerestrictFn), mesh ) #these now work on MappingFunctions\n",
    "        ###\n",
    "        Avg_temp = avg_temp()\n",
    "        Rms = rms()\n",
    "        Rms_surf = rms_surf()\n",
    "        Max_vx_surf = max_vx_surf(velocityField, mesh)\n",
    "        Gravwork = basic_int(dwint)\n",
    "        Viscdis = basic_int(vdint)\n",
    "        nu1, nu0 = nusseltTB(temperatureField, mesh) # return top then bottom\n",
    "        etamax, etamin = visc_extr(finalviscosityFn)\n",
    "        Area_mantle = basic_int(mantleArea)\n",
    "        Viscmantle = basic_int(mantleVisc)\n",
    "        Tempmantle = basic_int(mantleTemp)\n",
    "        Viscdismantle = basic_int(mantleVd)\n",
    "        Plateness = basic_int(plateint)/basic_int(surfint)\n",
    "        TMAX = tempMM.max_global()\n",
    "        # output to summary text file\n",
    "        if uw.rank()==0:\n",
    "            f_o.write((18*'%-15s ' + '\\n') % (realtime, Viscdis, float(nu0), float(nu1), Avg_temp,\n",
    "                                              Tempmantle,TMAX,\n",
    "                                              Rms,Rms_surf,Max_vx_surf,Gravwork, etamax, etamin, \n",
    "                                              Area_mantle, Viscmantle,  Viscdismantle,Plateness, subzone ))\n",
    "    ################\n",
    "    #Also repopulate entire swarm periodically\n",
    "    ################\n",
    "    #if step % swarm_repop == 0:\n",
    "    population_control.repopulate()   \n",
    "    ################\n",
    "    #Checkpoint\n",
    "    ################\n",
    "    if step % checkpoint_every == 0:\n",
    "        if uw.rank() == 0:\n",
    "            checkpoint1(step, checkpointPath,f_o, metric_output)           \n",
    "        checkpoint2(step, checkpointPath, gSwarm, f_o, varlist = varlist, varnames = varnames)\n",
    "        f_o = open(os.path.join(outputPath, outputFile), 'a') #is this line supposed to be here?\n",
    "    ################\n",
    "    #Gldb output\n",
    "    ################ \n",
    "    if (step % gldbs_output == 0): \n",
    "        if figures == 'gldb':\n",
    "            #Remember to rebuild any necessary swarm variables\n",
    "            fnamedb = \"dbFig\" + \"_\" + str(ModIt) + \"_\" + str(step) + \".gldb\"\n",
    "            fullpath = os.path.join(outputPath + \"gldbs/\" + fnamedb)\n",
    "            figDb.save_database(fullpath)\n",
    "        elif figures == 'store':      \n",
    "            fullpath = os.path.join(outputPath + \"gldbs/\")\n",
    "            store.step = step\n",
    "            #Save figures to store\n",
    "            figVisc.save( fullPath + \"Visc\" + str(step).zfill(4))\n",
    "            #figMech.save( fullPath + \"Mech\" + str(step).zfill(4))\n",
    "            figTemp.save(    outputPath + \"Temp\"    + str(step).zfill(4))\n",
    "    ################\n",
    "    #Files output\n",
    "    ################ \n",
    "    if (step % files_output == 0):\n",
    "\n",
    "        vel_surface = velocityField.evaluate_global(surface_nodes)\n",
    "        norm_surface_sr = normgradV.evaluate_global(surface_nodes)\n",
    "        if uw.rank() == 0:\n",
    "            fnametemp = \"velsurface\" + \"_\" + str(ModIt) + \"_\" + str(step)\n",
    "            fullpath = os.path.join(outputPath + \"files/\" + fnametemp)\n",
    "            np.save(fullpath, vel_surface)\n",
    "            fnametemp = \"norm_surface_sr\" + \"_\" + str(ModIt) + \"_\" + str(step)\n",
    "            fullpath = os.path.join(outputPath + \"files/\" + fnametemp)\n",
    "            np.save(fullpath, norm_surface_sr)\n",
    "            \n",
    "    ################\n",
    "    #Update the subduction zone / plate information\n",
    "    ################ \n",
    "    \n",
    "    comm.barrier()\n",
    "    if (step % files_output == 0):\n",
    "        \n",
    "        if uw.rank() == 0:\n",
    "            fnametemp = \"norm_surface_sr\" + \"_\" + str(ModIt) + \"_\" + str(step) + \".npy\"\n",
    "            fullpath = os.path.join(outputPath + \"files/\" + fnametemp)\n",
    "            subzone = plate_info(fullpath, MINX, MAXX,  200e3/dp.LS, oldszloc = subzone)\n",
    "            \n",
    "        else:\n",
    "            subzone = None\n",
    "        \n",
    "        comm.barrier()    \n",
    "        #send out the updated info for sz location\n",
    "        \n",
    "        subzone = comm.bcast(subzone, root=0)\n",
    "\n",
    "        #Has the polarity reversed?\n",
    "\n",
    "        if sense == 'right':\n",
    "            tempop = operator.lt\n",
    "            szoffet *= -1\n",
    "        else:\n",
    "            tempop = operator.gt\n",
    "            \n",
    "        #Update the relevant parts of the material graph\n",
    "        #Remove and rebuild edges related to crust\n",
    "        DG.remove_edges_from([(mantleIndex,crustIndex)])\n",
    "        DG.add_edges_from([(mantleIndex,crustIndex)])\n",
    "        DG.remove_edges_from([(harzIndex,crustIndex)])\n",
    "        DG.add_edges_from([(harzIndex,crustIndex)])\n",
    "\n",
    "        #... to crust\n",
    "        DG.add_transition((mantleIndex,crustIndex), depthFn, operator.lt, 0.5)\n",
    "        DG.add_transition((mantleIndex,crustIndex), xFn, tempop , subzone) #No crust on the upper plate\n",
    "        DG.add_transition((mantleIndex,crustIndex), ageVariable, operator.gt, 0.2)\n",
    "\n",
    "        DG.add_transition((harzIndex,crustIndex), depthFn, operator.lt, MANTLETOCRUST)\n",
    "        DG.add_transition((harzIndex,crustIndex), xFn, tempop, subzone) #This one sets no crust on the upper plate\n",
    "        DG.add_transition((harzIndex,crustIndex), ageVariable, operator.gt, crustageCond)\n",
    "        \n",
    "        comm.barrier()\n",
    "                   \n",
    "    \n",
    "    ################\n",
    "    #Particle update\n",
    "    ###############    \n",
    "    #ageVariable.data[:] += dt #increment the ages (is this efficient?)\n",
    "    ageDT += dt\n",
    "    \n",
    "    if step % swarm_update == 0:\n",
    "        #Increment age stuff. \n",
    "        ageConditions = [ (depthFn < AGETRACKDEPTH, ageVariable + ageDT ),  #add ageDThere\n",
    "                  (True, 0.) ]\n",
    "        ageVariable.data[:] = fn.branching.conditional( ageConditions ).evaluate(gSwarm)        \n",
    "        ageDT = 0. #reset the age incrementer\n",
    "        \n",
    "        #Apply any materialVariable changes\n",
    "        for i in range(2): #go through twice\n",
    "            materialVariable.data[:] = fn.branching.conditional(DG.condition_list).evaluate(gSwarm)\n",
    "\n",
    "    \n",
    "f_o.close()\n",
    "print 'step =',step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comm.Bcast?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saved = glucifer.Viewer('subduction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saved.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Re-visualise the final timestep\n",
    "saved.step = saved.steps[-1]\n",
    "for name in saved:\n",
    "    print(name)\n",
    "    fig = saved[name]\n",
    "    fig.quality = 2\n",
    "    fig.properties[\"title\"] = \"Timestep ##\"\n",
    "    fig.show()\n",
    "    fig.save_image(name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figDb.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vel_surface = velocityField.evaluate_global(surface_nodes)\n",
    "norm_surface_sr = normgradV.evaluate_global(surface_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x180 = np.copy(vel_surface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x90 = np.copy(vel_surface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(x180[:,0])\n",
    "plt.plot(x90[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vel_surface.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.1844729438857158"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#velocityField.evaluate(iWalls).mean()/ velocityField.evaluate(mesh).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
