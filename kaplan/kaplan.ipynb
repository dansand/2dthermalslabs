{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thermal subduction, linear rheology:\n",
    "\n",
    "\n",
    "The viscous rheology in this model is similar to the models described in the PhD thesis of Micheal Kaplan\n",
    "\n",
    "\n",
    "\n",
    "**Keywords:** subduction, thermally-activated creep, \n",
    "\n",
    "\n",
    "**References:**\n",
    "\n",
    "\n",
    "Kaplan, Michael. Numerical Geodynamics of Solid Planetary Deformation. Diss. University of Southern California, 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import underworld as uw\n",
    "import math\n",
    "from underworld import function as fn\n",
    "import glucifer\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import natsort\n",
    "import shutil\n",
    "from easydict import EasyDict as edict\n",
    "import operator\n",
    "import pint\n",
    "import time\n",
    "import operator\n",
    "from slippy2 import boundary_layer2d\n",
    "from slippy2 import material_graph\n",
    "from slippy2 import spmesh\n",
    "from slippy2 import phase_function\n",
    "from unsupported.interfaces import markerLine2D\n",
    "\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model name and directories\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############\n",
    "#Model letter and number\n",
    "############\n",
    "\n",
    "\n",
    "#Model letter identifier default\n",
    "Model = \"T\"\n",
    "\n",
    "#Model number identifier default:\n",
    "ModNum = 0\n",
    "\n",
    "#Any isolated letter / integer command line args are interpreted as Model/ModelNum\n",
    "\n",
    "if len(sys.argv) == 1:\n",
    "    ModNum = ModNum \n",
    "elif sys.argv[1] == '-f': #\n",
    "    ModNum = ModNum \n",
    "else:\n",
    "    for farg in sys.argv[1:]:\n",
    "        if not '=' in farg: #then Assume it's a not a paramter argument\n",
    "            try:\n",
    "                ModNum = int(farg) #try to convert everingthing to a float, else remains string\n",
    "            except ValueError:\n",
    "                Model  = farg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Standard output directory setup\n",
    "###########\n",
    "\n",
    "\n",
    "outputPath = \"results\" + \"/\" +  str(Model) + \"/\" + str(ModNum) + \"/\" \n",
    "imagePath = outputPath + 'images/'\n",
    "filePath = outputPath + 'files/'\n",
    "checkpointPath = outputPath + 'checkpoint/'\n",
    "dbPath = outputPath + 'gldbs/'\n",
    "outputFile = 'results_model' + Model + '_' + str(ModNum) + '.dat'\n",
    "\n",
    "if uw.rank()==0:\n",
    "    # make directories if they don't exist\n",
    "    if not os.path.isdir(outputPath):\n",
    "        os.makedirs(outputPath)\n",
    "    if not os.path.isdir(checkpointPath):\n",
    "        os.makedirs(checkpointPath)\n",
    "    if not os.path.isdir(imagePath):\n",
    "        os.makedirs(imagePath)\n",
    "    if not os.path.isdir(dbPath):\n",
    "        os.makedirs(dbPath)\n",
    "    if not os.path.isdir(filePath):\n",
    "        os.makedirs(filePath)\n",
    "\n",
    "        \n",
    "comm.Barrier() #Barrier here so no procs run the check in the next cell too early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/T/0/checkpoint/ is empty\n",
      "results/T/0/checkpoint/10 has files\n",
      "results/T/0/checkpoint/20 has files\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "#Check if starting from checkpoint\n",
    "###########\n",
    "\n",
    "checkdirs = []\n",
    "for dirpath, dirnames, files in os.walk(checkpointPath):\n",
    "    if files:\n",
    "        print dirpath, 'has files'\n",
    "        checkpointLoad = True\n",
    "        checkdirs.append(dirpath)\n",
    "    if not files:\n",
    "        print dirpath, 'is empty'\n",
    "        checkpointLoad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup summary output file (name above)\n",
    "if checkpointLoad:\n",
    "    checkpointLoadDir = natsort.natsort(checkdirs)[-1]\n",
    "    if uw.rank() == 0:\n",
    "        shutil.copyfile(os.path.join(checkpointLoadDir, outputFile), outputPath+outputFile)\n",
    "    comm.Barrier()\n",
    "    f_o = open(os.path.join(outputPath, outputFile), 'a')\n",
    "    prevdata = np.genfromtxt(os.path.join(outputPath, outputFile), skip_header=0, skip_footer=0)\n",
    "    if len(prevdata.shape) == 1: #this is in case there is only one line in previous file\n",
    "        realtime = prevdata[-1]\n",
    "    else:\n",
    "        realtime = prevdata[prevdata.shape[0]-1, -1]\n",
    "    step = int(checkpointLoadDir.split('/')[-1])\n",
    "    timevals = [0.]\n",
    "else:\n",
    "    f_o = open(outputPath+outputFile, 'w')\n",
    "    realtime = 0.\n",
    "    step = 0\n",
    "    timevals = [0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup parameters\n",
    "-----\n",
    "\n",
    "Set simulation parameters for test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use pint to setup any unit conversions we'll need**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:92: DeprecationWarning: DisplayFormatter._ipython_display_formatter_default is deprecated: use @default decorator instead.\n",
      "  def _ipython_display_formatter_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:98: DeprecationWarning: DisplayFormatter._formatters_default is deprecated: use @default decorator instead.\n",
      "  def _formatters_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:669: DeprecationWarning: PlainTextFormatter._singleton_printers_default is deprecated: use @default decorator instead.\n",
      "  def _singleton_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:672: DeprecationWarning: PlainTextFormatter._type_printers_default is deprecated: use @default decorator instead.\n",
      "  def _type_printers_default(self):\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/core/formatters.py:677: DeprecationWarning: PlainTextFormatter._deferred_printers_default is deprecated: use @default decorator instead.\n",
      "  def _deferred_printers_default(self):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "10000.0 meter/megayear"
      ],
      "text/latex": [
       "$10000.0 \\frac{meter}{megayear}$"
      ],
      "text/plain": [
       "<Quantity(10000.0, 'meter / megayear')>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = pint.UnitRegistry()\n",
    "cmpery = 1.*u.cm/u.year\n",
    "mpermy = 1.*u.m/u.megayear\n",
    "year = 1.*u.year\n",
    "spery = year.to(u.sec)\n",
    "cmpery.to(mpermy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.04, 1.2675505856327397e-11)\n"
     ]
    }
   ],
   "source": [
    "box_half_width =4000e3\n",
    "age_at_trench = 100e6\n",
    "cmperyear = box_half_width / age_at_trench #m/y\n",
    "mpersec = cmperyear*(cmpery.to(u.m/u.second)).magnitude #m/sec\n",
    "print(cmperyear, mpersec )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set parameter dictionaries**\n",
    "\n",
    "* Parameters are stored in dictionaries. \n",
    "* If starting from checkpoint, parameters are loaded using pickle\n",
    "* If params are passed in as flags to the script, they overwrite \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Parameter / settings dictionaries get saved&loaded using pickle\n",
    "###########\n",
    " \n",
    "dp = edict({}) #dimensional parameters\n",
    "sf = edict({}) #scaling factors\n",
    "ndp = edict({}) #dimensionless paramters\n",
    "md = edict({}) #model paramters, flags etc\n",
    "#od = edict({}) #output frequencies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_list = [dp, sf, ndp, md]\n",
    "dict_names = ['dp.pkl', 'sf.pkl', 'ndp.pkl', 'md.pkl']\n",
    "\n",
    "def save_pickles(dict_list, dict_names, dictPath):\n",
    "    import pickle\n",
    "    counter = 0\n",
    "    for pdict in dict_list:\n",
    "        myfile = os.path.join(dictPath, dict_names[counter])\n",
    "        with open(myfile, 'wb') as f:\n",
    "            pickle.dump(pdict, f)\n",
    "        counter+=1\n",
    "\n",
    "\n",
    "#ended up having to pretty much write a hard-coded function\n",
    "#All dictionaries we want checkpointed will have to  be added here \n",
    "#and where the function is called\n",
    "#Fortunately, this function is only called ONCE\n",
    "\n",
    "def load_pickles():\n",
    "    import pickle\n",
    "    dirpath = os.path.join(checkpointPath, str(step))\n",
    "    dpfile = open(os.path.join(dirpath, 'dp.pkl'), 'r')\n",
    "    dp = pickle.load(dpfile)\n",
    "#    #\n",
    "    ndpfile = open(os.path.join(dirpath, 'ndp.pkl'), 'r')\n",
    "    ndp = edict(pickle.load(ndpfile))\n",
    "    #\n",
    "    sffile = open(os.path.join(dirpath, 'sf.pkl'), 'r')\n",
    "    sf = edict(pickle.load(sffile))\n",
    "    #\n",
    "    mdfile = open(os.path.join(dirpath, 'md.pkl'), 'r')\n",
    "    md = edict(pickle.load(mdfile))\n",
    "    return dp, ndp, sf, md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Store the physical parameters, scale factors and dimensionless pramters in easyDicts\n",
    "#Mainly helps with avoiding overwriting variables\n",
    "###########\n",
    "\n",
    "\n",
    "dp = edict({'LS':670*1e3, #Scaling Length scale\n",
    "            'depth':670*1e3, #Depth of domain\n",
    "            'rho':3300.,  #reference density\n",
    "            'g':9.8, #surface gravity\n",
    "            'eta0':1e20, #reference viscosity\n",
    "            'k':1e-6, #thermal diffusivity\n",
    "            'a':3e-5, #surface thermal expansivity\n",
    "            'R':8.314, #gas constant\n",
    "            'TP':1673., #mantle potential temp (K)\n",
    "            'TS':273., #surface temp (K)\n",
    "            #Rheology - flow law paramters\n",
    "            'Adf':3e-11, #pre-exp factor for diffusion creep\n",
    "            'Edf':1e5, #Total viscosity variation in the Kaplan model\n",
    "            'cm':40e6, #mantle cohesion in Byerlee law\n",
    "            'cc':40e6, #mantle cohesion in Byerlee law\n",
    "            'ci':40e6, #mantle cohesion in Byerlee law\n",
    "            'cf':40e6, #mantle cohesion in Byerlee law\n",
    "            'fcm':0.03,   #mantle friction coefficient in Byerlee law (tan(phi))\n",
    "            'fcc':0.03,   #crust friction coefficient \n",
    "            'fci':0.03,   #subduction interface friction coefficient\n",
    "            'fcf':0.03,   #subduction interface friction coefficient\n",
    "            #Rheology - cutoff values\n",
    "            'eta_min':1e17, \n",
    "            'eta_max':1e25, #viscosity max in the mantle material\n",
    "            'eta_min_crust':1e20, #viscosity min in the weak-crust material\n",
    "            'eta_max_crust':1e20, #viscosity max in the weak-crust material\n",
    "            'eta_min_interface':1e20, #viscosity min in the subduction interface material\n",
    "            'eta_max_interface':1e20, #viscosity max in the subduction interface material\n",
    "            'eta_min_fault':1e20, #viscosity min in the subduction interface material\n",
    "            'eta_max_fault':1e20, #viscosity max in the subduction interface material\n",
    "            #Length scales\n",
    "            'MANTLETOCRUST':10.*1e3, #Crust depth\n",
    "            'HARZBURGDEPTH':40e3,\n",
    "            'CRUSTTOMANTLE':800.*1e3,\n",
    "            'LITHTOMANTLE':(900.*1e3),\n",
    "            'MANTLETOLITH':200.*1e3, \n",
    "            'TOPOHEIGHT':10.*1e3,  #rock-air topography limits\n",
    "            'CRUSTTOECL':100.*1e3,\n",
    "            'LOWMANTLEDEPTH':660.*1e3, \n",
    "            'CRUSTVISCUTOFF':150.*1e3, #Deeper than this, crust material rheology reverts to mantle rheology\n",
    "            'AGETRACKDEPTH':100e3, #above this depth we track the age of the lithsphere (below age is assumed zero)\n",
    "            #Slab and plate parameters\n",
    "            'roc':250e3,     #radius of curvature of slab\n",
    "            'subzone':0.0,   #X position of subduction zone...km\n",
    "            'lRidge':-0.5*(670e3*4),  #For depth = 670 km, aspect ratio of 4, this puts the ridges at MINX, MAXX\n",
    "            'rRidge':0.5*(670e3*4),\n",
    "            'maxDepth':250e3,\n",
    "            'theta':70., #Angle to truncate the slab (can also control with a maxDepth param)\n",
    "            'slabmaxAge':60e6, #age of subduction plate at trench\n",
    "            'platemaxAge':60e6, #max age of slab (Plate model)\n",
    "            'sense':'Right', #dip direction\n",
    "            'op_age_fac':0.5, #this controls the overidding plate age reduction\n",
    "            #Misc\n",
    "            'StALS':100e3, #depth of sticky air layer\n",
    "            'Steta_n':1e19, #stick air viscosity, normal\n",
    "            'Steta_s':1e18, #stick air viscosity, shear \n",
    "            'plate_vel':4,\n",
    "            'low_mantle_visc_fac':30.\n",
    "           })\n",
    "\n",
    "#append any derived parameters to the dictionary\n",
    "dp.deltaT = dp.TP - dp.TS\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Modelling and Physics switches\n",
    "\n",
    "md = edict({'refineMesh':True,\n",
    "            'stickyAir':False,\n",
    "            'subductionFault':True,\n",
    "            'symmetricIcs':False,\n",
    "            'velBcs':False,\n",
    "            'aspectRatio':4,\n",
    "            'compBuoyancy':False, #use compositional & phase buoyancy, or simply thermal\n",
    "            'periodicBcs':False,\n",
    "            'RES':128\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#If starting from a checkpoint load params from file\n",
    "###########\n",
    "\n",
    "if checkpointLoad:\n",
    "    dp, ndp, sf, md = load_pickles()  #remember to add any extra dictionaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#If command line args are given, overwrite\n",
    "#Note that this assumes that params as commans line args/\n",
    "#only append to the 'dimensional' and 'model' dictionary (not the non-dimensional)\n",
    "###########    \n",
    "\n",
    "\n",
    "###########\n",
    "#If extra arguments are provided to the script\" eg:\n",
    "### >>> uw.py 2 dp.arg1=1 dp.arg2=foo dp.arg3=3.0\n",
    "###\n",
    "###This would assign ModNum = 2, all other values go into the dp dictionary, under key names provided\n",
    "###\n",
    "###Two operators are searched for, = & *=\n",
    "###\n",
    "###If =, parameter is re-assigned to givn value\n",
    "###If *=, parameter is multipled by given value\n",
    "###\n",
    "### >>> uw.py 2 dp.arg1=1 dp.arg2=foo dp.arg3*=3.0\n",
    "###########\n",
    "\n",
    "for farg in sys.argv[1:]:\n",
    "    try:\n",
    "        (dicitem,val) = farg.split(\"=\") #Split on equals operator\n",
    "        (dic,arg) = dicitem.split(\".\") #colon notation\n",
    "        if '*=' in farg:\n",
    "            (dicitem,val) = farg.split(\"*=\") #If in-place multiplication, split on '*='\n",
    "            (dic,arg) = dicitem.split(\".\")\n",
    "        \n",
    "        try:\n",
    "            val = float(val) #try to convert everything to a float, else remains string\n",
    "        except ValueError:\n",
    "            pass\n",
    "        #Update the dictionary\n",
    "        if farg.startswith('dp'):\n",
    "            if '*=' in farg:\n",
    "                dp[arg] = dp[arg]*val #multiply parameter by given factor\n",
    "            else:\n",
    "                dp[arg] = val    #or reassign parameter by given value\n",
    "        if farg.startswith('md'):\n",
    "            if '*=' in farg:\n",
    "                md[arg] = md[arg]*val #multiply parameter by given factor\n",
    "            else:\n",
    "                md[arg] = val    #or reassign parameter by given value\n",
    "                \n",
    "    except:\n",
    "        pass\n",
    "            \n",
    "\n",
    "comm.barrier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Only build these guys first time around, otherwise the read from checkpoints\n",
    "#Important because some of these params (like SZ location) may change during model evolution\n",
    "\n",
    "\n",
    "if not checkpointLoad:\n",
    "\n",
    "    \n",
    "    \n",
    "    sf = edict({'stress':dp.LS**2/(dp.k*dp.eta0),\n",
    "                'lith_grad':dp.rho*dp.g*(dp.LS)**3/(dp.eta0*dp.k) , \n",
    "                'vel':dp.LS/dp.k,\n",
    "                'SR':dp.LS**2/dp.k    \n",
    "               })\n",
    "\n",
    "    #dimensionless parameters\n",
    "\n",
    "    ndp = edict({'RA':(dp.g*dp.rho*dp.a*(dp.TP - dp.TS)*(dp.LS)**3)/(dp.k*dp.eta0),\n",
    "                 'Edf':math.log(dp.Edf),\n",
    "                 'TSP':0., \n",
    "                 'TBP':1.,\n",
    "                 'TPP':(dp.TP - dp.TS)/dp.deltaT, #dimensionless potential temp\n",
    "                 'TS':dp.TS/dp.deltaT,\n",
    "                 'TP':dp.TP/dp.deltaT,\n",
    "                 'cm':dp.cm*sf.stress,\n",
    "                 'cc':dp.cc*sf.stress,    #{dimensionless cohesion in mantle, crust, interface}\n",
    "                 'ci':dp.ci*sf.stress,\n",
    "                 'cf':dp.cf*sf.stress,\n",
    "                 'fcmd':dp.fcm*sf.lith_grad, \n",
    "                 'fccd':dp.fcc*sf.lith_grad, #{dimensionless friction coefficient in mantle, crust, interface}\n",
    "                 'fcid':dp.fci*sf.lith_grad, \n",
    "                 'fcfd':dp.fci*sf.lith_grad, \n",
    "                 #Rheology - cutoff values\n",
    "                 'eta_min':dp.eta_min/dp.eta0, \n",
    "                 'eta_max':dp.eta_max/dp.eta0, #viscosity max in the mantle material\n",
    "                 'eta_min_crust':dp.eta_min_crust/dp.eta0, #viscosity min in the weak-crust material\n",
    "                 'eta_max_crust':dp.eta_max_crust/dp.eta0, #viscosity max in the weak-crust material\n",
    "                 'eta_min_interface':dp.eta_min_interface/dp.eta0, #viscosity min in the subduction interface material\n",
    "                 'eta_max_interface':dp.eta_max_interface/dp.eta0, #viscosity max in the subduction interface material\n",
    "                 'eta_min_fault':dp.eta_min_fault/dp.eta0, #viscosity min in the subduction interface material\n",
    "                 'eta_max_fault':dp.eta_max_fault/dp.eta0, #viscosity max in the subduction interface material   \n",
    "                 #Length scales\n",
    "                 'MANTLETOCRUST':dp.MANTLETOCRUST/dp.LS, #Crust depth\n",
    "                 'HARZBURGDEPTH':dp.HARZBURGDEPTH/dp.LS,\n",
    "                 'CRUSTTOMANTLE':dp.CRUSTTOMANTLE/dp.LS,\n",
    "                 'LITHTOMANTLE':dp.LITHTOMANTLE/dp.LS,\n",
    "                 'MANTLETOLITH':dp.MANTLETOLITH/dp.LS,\n",
    "                 'TOPOHEIGHT':dp.TOPOHEIGHT/dp.LS,  #rock-air topography limits\n",
    "                 'CRUSTTOECL':dp.CRUSTTOECL/dp.LS,\n",
    "                 'LOWMANTLEDEPTH':dp.LOWMANTLEDEPTH/dp.LS, \n",
    "                 'CRUSTVISCUTOFF':dp.CRUSTVISCUTOFF/dp.LS, #Deeper than this, crust material rheology reverts to mantle rheology\n",
    "                 'AGETRACKDEPTH':dp.AGETRACKDEPTH/dp.LS,\n",
    "                 #Slab and plate parameters\n",
    "                 'roc':dp.roc/dp.LS,     #radius of curvature of slab\n",
    "                 'subzone':dp.subzone/dp.LS,   #X position of subduction zone...km\n",
    "                 'lRidge':dp.lRidge/dp.LS,  #For depth = 670 km, aspect ratio of 4, this puts the ridges at MINX, MAXX\n",
    "                 'rRidge':dp.rRidge/dp.LS,\n",
    "                 'maxDepth':dp.maxDepth/dp.LS,    \n",
    "                 #misc\n",
    "                 'Steta_n':dp.Steta_n/dp.eta0, #stick air viscosity, normal\n",
    "                 'Steta_s':dp.Steta_n/dp.eta0, #stick air viscosity, shear \n",
    "                 'StALS':dp.StALS/dp.LS,\n",
    "                 'plate_vel':sf.vel*dp.plate_vel*(cmpery.to(u.m/u.second)).magnitude,\n",
    "                 'low_mantle_visc_fac':dp.low_mantle_visc_fac\n",
    "                })\n",
    "\n",
    "\n",
    "\n",
    "    #Append any more derived paramters\n",
    "    ndp.StRA = (3300.*dp.g*(dp.LS)**3)/(dp.eta0 *dp.k) #Composisitional Rayleigh number for rock-air buoyancy force\n",
    "    dp.CVR = (0.1*(dp.k/dp.LS)*ndp.RA**(2/3.))\n",
    "    ndp.CVR = dp.CVR*sf.vel #characteristic velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(849.2588923739356, 670000000000.0, 3.168876464081849e-10)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndp.plate_vel, sf.vel, (cmpery.to(u.m/u.second)).magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model setup parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Model setup parameters\n",
    "###########\n",
    "\n",
    "#Domain and Mesh paramters\n",
    "dim = 2          # number of spatial dimensions\n",
    "\n",
    "tot_depth = np.round(dp.depth/dp.LS, 3)\n",
    "\n",
    "#These options allow us to explore the choice of different length scalings\n",
    "\n",
    "if tot_depth == 1.: #Depth equal to length scale\n",
    "    MINY = 0.\n",
    "    MAXY = 1.\n",
    "elif tot_depth > 1.: #Depth larger than to length scale\n",
    "    MINY = 0.\n",
    "    MAXY = tot_depth\n",
    "    \n",
    "elif tot_depth < 1.: #Depth smaller to length scale\n",
    "    MINY = np.round(1. - tot_depth, 2)\n",
    "    MAXY = 1.\n",
    "    \n",
    "MINX = np.round(-1.*tot_depth*md.aspectRatio/2., 2)  #Aspect ratio is fixed, x-domain shifts according to system depth and length scale\n",
    "\n",
    "MAXX = np.round(1.*tot_depth*md.aspectRatio/2., 2)\n",
    "\n",
    "if MINX == 0.:\n",
    "    squareModel = True\n",
    "else: \n",
    "    squareModel = False\n",
    "    \n",
    "    \n",
    "\n",
    "Xres = int(md.RES*md.aspectRatio)\n",
    "#if MINY == 0.5:\n",
    "#    Xres = int(2.*RES*aspectRatio)\n",
    "    \n",
    "\n",
    "if md.stickyAir:\n",
    "    Yres = md.RES\n",
    "    MAXY = np.round(MAXY + dp.StALS/dp.LS, 2)\n",
    "    \n",
    "else:\n",
    "    Yres = md.RES\n",
    "    MAXY = np.round(MAXY, 2)\n",
    "\n",
    "periodic = [False, False]\n",
    "if md.periodicBcs:\n",
    "    periodic = [True, False]\n",
    "    \n",
    "elementType = \"Q1/dQ0\"\n",
    "#elementType =\"Q2/DPC1\"\n",
    "\n",
    "\n",
    "#System/Solver stuff\n",
    "PIC_integration=True\n",
    "ppc = 25\n",
    "\n",
    "#Metric output stuff\n",
    "figures =  'gldb' #glucifer Store won't work on all machines, if not, set to 'gldb' \n",
    "swarm_repop, swarm_update = 10, 10\n",
    "gldbs_output = 5\n",
    "checkpoint_every, files_output = 10, 100\n",
    "metric_output = 1\n",
    "sticky_air_temp = 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create mesh and finite element variables\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mesh = uw.mesh.FeMesh_Cartesian( elementType = (elementType),\n",
    "                                 elementRes  = (Xres, Yres), \n",
    "                                 minCoord    = (MINX, MINY), \n",
    "                                 maxCoord    = (MAXX, MAXY), periodic=periodic)\n",
    "\n",
    "velocityField       = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=2 )\n",
    "pressureField       = uw.mesh.MeshVariable( mesh=mesh.subMesh, nodeDofCount=1 )\n",
    "temperatureField    = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=1 )\n",
    "temperatureDotField = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mesh.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min\n",
      "(112, 0.017860714285714334, 3.0003999999999973, 0.9996000000000107)\n",
      "('edges', 112)\n",
      "-- iteration 0 --\n",
      "| F( p_n ) |^2: 0.000660267883564\n",
      "| p_n+1 - p_n |^2: 3.74374166767\n",
      "-- iteration 1 --\n",
      "| F( p_n ) |^2: 1.99887454103e-30\n",
      "Min, Max element width: \n",
      "0.01786\n",
      "0.05357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/slippy2/slippy2/spmesh.py:213: DeprecationWarning: the sets module is deprecated\n",
      "  from sets import ImmutableSet as Set\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "#Mesh refinement\n",
    "###########\n",
    "\n",
    "#X-Axis\n",
    "\n",
    "if md.refineMesh:\n",
    "    mesh.reset()\n",
    "    axis = 0\n",
    "    origcoords = np.linspace(mesh.minCoord[axis], mesh.maxCoord[axis], mesh.elementRes[axis] + 1)\n",
    "    edge_rest_lengths = np.diff(origcoords)\n",
    "\n",
    "    deform_lengths = edge_rest_lengths.copy()\n",
    "    min_point =  (abs(mesh.maxCoord[axis]) - abs(mesh.minCoord[axis]))/2.\n",
    "    el_reduction = 0.5001\n",
    "    dx = mesh.maxCoord[axis] - min_point\n",
    "\n",
    "    deform_lengths = deform_lengths - \\\n",
    "                                    ((1.-el_reduction) *deform_lengths[0]) + \\\n",
    "                                    abs((origcoords[1:] - min_point))*((0.5*deform_lengths[0])/dx)\n",
    "\n",
    "    #print(edge_rest_lengths.shape, deform_lengths.shape)\n",
    "\n",
    "    spmesh.deform_1d(deform_lengths, mesh,axis = 'x',norm = 'Min', constraints = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "axis = 1\n",
    "orgs = np.linspace(mesh.minCoord[axis], mesh.maxCoord[axis], mesh.elementRes[axis] + 1)\n",
    "\n",
    "value_to_constrain = MAXY #nodes will remain along this line\n",
    "\n",
    "\n",
    "yconst = [(spmesh.find_closest(orgs, value_to_constrain), np.array([value_to_constrain,0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min\n",
      "(28, 0.017860714285714382, 0.74117142857142859, 1.0736592592592709)\n",
      "('edges', 28)\n",
      "-- iteration 0 --\n",
      "| F( p_n ) |^2: 0.000684722249622\n",
      "| p_n+1 - p_n |^2: 0.250836584112\n",
      "-- iteration 1 --\n",
      "| F( p_n ) |^2: 1.52485503347e-31\n",
      "Min, Max element width: \n",
      "0.01786\n",
      "0.05357\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "#Mesh refinement\n",
    "###########\n",
    "\n",
    "if md.refineMesh:\n",
    "    #Y-Axis\n",
    "    axis = 1\n",
    "    origcoords = np.linspace(mesh.minCoord[axis], mesh.maxCoord[axis], mesh.elementRes[axis] + 1)\n",
    "    edge_rest_lengths = np.diff(origcoords)\n",
    "\n",
    "    deform_lengths = edge_rest_lengths.copy()\n",
    "    min_point =  (mesh.maxCoord[axis])\n",
    "    el_reduction = 0.5001\n",
    "    dx = mesh.maxCoord[axis]\n",
    "\n",
    "    deform_lengths = deform_lengths - \\\n",
    "                                    ((1.-el_reduction)*deform_lengths[0]) + \\\n",
    "                                    abs((origcoords[1:] - min_point))*((0.5*deform_lengths[0])/dx)\n",
    "\n",
    "    #print(edge_rest_lengths.shape, deform_lengths.shape)\n",
    "\n",
    "    spmesh.deform_1d(deform_lengths, mesh,axis = 'y',norm = 'Min', constraints = yconst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fig= glucifer.Figure()\n",
    "\n",
    "#fig.append(glucifer.objects.Mesh(mesh))\n",
    "\n",
    "#fig.show()\n",
    "#fig.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#THis is a hack for adding a sticky air domain, we refine MAXY and things like the temperature stencil work from Y = 1. \n",
    "\n",
    "if md.stickyAir:\n",
    "    MAXY = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial conditions\n",
    "-------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coordinate = fn.input()\n",
    "depthFn = MAXY - coordinate[1] #a function providing the depth\n",
    "\n",
    "\n",
    "xFn = coordinate[0]  #a function providing the x-coordinate\n",
    "yFn = coordinate[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def age_fn(xFn, sz = 0.0, lMOR=MINX, rMOR=MAXX, opFac=1., conjugate_plate = False):\n",
    "    \"\"\"\n",
    "    Simple function to generate a discrete 1-d (i.e x-coordinate) function for the age of the thermal BC. \n",
    "    All paramters are dimensionless\n",
    "    sz: location of subduction zone\n",
    "    lMOR: location of left-hand MOR\n",
    "    rMOR: location of right-hand MOR\n",
    "    opFac: uniform reduce the age of the right hand plate by this factor\n",
    "    conjugate_plate: if True, build plates on the outer sides of the MORs, if False, age = 0. \n",
    "    \"\"\"\n",
    "    \n",
    "    if lMOR < MINX:\n",
    "        lMOR = MINX\n",
    "    if rMOR > MAXX:\n",
    "        rMOR = MAXX\n",
    "    r_grad =  1./(abs(rMOR-sz))\n",
    "    l_grad =  1./(abs(sz-lMOR))\n",
    "    if conjugate_plate:\n",
    "        ageFn = fn.branching.conditional([(operator.and_(xFn > lMOR, xFn < sz) , (xFn + abs(lMOR))/(abs(sz-lMOR))), \n",
    "                                      (operator.and_(xFn < rMOR, xFn >= sz), (1.-(xFn + abs(sz))/abs(rMOR-sz))*opFac),\n",
    "                                      (xFn > rMOR, r_grad*opFac*(xFn -abs(rMOR)) / (abs(MAXX-rMOR))),\n",
    "                                      (True, l_grad*fn.math.abs((((xFn + abs(lMOR)) / (abs(lMOR - MINX))))))\n",
    "                                         ])\n",
    "    else:    \n",
    "        \n",
    "        ageFn = fn.branching.conditional([(operator.and_(xFn > lMOR, xFn < sz) , (xFn + abs(lMOR))/(abs(sz-lMOR))), \n",
    "                                      (operator.and_(xFn < rMOR, xFn >= sz), (1.-(xFn + abs(sz))/abs(rMOR-sz))*opFac),\n",
    "\n",
    "                                      (True, 0.0)])\n",
    "    return ageFn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Thermal initial condition - half-space coooling\n",
    "###########\n",
    "\n",
    "\n",
    "#  a few conversions\n",
    "ageAtTrenchSeconds = min(dp.platemaxAge*(3600*24*365), dp.slabmaxAge*(3600*24*365))\n",
    "#slab perturbation params (mostly dimensionless / model params here)\n",
    "phi = 90. - dp.theta\n",
    "Org = (ndp.subzone, MAXY-ndp.roc)\n",
    "\n",
    "#First build the top TBL\n",
    "ageFn = age_fn(xFn, sz =ndp.subzone, lMOR=ndp.lRidge,rMOR=ndp.rRidge, conjugate_plate=True, opFac = dp.op_age_fac)\n",
    "#dimensionlize the age function\n",
    "ageFn *= ageAtTrenchSeconds #seconds to year\n",
    "w0 = (2.*math.sqrt(dp.k*ageAtTrenchSeconds))/dp.LS #diffusion depth of plate at the trench\n",
    "\n",
    "tempBL = (ndp.TP - ndp.TS) *fn.math.erf((depthFn*dp.LS)/(2.*fn.math.sqrt(dp.k*ageFn))) + ndp.TSP #boundary layer function\n",
    "tempTBL =  fn.branching.conditional([(depthFn < w0, tempBL),\n",
    "                          (True, ndp.TPP)])\n",
    "\n",
    "if not md.symmetricIcs:\n",
    "    if not checkpointLoad:\n",
    "        out = uw.utils.MeshVariable_Projection( temperatureField, tempTBL) #apply function with projection\n",
    "        out.solve()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now build the perturbation part\n",
    "def inCircleFnGenerator(centre, radius):\n",
    "    coord = fn.input()\n",
    "    offsetFn = coord - centre\n",
    "    return fn.math.dot( offsetFn, offsetFn ) < radius**2\n",
    "\n",
    "\n",
    "\n",
    "#We use three circles to define our slab and crust perturbation,  \n",
    "Oc = inCircleFnGenerator(Org , ndp.roc)\n",
    "Ic = inCircleFnGenerator(Org , ndp.roc - w0)\n",
    "Cc = inCircleFnGenerator(Org , ndp.roc - (1.2*ndp.MANTLETOCRUST)) #... weak zone on 'outside' of slab\n",
    "Hc = inCircleFnGenerator(Org , ndp.roc - ndp.HARZBURGDEPTH) #... Harzburgite layer \n",
    "dx = (ndp.roc)/(np.math.tan((np.math.pi/180.)*phi))\n",
    "\n",
    "#We'll also create a triangle which will truncate the circles defining the slab...\n",
    "if dp.sense == 'Left':\n",
    "    ptx = ndp.subzone - dx\n",
    "else:\n",
    "    ptx = ndp.subzone + dx\n",
    "coords = ((0.+ ndp.subzone, MAXY), (0.+ ndp.subzone, MAXY-ndp.roc), (ptx, MAXY))\n",
    "Tri = fn.shape.Polygon(np.array(coords))\n",
    "\n",
    "#Actually apply the perturbation - could probably avoid particle walk here\n",
    "if not md.symmetricIcs:\n",
    "    if not checkpointLoad:\n",
    "        sdFn = ((ndp.roc - fn.math.sqrt((coordinate[0] - Org[0])**2. + (coordinate[1] - Org[1])**2.)))\n",
    "        slabFn = ndp.TPP*fn.math.erf((sdFn*dp.LS)/(2.*math.sqrt(dp.k*ageAtTrenchSeconds))) + ndp.TSP\n",
    "        for index, coord in enumerate(mesh.data):\n",
    "            if (\n",
    "                Oc.evaluate(tuple(coord)) and\n",
    "                Tri.evaluate(tuple(coord)) and not\n",
    "                Ic.evaluate(tuple(coord)) and\n",
    "                coord[1] > (MAXY - ndp.maxDepth)\n",
    "                ): #In the quarter-circle defining the lithosphere\n",
    "                temperatureField.data[index] = slabFn.evaluate(mesh)[index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sdFn = ((RocM - fn.math.sqrt((coordinate[0] - Org[0])**2. + (coordinate[1] - Org[1])**2.)))\n",
    "#slabFn = ndp.TPP*fn.math.erf((sdFn*dp.LS)/(2.*math.sqrt(dp.k*ageAtTrenchSeconds))) + ndp.TSP\n",
    "#sdFn, slabFn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make sure material in sticky air region is at the surface temperature.\n",
    "for index, coord in enumerate(mesh.data):\n",
    "            if coord[1] >= MAXY:\n",
    "                temperatureField.data[index] = ndp.TSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fn.math.erf((sdFn*dp.LS)/(2.*fn.math.sqrt(dp.k*(slabmaxAge*(3600*24*365))))) \n",
    "#CRUSTVISCUTOFF, MANTLETOCRUST*3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def matplot_field(temperatureField, dp):\n",
    "    if uw.nProcs() != 1:\n",
    "        print(\"only in Serial folks\")\n",
    "    else:\n",
    "        import matplotlib.pyplot as pyplt\n",
    "        try :\n",
    "            if(__IPYTHON__) :\n",
    "                get_ipython().magic(u'matplotlib inline')\n",
    "        except NameError :\n",
    "            pass\n",
    "        field_data = temperatureField.data.reshape(mesh.elementRes[1] + 1, mesh.elementRes[0] + 1)\n",
    "        fig, ax = pyplt.subplots(figsize=(32,2))\n",
    "        ql = dp.LS/1e3\n",
    "        pyplt.ioff()\n",
    "        cax =ax.imshow(np.flipud(field_data), cmap='coolwarm', aspect = 0.5, extent=[0,ql*aspectRatio,ql, 0])\n",
    "        fig.colorbar(cax, orientation='horizontal' )\n",
    "        #ax.set_x([0,dp.LS*aspectRatio])\n",
    "        pyplt.tight_layout()\n",
    "        \n",
    "        return fig, ax\n",
    "        \n",
    "fig, ax = matplot_field(temperatureField, dp)\n",
    "fig.savefig('test.png')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperatureField.data.min(), temperatureField.data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#ageFn = age_fn(xFn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#fig= glucifer.Figure(quality=3)\n",
    "\n",
    "#fig.append( glucifer.objects.Surface(mesh,temperatureField ))\n",
    "#fig.append( glucifer.objects.Mesh(mesh))\n",
    "#fig.show()\n",
    "\n",
    "##fig.save_database('test.gldb')\n",
    "#fig.save_image('test.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boundary conditions\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "for index in mesh.specialSets[\"MinJ_VertexSet\"]:\n",
    "    temperatureField.data[index] = ndp.TBP\n",
    "for index in mesh.specialSets[\"MaxJ_VertexSet\"]:\n",
    "    temperatureField.data[index] = ndp.TSP\n",
    "    \n",
    "iWalls = mesh.specialSets[\"MinI_VertexSet\"] + mesh.specialSets[\"MaxI_VertexSet\"]\n",
    "jWalls = mesh.specialSets[\"MinJ_VertexSet\"] + mesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "tWalls = mesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "bWalls =mesh.specialSets[\"MinJ_VertexSet\"]\n",
    "\n",
    "VelBCs = mesh.specialSets[\"Empty\"]\n",
    "\n",
    "\n",
    "\n",
    "if md.velBcs:\n",
    "    for index in list(tWalls.data):\n",
    "\n",
    "        if (mesh.data[int(index)][0] < (ndp.subzone - 0.05*aspectRatio) and \n",
    "            mesh.data[int(index)][0] > (mesh.minCoord[0] + 0.05*aspectRatio)): #Only push with a portion of teh overiding plate\n",
    "            #print \"first\"\n",
    "            VelBCs.add(int(index))\n",
    "            #Set the plate velocities for the kinematic phase\n",
    "            velocityField.data[index] = [ndp.plate_vel, 0.]\n",
    "        \n",
    "        elif (mesh.data[int(index)][0] > (ndp.subzone + 0.05*aspectRatio) and \n",
    "            mesh.data[int(index)][0] < (mesh.maxCoord[0] - 0.05*aspectRatio)):\n",
    "            #print \"second\"\n",
    "            VelBCs.add(int(index))\n",
    "            #Set the plate velocities for the kinematic phase\n",
    "            velocityField.data[index] = [0., 0.]\n",
    "        \n",
    "\n",
    "#If periodic, we'll fix a the x-vel at a single node - at the bottom left (index 0)\n",
    "Fixed = mesh.specialSets[\"Empty\"]\n",
    "Fixed.add(int(0))        \n",
    "        \n",
    "\n",
    "if periodic[0] == False:\n",
    "    if md.velBcs:\n",
    "        print(1)\n",
    "        freeslipBC = uw.conditions.DirichletCondition( variable      = velocityField, \n",
    "                                               indexSetsPerDof = ( iWalls + VelBCs, jWalls) )\n",
    "    else:\n",
    "        print(2)\n",
    "        freeslipBC = uw.conditions.DirichletCondition( variable      = velocityField, \n",
    "                                               indexSetsPerDof = ( iWalls, jWalls) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if periodic[0] == True:\n",
    "    if md.velBcs:\n",
    "        print(3)\n",
    "        freeslipBC = uw.conditions.DirichletCondition( variable      = velocityField, \n",
    "                                               indexSetsPerDof = ( Fixed + VelBCs , jWalls) )\n",
    "    else:\n",
    "        print(4)\n",
    "        freeslipBC = uw.conditions.DirichletCondition( variable      = velocityField, \n",
    "                                               indexSetsPerDof = ( Fixed, jWalls) )\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "# also set dirichlet for temp field\n",
    "dirichTempBC = uw.conditions.DirichletCondition(     variable=temperatureField, \n",
    "                                              indexSetsPerDof=(tWalls,) )\n",
    "dT_dy = [0.,0.]\n",
    "\n",
    "# also set dirichlet for temp field\n",
    "neumannTempBC = uw.conditions.NeumannCondition( dT_dy, variable=temperatureField, \n",
    "                                         nodeIndexSet=bWalls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check VelBCs are where we want them\n",
    "#test = np.zeros(len(tWalls.data))\n",
    "#VelBCs\n",
    "#tWalls.data\n",
    "#tWalls.data[VelBCs.data]\n",
    "#test[np.in1d(tWalls.data, VelBCs.data)] = 1.\n",
    "#test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swarm setup\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Material Swarm and variables\n",
    "###########\n",
    "\n",
    "#create material swarm\n",
    "gSwarm = uw.swarm.Swarm(mesh=mesh, particleEscape=True)\n",
    "\n",
    "#create swarm variables\n",
    "yieldingCheck = gSwarm.add_variable( dataType=\"int\", count=1 )\n",
    "#tracerVariable = gSwarm.add_variable( dataType=\"int\", count=1)\n",
    "materialVariable = gSwarm.add_variable( dataType=\"int\", count=1 )\n",
    "ageVariable = gSwarm.add_variable( dataType=\"double\", count=1 )\n",
    "#testVariable = gSwarm.add_variable( dataType=\"float\", count=1 )\n",
    "\n",
    "\n",
    "#these lists  are part of the checkpointing implementation\n",
    "varlist = [materialVariable, yieldingCheck, ageVariable]\n",
    "varnames = ['materialVariable', 'yieldingCheck', 'ageVariable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mantleIndex = 0\n",
    "crustIndex = 1\n",
    "harzIndex = 2\n",
    "airIndex = 3\n",
    "\n",
    "\n",
    "\n",
    "if checkpointLoad:\n",
    "    temperatureField.load(os.path.join(checkpointLoadDir, \"temperatureField\" + \".hdf5\"))\n",
    "    pressureField.load(os.path.join(checkpointLoadDir, \"pressureField\" + \".hdf5\"))\n",
    "    velocityField.load(os.path.join(checkpointLoadDir, \"velocityField\" + \".hdf5\"))\n",
    "    gSwarm.load(os.path.join(checkpointLoadDir, \"swarm\" + \".h5\"))\n",
    "    for ix in range(len(varlist)):\n",
    "        varb = varlist[ix]\n",
    "        varb.load(os.path.join(checkpointLoadDir,varnames[ix] + \".h5\"))\n",
    "\n",
    "else:\n",
    "\n",
    "    # Layouts are used to populate the swarm across the whole domain\n",
    "    layout = uw.swarm.layouts.PerCellRandomLayout(swarm=gSwarm, particlesPerCell=ppc)\n",
    "    gSwarm.populate_using_layout( layout=layout ) # Now use it to populate.\n",
    "    # Swarm variables\n",
    "    materialVariable.data[:] = mantleIndex\n",
    "    #tracerVariable.data[:] = 1\n",
    "    yieldingCheck.data[:] = 0\n",
    "    ageVariable.data[:] = -1\n",
    "\n",
    "    #Set initial air and crust materials (allow the graph to take care of lithsophere)\n",
    "    #########\n",
    "    #This initial material setup will be model dependent\n",
    "    #########\n",
    "    for particleID in range(gSwarm.particleCoordinates.data.shape[0]):\n",
    "        if (1. - gSwarm.particleCoordinates.data[particleID][1]) < ndp.MANTLETOCRUST:\n",
    "                 materialVariable.data[particleID] = crustIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###########\n",
    "#This block sets up a checkboard layout of passive tracers\n",
    "###########\n",
    "\n",
    "square_size = 0.1\n",
    "xlist = np.arange(mesh.minCoord[0] + square_size/2., mesh.maxCoord[0] + square_size/2., square_size)\n",
    "xlist = zip(xlist[:], xlist[1:])[::2]\n",
    "ylist = np.arange(mesh.minCoord[1] + square_size/2., mesh.maxCoord[1] + square_size/2., square_size)\n",
    "ylist = zip(ylist[:], ylist[1:])[::2]\n",
    "xops = []\n",
    "for vals in xlist:\n",
    "    xops.append( (operator.and_(   operator.gt(coordinate[0],vals[0]),   operator.lt(coordinate[0],vals[1])  ),0.) )\n",
    "xops.append((True,1.))\n",
    "\n",
    "testfunc = fn.branching.conditional(xops) \n",
    "\n",
    "yops = []\n",
    "for vals in ylist:\n",
    "    yops.append( (operator.and_(   operator.gt(coordinate[1],vals[0]),   operator.lt(coordinate[1],vals[1])  ),0.) )\n",
    "yops.append((True,testfunc))\n",
    "\n",
    "testfunc2 = fn.branching.conditional(yops) \n",
    "tracerVariable.data[:] = testfunc.evaluate(gSwarm)\n",
    "tracerVariable.data[:] = testfunc2.evaluate(gSwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#Set the initial particle age for particles above the critical depth; \n",
    "#only material older than crustageCond will be transformed to crust / harzburgite\n",
    "##############\n",
    "\n",
    "ageVariable.data[:] = 0. #start with all zero\n",
    "ageVariable.data[:] = ageFn.evaluate(gSwarm)/sf.SR\n",
    "crustageCond = 2e6*(3600.*365.*24.)/sf.SR #set inital age above critical depth. (x...Ma)\n",
    "\n",
    "\n",
    "\n",
    "ageConditions = [ (depthFn < ndp.AGETRACKDEPTH, ageVariable),  #In the main loop we add ageVariable + dt here\n",
    "                  (True, 0.) ]\n",
    "                 \n",
    "#apply conditional \n",
    "ageVariable.data[:] = fn.branching.conditional( ageConditions ).evaluate(gSwarm)\n",
    "\n",
    "ageDT = 0.#this is used in the main loop for short term time increments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fig= glucifer.Figure()\n",
    "#fig.append( glucifer.objects.Points(gSwarm,ageVariable))\n",
    "#fig.append( glucifer.objects.Points(gSwarm, viscosityMapFn, logScale=True, valueRange =[1e-3,1e5]))\n",
    "\n",
    "\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#Here we set up a directed graph object that we we use to control the transformation from one material type to another\n",
    "##############\n",
    "\n",
    "#All depth conditions are given as (km/D) where D is the length scale,\n",
    "#note that 'model depths' are used, e.g. 1-z, where z is the vertical Underworld coordinate\n",
    "#All temp conditions are in dimensionless temp. [0. - 1.]\n",
    "\n",
    "#Need a list of all material indexes (safer in parallel)\n",
    "material_list = [0,1,2,3]\n",
    "\n",
    "if not checkpointLoad:\n",
    "    materialVariable.data[:] = 0 #Initialize to zero \n",
    "\n",
    "#Setup the graph object\n",
    "DG = material_graph.MatGraph()\n",
    "\n",
    "#Important: First thing to do is to add all the material types to the graph (i.e add nodes)\n",
    "DG.add_nodes_from(material_list)\n",
    "\n",
    "#Now set the conditions for transformations\n",
    "\n",
    "hs = 2e3/dp.LS  #add some hysteresis to the depths of transition\n",
    "\n",
    "#... to mantle\n",
    "DG.add_transition((crustIndex,mantleIndex), depthFn, operator.gt, ndp.CRUSTTOMANTLE + hs)\n",
    "DG.add_transition((harzIndex,mantleIndex), depthFn, operator.gt, ndp.CRUSTTOMANTLE + hs)\n",
    "DG.add_transition((airIndex,mantleIndex), depthFn, operator.gt, ndp.TOPOHEIGHT + hs)\n",
    "\n",
    "#... to crust\n",
    "DG.add_transition((mantleIndex,crustIndex), depthFn, operator.lt, ndp.MANTLETOCRUST)\n",
    "DG.add_transition((mantleIndex,crustIndex), xFn, operator.lt, ndp.subzone + 4.*ndp.MANTLETOCRUST) #No crust on the upper plate\n",
    "DG.add_transition((mantleIndex,crustIndex), ageVariable, operator.gt, crustageCond)\n",
    "\n",
    "\n",
    "DG.add_transition((harzIndex,crustIndex), depthFn, operator.lt, ndp.MANTLETOCRUST)\n",
    "DG.add_transition((harzIndex,crustIndex), xFn, operator.lt, ndp.subzone + 4.*ndp.MANTLETOCRUST) #This one sets no crust on the upper plate\n",
    "DG.add_transition((harzIndex,crustIndex), ageVariable, operator.gt, crustageCond)\n",
    "\n",
    "#... to Harzbugite\n",
    "DG.add_transition((mantleIndex,harzIndex), depthFn, operator.lt, ndp.HARZBURGDEPTH)\n",
    "DG.add_transition((mantleIndex,harzIndex), depthFn, operator.gt, ndp.MANTLETOCRUST)\n",
    "DG.add_transition((mantleIndex,harzIndex), ageVariable, operator.gt, crustageCond) #Note we can mix functions and swarm variabls\n",
    "\n",
    "\n",
    "\n",
    "#... to air\n",
    "DG.add_transition((mantleIndex,airIndex), depthFn, operator.lt,0.)\n",
    "DG.add_transition((crustIndex,airIndex), depthFn, operator.lt, 0. )\n",
    "DG.add_transition((harzIndex,airIndex), depthFn, operator.lt, 0. )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#CRUSTTOMANTLE, HARZBURGDEPTH, 0. + 7.*MANTLETOCRUST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#gSwarm.particleCoordinates.data[particleID][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#For the slab_IC, we'll also add a crustal weak zone following the dipping perturbation\n",
    "##############\n",
    "\n",
    "if checkpointLoad != True:\n",
    "    if not md.symmetricIcs:\n",
    "        for particleID in range(gSwarm.particleCoordinates.data.shape[0]):\n",
    "            if gSwarm.particleCoordinates.data[particleID][1] < 0.:\n",
    "                materialVariable.data[particleID] = airIndex\n",
    "                \n",
    "            elif (\n",
    "                Oc.evaluate(list(gSwarm.particleCoordinates.data[particleID])) and\n",
    "                Tri.evaluate(list(gSwarm.particleCoordinates.data[particleID])) and\n",
    "                gSwarm.particleCoordinates.data[particleID][1] > (MAXY - ndp.maxDepth) and\n",
    "                Cc.evaluate(list(gSwarm.particleCoordinates.data[particleID])) == False\n",
    "                \n",
    "                ):\n",
    "                materialVariable.data[particleID] = crustIndex\n",
    "                \n",
    "            elif (\n",
    "                Oc.evaluate(list(gSwarm.particleCoordinates.data[particleID])) and\n",
    "                Tri.evaluate(list(gSwarm.particleCoordinates.data[particleID])) and\n",
    "                gSwarm.particleCoordinates.data[particleID][1] > (MAXY - ndp.maxDepth) and\n",
    "                Hc.evaluate(list(gSwarm.particleCoordinates.data[particleID])) == False\n",
    "                \n",
    "                ):\n",
    "                materialVariable.data[particleID] = harzIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#This is how we use the material graph object to test / apply material transformations\n",
    "##############\n",
    "DG.build_condition_list(materialVariable)\n",
    "\n",
    "for i in range(2): #Need to go through a number of times\n",
    "    materialVariable.data[:] = fn.branching.conditional(DG.condition_list).evaluate(gSwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#maxDepth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fig2= glucifer.Figure()\n",
    "#fig2.append( glucifer.objects.Points(gSwarm,materialVariable))\n",
    "#fig2.append( glucifer.objects.Surface(mesh, depthFn))\n",
    "\n",
    "#fig2.show()\n",
    "#fig2.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Fault stuff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import marker2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_swarm_from_faults(faults, proximityVariable, normalVectorVariable, signedDistanceVariable):\n",
    "    \"\"\"\n",
    "    Compute fault attributes from the marker-line objects in the 'faults' list.\n",
    "    Specifically:\n",
    "    \n",
    "      - proximityVariable carries information about which fault each swarm particle is close to (0 means none)\n",
    "      - normalVectorVariable maps the orientation of the fault to nearby swarm particles\n",
    "      - signedDistanceVariable carries the distance (positive means 'inside')  \n",
    "      \n",
    "      Unchecked error: if these variables are from different swarms \n",
    "      \n",
    "    \"\"\"\n",
    "    \n",
    "    for fault_seg in faults:\n",
    "\n",
    "        swarm = proximityVariable.swarm\n",
    "        \n",
    "        f, nz = fault_seg.compute_marker_proximity(swarm.particleCoordinates.data)    \n",
    "        proximityVariable.data[nz] = f[nz]\n",
    "\n",
    "        dv, nzv = fault_seg.compute_normals(swarm.particleCoordinates.data)\n",
    "        normalVectorVariable.data[nzv] = dv[nzv]\n",
    "\n",
    "        sd, dnz = fault_seg.compute_signed_distance(swarm.particleCoordinates.data)\n",
    "        signedDistanceVariable.data[dnz] = sd[dnz]\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def update_swarm_from_line(fault, signedDistanceVariable):\n",
    "    \"\"\"\n",
    "    Compute fault attributes from the marker-line objects in the 'faults' list.\n",
    "    Specifically:\n",
    "    \n",
    "      - proximityVariable carries information about which fault each swarm particle is close to (0 means none)\n",
    "      - normalVectorVariable maps the orientation of the fault to nearby swarm particles\n",
    "      - signedDistanceVariable carries the distance (positive means 'inside')  \n",
    "      \n",
    "      Unchecked error: if these variables are from different swarms \n",
    "      \n",
    "    \"\"\"\n",
    "        \n",
    "    sd, dnz = fault.compute_signed_distance(gSwarm.particleCoordinates.data)\n",
    "    signedDistanceVariable.data[dnz] = sd[dnz]\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def mask_materials(fault, material, materialVariable, proximityVariable, normalVectorVariable, signedDistanceVariable):\n",
    "\n",
    "    \"\"\"\n",
    "    set the key fault-related swarm variabels to zero, based on material typr\n",
    "    \"\"\"\n",
    "    \n",
    "    fptsMask1 = (materialVariable.data[:,0] != material)\n",
    "    fptsMask2 = (proximityVariable.data[:,0] == fault.ID )\n",
    "\n",
    "    fptsMaskOut = fptsMask1 & fptsMask2\n",
    "\n",
    "    normalVectorVariable.data[fptsMaskOut,:] = [0.0,0.0]\n",
    "    proximityVariable.data[fptsMaskOut] = 0\n",
    "    signedDistanceVariable.data[fptsMaskOut] = 0.0\n",
    "    \n",
    "    \n",
    "def fault_strainrate_fns(fault_list, velocityField, faultNormalVariable, proximityproVariable):\n",
    "\n",
    "    ## This is a quick / short cut way to find the resolved stress components.\n",
    "    \n",
    "    strainRateFn = fn.tensor.symmetric( velocityField.fn_gradient )\n",
    "\n",
    "    \n",
    "    _edotn_SFn = (        directorVector[0]**2 * strainRateFn[0]  + \n",
    "                    2.0 * directorVector[1]    * strainRateFn[2] * directorVector[0] + \n",
    "                          directorVector[1]**2 * strainRateFn[1]                          \n",
    "                ) \n",
    "\n",
    "    # any non-zero proximity requires the computation of the above\n",
    "    \n",
    "    _edotn_SFn_Map    = { 0: 0.0 }\n",
    "    for f in fault_list:\n",
    "        _edotn_SFn_Map[f.ID] =  _edotn_SFn\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    _edots_SFn = (  directorVector[0] *  directorVector[1] *(strainRateFn[1] - strainRateFn[0]) +\n",
    "                    strainRateFn[2] * (directorVector[0]**2 - directorVector[1]**2)\n",
    "                 )\n",
    "    \n",
    "  \n",
    "    _edots_SFn_Map = { 0: 1.0e-15 }\n",
    "    \n",
    "    for f in fault_list:\n",
    "        _edots_SFn_Map[f.ID] =  _edots_SFn\n",
    "        \n",
    "        \n",
    "    #Finally, map the resolved strain rate to the proximity variable, \n",
    "    #which also makes resolved strain rate zero whereever proximity variable is zero \n",
    "\n",
    "\n",
    "    edotn_SFn =     fn.branching.map( fn_key = proximityVariable, \n",
    "                                      mapping = _edotn_SFn_Map)\n",
    "\n",
    "\n",
    "    edots_SFn =     fn.branching.map( fn_key = proximityVariable, \n",
    "                                      mapping = _edots_SFn_Map )\n",
    "\n",
    "    \n",
    "    return edotn_SFn, edots_SFn\n",
    "\n",
    "\n",
    "## Time update\n",
    "\n",
    "def faults_advance_in_time(faults,proximityVariable, directorVector, signedDistanceVariable, materialVariable, mmask):\n",
    "    for f in faults:\n",
    "        f.advection(dt)\n",
    "\n",
    "\n",
    "    update_swarm_from_faults(faults, proximityVariable, directorVector, signedDistanceVariable)\n",
    "    mask_materials(materialV, materialVariable, proximityVariable, directorVector, signedDistanceVariable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "introPoint = ndp.subzone - abs(ndp.subzone - ndp.lRidge)/2. #half way between ridge and Sz\n",
    "fthickness = ndp.MANTLETOCRUST/2. #initiale fault at half-depth of crust\n",
    "nfault = 200\n",
    "faultCoords =np.zeros((nfault, 2))\n",
    "\n",
    "reducedRocM = ndp.roc  - fthickness\n",
    "xlimslab = reducedRocM*math.cos(math.pi*(90. - dp.theta)/180)\n",
    "faultCoords[:, 0] = np.linspace(introPoint, ndp.subzone + xlimslab, nfault) #note SZ location is hardcoded here \n",
    "for index, xval in np.ndenumerate(faultCoords[:,0]):\n",
    "    #print index, xval\n",
    "    #swarmCoords[index[0], 1] = 1. - isodepthFn.evaluate((xval, 0.)) #This bit for the plate \n",
    "    if  xval < 0.:\n",
    "        faultCoords[index[0], 1] = 1. - fthickness #This bit for the plate \n",
    "        \n",
    "    else:\n",
    "        faultCoords[index[0], 1] = (1. - (fthickness) - (reducedRocM - ( math.sqrt((reducedRocM**2 - xval**2)))))\n",
    "        \n",
    "    \n",
    "faultCoords = faultCoords[faultCoords[:,1] > (1. - ndp.maxDepth)] #kill any deeper than cutoff\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#surface tracer:\n",
    "\n",
    "surfaceCoords =np.ones((nfault, 2))*1.\n",
    "surfaceCoords[:,0] = np.linspace(MINX, MAXX, nfault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from unsupported.interfaces import markerLine2D\n",
    "faults = []\n",
    "fault_seg  = marker2D.markerLine2D(mesh, velocityField, faultCoords[:, 0], faultCoords[:, 1], fthickness, 0.0, 0.0, crustIndex)\n",
    "faults.append(fault_seg)\n",
    "\n",
    "fault_seg  = marker2D.markerLine2D(mesh, velocityField, surfaceCoords[:, 0], surfaceCoords[:, 1], ndp.StALS, 0.0, 0.0, airIndex)\n",
    "faults.append(fault_seg)\n",
    "\n",
    "\n",
    "#Add the necessary swarm variables\n",
    "\n",
    "proximityVariable      = gSwarm.add_variable( dataType=\"int\", count=1 )\n",
    "signedDistanceVariable = gSwarm.add_variable( dataType=\"float\", count=1 )\n",
    "directorVector   = gSwarm.add_variable( dataType=\"double\", count=2)\n",
    "\n",
    "directorVector.data[:,:] = 0.0\n",
    "proximityVariable.data[:] = 0\n",
    "signedDistanceVariable.data[:] = 0.0\n",
    "\n",
    "\n",
    "\n",
    "# Call the Fault helper functions to initialize this info on the main material swarm\n",
    "\n",
    "    \n",
    "    \n",
    "update_swarm_from_faults(faults[1:], proximityVariable, directorVector, signedDistanceVariable)\n",
    "mask_materials(faults[1], airIndex, materialVariable, proximityVariable, directorVector, signedDistanceVariable)\n",
    "\n",
    "\n",
    "update_swarm_from_faults(faults[0:-1], proximityVariable, directorVector, signedDistanceVariable)\n",
    "mask_materials(faults[0], crustIndex, materialVariable, proximityVariable, directorVector, signedDistanceVariable)\n",
    "\n",
    "#Also switch off proximity beneath ndp.CRUSTVISCUTOFF depth\n",
    "proximityVariable.data[gSwarm.particleCoordinates.data[:,1]  < (1. - ndp.CRUSTVISCUTOFF)] = 0. \n",
    "\n",
    "\n",
    "# These should be general enough not to need updating when the faults move etc..\n",
    "#ie they should update as the fields/functions/swarm variables they are built on update\n",
    "edotn_SFn, edots_SFn = fault_strainrate_fns(faults, velocityField, directorVector, proximityVariable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Take a look at the locations of the materials\n",
    "\n",
    "\n",
    "#Note we only use this mesh director for visualizing the directorVector (vector-on-swarm viewing not suppoted yet)\n",
    "meshDirector = uw.mesh.MeshVariable( mesh, 2 )\n",
    "projectDirector = uw.utils.MeshVariable_Projection( meshDirector, directorVector, type=1 )\n",
    "projectDirector.solve()    \n",
    "\n",
    "figMaterials = glucifer.Figure( figsize=(1200,400), boundingBox=((-2.0, -0.0, 0.0), (2.0, 1.0, 0.0)) )\n",
    "\n",
    "#Plot swarm associated with each fault\n",
    "for f in faults:\n",
    "    figMaterials.append( glucifer.objects.Points(f.swarm, colours=\"Black Black\", pointSize=2.0, colourBar=False) )\n",
    "\n",
    "\n",
    "#plot mesh director viz. guy\n",
    "figMaterials.append( glucifer.objects.VectorArrows(mesh, meshDirector, scaling=.08, \n",
    "                                               resolutionI=100, resolutionJ=20, opacity=0.25) )\n",
    "\n",
    "\n",
    "#Proximity variable - this is the colour\n",
    "figMaterials.append( glucifer.objects.Points(gSwarm, proximityVariable, \n",
    "                                             pointSize=5.0,  opacity=0.75) )\n",
    "\n",
    "\n",
    "#signedDistanceVariable - this variable goes to zero where the proximity cutoff is\n",
    "#note that it's signed...faults have a direction\n",
    "#figMaterials.append( glucifer.objects.Points(gSwarm, signedDistanceVariable, \n",
    "#                                             pointSize=2.0))\n",
    "\n",
    "#Add mesh\n",
    "#figMaterials.append( glucifer.objects.Mesh(mesh, opacity=0.1) )\n",
    "\n",
    "#figMaterials.show()\n",
    "#figMaterials.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rheology\n",
    "-----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#Set up any functions required by the rheology\n",
    "##############\n",
    "strainRate_2ndInvariant = fn.tensor.second_invariant( \n",
    "                            fn.tensor.symmetric( \n",
    "                            velocityField.fn_gradient ))\n",
    "\n",
    "def safe_visc(func, viscmin=ndp.eta_min, viscmax=ndp.eta_max):\n",
    "    return fn.misc.max(viscmin, fn.misc.min(viscmax, func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#strainRate_2ndInvariant = fn.misc.constant(ndp.SR) #dummy fucntion to check which mechanisms are at active are reference strain rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ndp.crust_cohesion_fac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############\n",
    "#Rheology: create UW2 functions for all viscous mechanisms\n",
    "#############\n",
    "\n",
    "omega = fn.misc.constant(1.) #this function can hold any arbitary viscosity modifications \n",
    "\n",
    "\n",
    "##Diffusion Creep\n",
    "diffusion = fn.misc.min(ndp.eta_max, fn.math.exp(-1*ndp.Edf + ndp.Edf / (temperatureField + 1e-8)))\n",
    "\n",
    "\n",
    "\n",
    "##Define the Plasticity\n",
    "ys =  ndp.cm + (depthFn*ndp.fcmd)\n",
    "ysMax = 10e4*1e6*sf.stress\n",
    "ysf = fn.misc.min(ys, ysMax)\n",
    "yielding = ysf/(2.*(strainRate_2ndInvariant))\n",
    "\n",
    "##Crust rheology\n",
    "#crustys =  ndp.cohesion*ndp.crust_cohesion_fac + (depthFn*ndp.fcd*ndp.crust_fc_fac)\n",
    "crustys =  ndp.cc + (depthFn*ndp.fccd) #only weakened cohesion is discussed, not fc\n",
    "crustvisc = crustys/(2.*(strainRate_2ndInvariant)) \n",
    "\n",
    "\n",
    "##Interface rheology\n",
    "interfaceys =  ndp.ci + (depthFn*ndp.fcid) #only weakened cohesion is discussed, not fc\n",
    "interfacevisc = interfaceys/(2.*(strainRate_2ndInvariant))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############\n",
    "#Rheology: combine viscous mechanisms in various ways \n",
    "#harmonic: harmonic average of all mechanims\n",
    "#min: minimum effective viscosity of the mechanims\n",
    "#mixed: takes the minimum of the harmonic and the plastic effective viscosity\n",
    "#############\n",
    "\n",
    "#linear rheology \n",
    "linearviscosityFn = safe_visc(diffusion)\n",
    "\n",
    "\n",
    "\n",
    "interfaceCond = operator.and_((depthFn < ndp.CRUSTVISCUTOFF), (depthFn > ndp.MANTLETOCRUST))    \n",
    "\n",
    "\n",
    "#combined rheology    \n",
    "finalviscosityFn  = fn.branching.conditional([(depthFn < ndp.LOWMANTLEDEPTH, safe_visc(fn.misc.min(diffusion, yielding))),\n",
    "                                  (True, safe_visc(safe_visc(diffusion*ndp.low_mantle_visc_fac)))])\n",
    "\n",
    "#crust rheology    \n",
    "#finalcrustviscosityFn = safe_visc(fn.misc.min(ndp.eta_max_crust, \n",
    "#                                              crustyielding)) #cohesion weakening factor also applies to eta_0\n",
    "\n",
    "crustviscosityFn = safe_visc(fn.misc.min(linearviscosityFn, crustvisc), ndp.eta_max_crust)\n",
    "interfaceviscosityFn = safe_visc(fn.misc.min(linearviscosityFn, interfacevisc), ndp.eta_max_interface)\n",
    "\n",
    "if ndp.eta_max_crust == ndp.eta_min_crust: #If these are equal, set to constant visc. \n",
    "    crustviscosityFn = fn.misc.constant(ndp.eta_min_crust)\n",
    "    \n",
    "if ndp.eta_max_interface == ndp.eta_min_interface: #If these are equal, set to constant visc. \n",
    "    interfaceviscosityFn = fn.misc.constant(ndp.eta_min_interface)\n",
    "    \n",
    "\n",
    "\n",
    "finalcrustviscosityFn  = fn.branching.conditional([(depthFn < ndp.MANTLETOCRUST, crustviscosityFn),\n",
    "                                                     (interfaceCond, interfaceviscosityFn), #\n",
    "                                                     (True, finalviscosityFn)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stokes system setup\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "buoyancyFn =  ndp.RA*temperatureField\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "densityMapFn = fn.branching.map( fn_key = materialVariable,\n",
    "                         mapping = {airIndex:ndp.StRA,\n",
    "                                    crustIndex:buoyancyFn, \n",
    "                                    mantleIndex:buoyancyFn,\n",
    "                                    harzIndex:buoyancyFn} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define our vertical unit vector using a python tuple (this will be automatically converted to a function).\n",
    "gravity = ( 0.0, 1.0 )\n",
    "\n",
    "# Now create a buoyancy force vector using the density and the vertical unit vector. \n",
    "buoyancyFn = densityMapFn * gravity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stokesPIC = uw.systems.Stokes(velocityField=velocityField, \n",
    "                              pressureField=pressureField,\n",
    "                              conditions=[freeslipBC,],\n",
    "                              fn_viscosity=linearviscosityFn, \n",
    "                              fn_bodyforce=buoyancyFn )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solver = uw.systems.Solver(stokesPIC)\n",
    "if not checkpointLoad:\n",
    "    solver.solve() #A solve on the linear visocisty is unhelpful unless we're starting from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "viscosityMapFn1 = fn.branching.map( fn_key = materialVariable,\n",
    "                         mapping = {crustIndex:finalcrustviscosityFn,\n",
    "                                    mantleIndex:finalviscosityFn,\n",
    "                                    harzIndex:finalviscosityFn,\n",
    "                                    airIndex:ndp.Steta_n} )\n",
    "\n",
    "\n",
    "delta_Steata2 = ndp.Steta_n - ndp.Steta_s\n",
    "delta_eta_fault = 0.\n",
    "\n",
    "if md.subductionFault:  \n",
    "    if ndp.eta_min_fault == ndp.eta_min_fault:#Transverse rheology is isoviscous\n",
    "        delta_eta_fault = fn.misc.min(0.999, fn.misc.max (0.,   ndp.eta_min_crust - ndp.eta_min_fault))       \n",
    "        \n",
    "    else:\n",
    "        #Transverse viscosity is related the Mohr-Coulomb criterion\n",
    "        delta_eta_fault = fn.misc.min(0.999, fn.misc.max (0., \n",
    "        viscosityMapFn1 - ((edotn_SFn*viscosityMapFn1 + ndp.fcfd * pressureField)  + ndp.cf)/edots_SFn))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.99]), 0.0)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(delta_eta_fault.evaluate(gSwarm)), delta_Steata2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This one maps to my fault-proximity variable (which also picks only materialV)\n",
    "viscosityMapFn2    = { 0: 0.0, \n",
    "                           1: delta_eta_fault, \n",
    "                           3: delta_Steata2\n",
    "                       }\n",
    "    \n",
    "\n",
    "viscosityMapFn2  = fn.branching.map( fn_key = proximityVariable, \n",
    "                                           mapping = viscosityMapFn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#orientation = -1.*90. * math.pi / 180.0  #vertical\n",
    "#math.cos(orientation), math.sin(orientation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#stickyAir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Add the non-linear viscosity to the Stokes system\n",
    "stokesPIC.fn_viscosity = viscosityMapFn1\n",
    "\n",
    "if md.stickyAir or md.subductionFault:\n",
    "    stokesPIC.fn_viscosity2 = viscosityMapFn2\n",
    "    stokesPIC._fn_director   = directorVector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m\n",
      " \n",
      "Pressure iterations:   4\n",
      "Velocity iterations:   1 (presolve)      \n",
      "Velocity iterations:  -1 (pressure solve)\n",
      "Velocity iterations:   1 (backsolve)     \n",
      "Velocity iterations:   1 (total solve)   \n",
      " \n",
      "SCR RHS  solve time: 5.0743e-02\n",
      "Pressure solve time: 7.1070e-03\n",
      "Velocity solve time: 4.6391e-02 (backsolve)\n",
      "Total solve time   : 1.1670e-01\n",
      " \n",
      "Velocity solution min/max: 0.0000e+00/0.0000e+00\n",
      "Pressure solution min/max: 0.0000e+00/0.0000e+00\n",
      " \n",
      "\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "solver.set_inner_method(\"mumps\")\n",
    "solver.options.scr.ksp_type=\"cg\"\n",
    "solver.set_penalty(1.0e7)\n",
    "solver.options.scr.ksp_rtol = 1.0e-4\n",
    "solver.solve(nonLinearIterate=True)\n",
    "solver.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check which particles are yielding\n",
    "#yieldingCheck.data[:] = 0\n",
    "\n",
    "#yieldconditions = [ ( finalviscosityFn < Visc , 1), \n",
    "#               ( True                                           , 0) ]\n",
    "\n",
    "# use the branching conditional function to set each particle's index\n",
    "#yieldingCheck.data[:] = fn.branching.conditional( yieldconditions ).evaluate(gSwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#velocityFieldIso       = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=2 )\n",
    "#velocityFieldIso.data[:] = velocityField.data.copy()\n",
    "\n",
    "\n",
    "\n",
    "#strainRate_2ndInvariantIso = fn.tensor.second_invariant( \n",
    "#                            fn.tensor.symmetric( \n",
    "#                            velocityFieldIso.fn_gradient ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fig= glucifer.Figure()\n",
    "#fig.append( glucifer.objects.Points(gSwarm,strainRate_2ndInvariant - strainRate_2ndInvariantIso))\n",
    "#fig.append( glucifer.objects.VectorArrows(mesh,velocityField -velocityFieldIso))\n",
    "\n",
    "#fig.append( glucifer.objects.Surface(mesh,ndflm, logScale=True))\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advection-diffusion System setup\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "advDiff = uw.systems.AdvectionDiffusion( phiField       = temperatureField, \n",
    "                                         phiDotField    = temperatureDotField, \n",
    "                                         velocityField  = velocityField,\n",
    "                                         fn_sourceTerm    = 0.0,\n",
    "                                         fn_diffusivity = 1.0, \n",
    "                                         #conditions     = [neumannTempBC, dirichTempBC] )\n",
    "                                         conditions     = [ dirichTempBC] )\n",
    "\n",
    "passiveadvector = uw.systems.SwarmAdvector( swarm         = gSwarm, \n",
    "                                     velocityField = velocityField, \n",
    "                                     order         = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "population_control = uw.swarm.PopulationControl(gSwarm,deleteThreshold=0.2,splitThreshold=1.,maxDeletions=3,maxSplits=0, aggressive=True, particlesPerCell=ppc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis functions / routines\n",
    "-----\n",
    "\n",
    "Most of the metrics we want to calculate are either:\n",
    "\n",
    "* extrema of some field / function\n",
    "* integral of some field / function\n",
    "* average value of some function (integral divide by area)\n",
    "\n",
    "In addition, we also want to be able to determine these metrics over some restricted part of the domain, where the restriction may either be due some value of a field, a material type, or something more arbitrary.\n",
    "\n",
    "Much of he challenge lies in defining these restriction functions in an efficient and robust way (i.e they don't break down as the model evolves)\n",
    "\n",
    "For volume integrals, and extrema, we build a hierarchy of restriction functions, each borrowing from the previous, until we have divided the domain into a number of sub regions of interest. \n",
    "\n",
    "In general, averages are found afterwards by combining the integral and the area of the relavent subregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###################\n",
    "#Volume Restriction functions\n",
    "###################\n",
    "\n",
    "#Level 1. Global\n",
    "globRestFn = fn.misc.constant(1.)\n",
    "\n",
    "#Level 2. Rock - air:\n",
    "rockRestFn = uw.swarm.SwarmVariable(gSwarm, dataType='double', count=1)\n",
    "rockRestFn.data[:] = 0.\n",
    "rockRestFn.data[np.where(materialVariable.data[:] != airIndex)] = 1.\n",
    "rockRestFn *= globRestFn #Add next level up in heirarchy\n",
    "\n",
    "\n",
    "#Level 3. lithosphere - mantle:\n",
    "tempMM = fn.view.min_max(temperatureField)\n",
    "tempMM.evaluate(mesh)\n",
    "TMAX = tempMM.max_global()\n",
    "mantleconditions = [ (                                  temperatureField < 0.9*TMAX, 1.),\n",
    "                   (                                                   True , 0.) ]\n",
    "lithRestFn = fn.branching.conditional(mantleconditions)\n",
    "lithRestFn*=rockRestFn #Add next level up in heirarchy\n",
    "\n",
    "\n",
    "#Level 4. lower plate - upper plate:\n",
    "\n",
    "\n",
    "#This whole section simply builds a restriction Fn that separates the upper and lower plate \n",
    "#It's pretty cumbersome, and will need to advected, rebuilt\n",
    "#can YOU think of a better way?\n",
    "\n",
    "\n",
    "    \n",
    "fthickness = 20e3/dp.LS #initialize tracking swarm at ~ mid lithosphere depth\n",
    "\n",
    "if dp.sense == 'Right':\n",
    "    introPoint = ndp.lRidge + fthickness #\n",
    "else:\n",
    "    introPoint = ndp.rRidge - fthickness #\n",
    "nfault = 200\n",
    "slabCoords =np.zeros((nfault, 2))\n",
    "\n",
    "reducedRocM = ndp.roc  - fthickness\n",
    "xlimslab = reducedRocM*math.cos(math.pi*(90. - dp.theta)/180)\n",
    "slabCoords[:, 0] = np.linspace(introPoint, ndp.subzone + xlimslab, nfault) #note SZ location is hardcoded here \n",
    "for index, xval in np.ndenumerate(slabCoords[:,0]):\n",
    "    #print index, xval\n",
    "    #swarmCoords[index[0], 1] = 1. - isodepthFn.evaluate((xval, 0.)) #This bit for the plate \n",
    "    if  xval < 0.:\n",
    "        slabCoords[index[0], 1] = 1. - fthickness #This bit for the plate \n",
    "        \n",
    "    else:\n",
    "        slabCoords[index[0], 1] = (1. - (fthickness) - (reducedRocM - ( math.sqrt((reducedRocM**2 - xval**2)))))\n",
    "        \n",
    "slabCoords = slabCoords[slabCoords[:,1] > (1. - ndp.maxDepth)] #kill any deeper than cutoff\n",
    "\n",
    "slab_line  = marker2D.markerLine2D(mesh, velocityField, slabCoords[:, 0], slabCoords[:, 1], 1e9/dp.LS, 0.0, 0.0, crustIndex)\n",
    "lowerPlateRestFn = gSwarm.add_variable( dataType=\"double\", count=1 )\n",
    "lowerPlateRestFn.data[:] = 0.0\n",
    "\n",
    "update_swarm_from_line(slab_line, lowerPlateRestFn )\n",
    "lowerPlateRestFn.data[np.where(lowerPlateRestFn.data != 0.)] += fthickness #assume instances of 0. are actually where no fault on proc\n",
    "lowerPlateRestFn.data[np.where(lowerPlateRestFn.data > 0*fthickness)] = 1.\n",
    "lowerPlateRestFn.data[np.where(lowerPlateRestFn.data <= 0.*fthickness)] = 0. \n",
    "lowerPlateRestFn *= lithRestFn #Add next level up in heirarchy\n",
    "\n",
    "#Also see if we can stick the the Velocity and coords on to this swarm as well\n",
    "tipVar = uw.swarm.SwarmVariable(slab_line.swarm, dataType='double', count=4)\n",
    "tipVar.data[:,:2] = velocityField.evaluate(slab_line.swarm)\n",
    "tipVar.data[:,2:] = xFn.evaluate(slab_line.swarm)\n",
    "tipVar.data[:,3:] = yFn.evaluate(slab_line.swarm)\n",
    "\n",
    "\n",
    "#Level 5. hinge of lower plate:\n",
    "\n",
    "hingeSpatialconditions = [ (           operator.and_( (depthFn < MAXY - (150e3/dp.LS)),  (xFn > ndp.subzone - 50e3/dp.LS)), 1.),\n",
    "                   (                                                   True , 0.) ]\n",
    "\n",
    "hingeRestFn = fn.branching.conditional(hingeSpatialconditions)\n",
    "hingeRestFn*=lowerPlateRestFn #Add next level up in heirarchy\n",
    "\n",
    "\n",
    "#Level 6. crust/interface in hinge of lower plate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "respltconditions = [ \n",
    "                    (                                  hingeRestFn*2. > rockRestFn*1., 1.),\n",
    "                    (                                  lowerPlateRestFn*3. > hingeRestFn*2. , 3.),\n",
    "                    (                                  lithRestFn*5. > lowerPlateRestFn*3. , 4.),\n",
    "                   (                                                   True , 0.) ]\n",
    "\n",
    "respltFn = fn.branching.conditional(respltconditions )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig= glucifer.Figure()\n",
    "fig.append( glucifer.objects.Points(gSwarm,respltFn))\n",
    "#fig.show()\n",
    "#fig.save_database('test_restrict.gldb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################\n",
    "#Surface Restriction functions\n",
    "###################\n",
    "\n",
    "def platenessFn(val = 0.1):\n",
    "    normgradV = fn.math.abs(velocityField.fn_gradient[0]/fn.math.sqrt(velocityField[0]*velocityField[0])) #[du*/dx]/sqrt(u*u)\n",
    "\n",
    "\n",
    "\n",
    "    srconditions = [ (                                  normgradV < val, 1.),\n",
    "                   (                                                   True , 0.) ]\n",
    "\n",
    "\n",
    "    return fn.branching.conditional(srconditions)\n",
    "\n",
    "srRestFn = platenessFn(val = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###################\n",
    "#Setup any Functions to be integrated\n",
    "###################\n",
    "\n",
    "sqrtv2 = fn.math.sqrt(fn.math.dot(velocityField,velocityField))\n",
    "vx = velocityField[0]\n",
    "v2x = fn.math.dot(velocityField[0],velocityField[0])\n",
    "sqrtv2x = fn.math.sqrt(fn.math.dot(velocityField[0],velocityField[0]))\n",
    "dw = temperatureField*velocityField[1]\n",
    "sinner = fn.math.dot( strainRate_2ndInvariant, strainRate_2ndInvariant )\n",
    "vd = 2.*viscosityMapFn1*sinner\n",
    "dTdZ = temperatureField.fn_gradient[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###################\n",
    "#Create integral, max/min templates \n",
    "###################\n",
    "\n",
    "def volumeint(Fn = 1., rFn=globRestFn):\n",
    "    return uw.utils.Integral( Fn*rFn,  mesh )\n",
    "\n",
    "def surfint(Fn = 1., rFn=globRestFn, surfaceIndexSet=mesh.specialSets[\"MaxJ_VertexSet\"]):\n",
    "    return uw.utils.Integral( Fn*rFn, mesh=mesh, integrationType='Surface', surfaceIndexSet=surfaceIndexSet)\n",
    "\n",
    "def maxMin(Fn = 1.):\n",
    "    #maxMin(Fn = 1., rFn=globRestFn\n",
    "    #vuFn = fn.view.min_max(Fn*rFn) #the restriction functions don't work with the view.min_max fn yet\n",
    "    vuFn = fn.view.min_max(Fn)\n",
    "    return vuFn\n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setup volume integrals on different sub regions\n",
    "\n",
    "##Whole rock domain\n",
    "\n",
    "_areaintRock = volumeint(rockRestFn)\n",
    "_tempintRock = volumeint(temperatureField, rockRestFn)\n",
    "_rmsintRock = volumeint(sqrtv2,rockRestFn)\n",
    "_dwintRock = volumeint(dw,rockRestFn)\n",
    "_vdintRock = volumeint(vd,rockRestFn)\n",
    "\n",
    "##Lith \n",
    "\n",
    "_areaintLith  = volumeint(lithRestFn)\n",
    "_tempintLith  = volumeint(temperatureField, lithRestFn)\n",
    "_rmsintLith  = volumeint(sqrtv2,lithRestFn)\n",
    "_dwintLith  = volumeint(dw,lithRestFn)\n",
    "_vdintLith  = volumeint(vd,lithRestFn)\n",
    "\n",
    "##Lower plate\n",
    "\n",
    "_areaintLower  = volumeint(lowerPlateRestFn)\n",
    "_tempintLower  = volumeint(temperatureField, lowerPlateRestFn)\n",
    "_rmsintLower  = volumeint(sqrtv2,lowerPlateRestFn)\n",
    "_dwintLower = volumeint(dw,lowerPlateRestFn)\n",
    "_vdintLower  = volumeint(vd,lowerPlateRestFn)\n",
    "\n",
    "##Hinge lower plate\n",
    "\n",
    "_areaintHinge  = volumeint(hingeRestFn)\n",
    "_vdintHinge  = volumeint(vd,hingeRestFn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setup surface integrals\n",
    "\n",
    "_surfLength = surfint()\n",
    "_rmsSurf = surfint(v2x)\n",
    "_nuTop = surfint(dTdZ)\n",
    "_nuBottom = surfint(dTdZ, surfaceIndexSet=mesh.specialSets[\"MinJ_VertexSet\"])\n",
    "_plateness = surfint(srRestFn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setup max min fns (at the moment, we can't pass restriction function to view.min_max, so we're limited to whole volume or surface extrema)\n",
    "\n",
    "##Whole rock domain\n",
    "\n",
    "#_maxMinVisc = maxMin(viscosityMapFn1)  #These don't work on swarm variables or mapping functions, yet\n",
    "#dummyFn = _maxMinVisc.evaluate(mesh)\n",
    "#_maxMinStressInv = maxMin(2*viscosityMapFn1*strainRate_2ndInvariant) #These don't work on swarm variables or mapping functions, yet\n",
    "#dummyFn = _maxMinStress.evaluate(mesh)\n",
    "#_maxMinVd = maxMin(vd) #These don't work on swarm variables or mapping functions, yet\n",
    "#dummyFn = _maxMinVd.evaluate(mesh)\n",
    "\n",
    "\n",
    "_maxMinVel = maxMin(velocityField) \n",
    "dummyFn = _maxMinVel.evaluate(mesh)\n",
    "\n",
    "_maxMinSr = maxMin(strainRate_2ndInvariant) \n",
    "dummyFn = _maxMinSr.evaluate(mesh)\n",
    "\n",
    "\n",
    "#Surface extrema\n",
    "_maxMinVxSurf = maxMin(vx)\n",
    "dummyFn = _maxMinVxSurf.evaluate(tWalls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Volume Ints\n",
    "areaintRock = _areaintRock.evaluate()[0]\n",
    "tempintRock = _tempintRock.evaluate()[0]\n",
    "rmsintRock = _rmsintRock.evaluate()[0]\n",
    "dwintRock = _dwintRock.evaluate()[0]\n",
    "vdintRock = _vdintRock.evaluate()[0]\n",
    "areaintLith = _areaintLith.evaluate()[0]\n",
    "tempintLith = _tempintLith.evaluate()[0]\n",
    "rmsintLith = _rmsintLith.evaluate()[0]\n",
    "dwintLith = _dwintLith.evaluate()[0]\n",
    "vdintLith = _vdintLith.evaluate()[0]\n",
    "areaintLower = _areaintLower.evaluate()[0]\n",
    "tempintLower = _tempintLower.evaluate()[0]\n",
    "rmsintLower = _rmsintLower.evaluate()[0]\n",
    "dwintLower = _dwintLower.evaluate()[0]\n",
    "vdintLower = _vdintLower.evaluate()[0]\n",
    "vdintHinge = _vdintHinge.evaluate()[0]\n",
    "areaintHinge = _areaintHinge.evaluate()[0]\n",
    "\n",
    "#Surface Ints\n",
    "surfLength = _surfLength.evaluate()[0]\n",
    "rmsSurf = _rmsSurf.evaluate()[0]\n",
    "nuTop = _nuTop.evaluate()[0]\n",
    "nuBottom = _nuBottom.evaluate()[0]\n",
    "plateness = _plateness.evaluate()[0]\n",
    "\n",
    "#Max mins\n",
    "maxVel = _maxMinVel.max_global()\n",
    "minVel = _maxMinVel.min_global() \n",
    "maxSr = _maxMinSr.max_global()\n",
    "minSr = _maxMinSr.min_global()\n",
    "maxVxsurf = _maxMinVxSurf.max_global()\n",
    "minVxsurf = _maxMinVxSurf.min_global()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "3.81399229205\n",
      "75.3325503856\n",
      "1.55396221115\n",
      "1798532.66722\n",
      "0.375693682455\n",
      "0.195991824332\n",
      "13.6856157949\n",
      "-0.874640752617\n",
      "1671940.09023\n",
      "0.244240887702\n",
      "0.126193601564\n",
      "13.0391731558\n",
      "-0.681183624713\n",
      "351948.171898\n",
      "258230.908924\n",
      "4.0\n",
      "5929.36376448\n",
      "-70.9531465275\n",
      "0.0\n",
      "2.10333852041\n",
      "105.032522262\n",
      "0.0\n",
      "3439.36839803\n",
      "0.00314488062949\n",
      "54.4884224865\n",
      "-2.07350406386\n"
     ]
    }
   ],
   "source": [
    "print(areaintRock)\n",
    "print(tempintRock)\n",
    "print(rmsintRock)\n",
    "print(dwintRock)\n",
    "print(vdintRock)\n",
    "print(areaintLith)\n",
    "print(tempintLith )\n",
    "print(rmsintLith)\n",
    "print(dwintLith)\n",
    "print(vdintLith)\n",
    "print(areaintLower)\n",
    "print(tempintLower)\n",
    "print(rmsintLower) \n",
    "print(dwintLower)\n",
    "print(vdintLower)\n",
    "print(vdintHinge)\n",
    "\n",
    "print(surfLength)\n",
    "print(rmsSurf)\n",
    "print(nuTop)\n",
    "print(nuBottom)\n",
    "print(plateness)\n",
    "\n",
    "\n",
    "print(maxVel)\n",
    "print(minVel)\n",
    "print(maxSr)\n",
    "print(minSr)\n",
    "print(maxVxsurf)\n",
    "print(minVxsurf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viz.\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#viscVariable = gSwarm.add_variable( dataType=\"float\", count=1 )\n",
    "#viscVariable.data[:] = viscosityMapFn1.evaluate(gSwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if figures == 'gldb':\n",
    "    #Pack some stuff into a database as well\n",
    "    figDb = glucifer.Figure()\n",
    "    #figDb.append( glucifer.objects.Mesh(mesh))\n",
    "    figDb.append( glucifer.objects.VectorArrows(mesh,velocityField, scaling=0.0005))\n",
    "    #figDb.append( glucifer.objects.Points(gSwarm,tracerVariable, colours= 'white black'))\n",
    "    figDb.append( glucifer.objects.Points(gSwarm,materialVariable))\n",
    "    #figDb.append( glucifer.objects.Points(gSwarm,viscMinVariable))\n",
    "    #figDb.append( glucifer.objects.Points(gSwarm,fnViscMin))\n",
    "    #figDb.append( glucifer.objects.Points(gSwarm,viscosityMapFn1, logScale=True))\n",
    "    figDb.append( glucifer.objects.Points(gSwarm, strainRate_2ndInvariant))\n",
    "    figDb.append( glucifer.objects.Points(gSwarm,temperatureField))\n",
    "    \n",
    "    \n",
    "    figRestrict= glucifer.Figure()\n",
    "    figRestrict.append( glucifer.objects.Points(gSwarm,respltFn))\n",
    "    figRestrict.append( glucifer.objects.Points(slab_line.swarm, colours=\"Black Black\", pointSize=2.0, colourBar=False) )\n",
    "\n",
    "elif figures == 'store':\n",
    "    fullpath = os.path.join(outputPath + \"gldbs/\")\n",
    "    store = glucifer.Store(fullpath + 'subduction.gldb')\n",
    "\n",
    "    figTemp = glucifer.Figure(store,figsize=(300*np.round(aspectRatio,2),300))\n",
    "    figTemp.append( glucifer.objects.Points(gSwarm,temperatureField))\n",
    "\n",
    "    figVisc= glucifer.Figure(store, figsize=(300*np.round(aspectRatio,2),300))\n",
    "    figVisc.append( glucifer.objects.Points(gSwarm,viscosityMapFn1, logScale=True, valueRange =[1e-3,1e5]))\n",
    "\n",
    "    #figMech= glucifer.Figure(store, figsize=(300*np.round(aspectRatio,2),300))\n",
    "    #figMech.append( glucifer.objects.Points(gSwarm,fnViscMin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Miscellania**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/core/numeric.py:190: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  a = empty(shape, dtype, order)\n"
     ]
    }
   ],
   "source": [
    "##############\n",
    "#Create a numpy array at the surface to get surface information on (using parallel-friendly evaluate_global)\n",
    "##############\n",
    "\n",
    "surface_xs = np.linspace(mesh.minCoord[0], mesh.maxCoord[0], mesh.elementRes[0] + 1)\n",
    "surface_nodes = np.array(zip(surface_xs, np.ones(len(surface_xs)*mesh.maxCoord[1]))) #For evaluation surface velocity\n",
    "normgradV = velocityField.fn_gradient[0]/fn.math.sqrt(velocityField[0]*velocityField[0])\n",
    "\n",
    "tempMM = fn.view.min_max(temperatureField)\n",
    "dummy = tempMM.evaluate(mesh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#These functions handle checkpointing\n",
    "##############\n",
    "\n",
    "\n",
    "#Subzone = ndp.subzone\n",
    "\n",
    "\n",
    "def checkpoint1(step, checkpointPath,filename, filewrites):\n",
    "    path = checkpointPath + str(step) \n",
    "    os.mkdir(path)\n",
    "    ##Write and save the file, if not already a writing step\n",
    "    if not step % filewrites == 0:\n",
    "        f_o.write((22*'%-15s ' + '\\n') % (areaintRock, tempintRock, rmsintRock, dwintRock, vdintRock,\n",
    "                                  areaintLith, tempintLith,rmsintLith, dwintLith, vdintLith,\n",
    "                                  areaintLower, tempintLower, rmsintLower, dwintLower, vdintLower, \n",
    "                                  vdintHinge,rmsSurf, nuTop, nuBottom, plateness, ndp.subzone, realtime))\n",
    "    filename.close()\n",
    "    shutil.copyfile(os.path.join(outputPath, outputFile), os.path.join(path, outputFile))\n",
    "\n",
    "\n",
    "def checkpoint2(step, checkpointPath, swarm, filename, varlist = [materialVariable], varnames = ['materialVariable']):\n",
    "    path = checkpointPath + str(step) \n",
    "    velfile = \"velocityField\" + \".hdf5\"\n",
    "    tempfile = \"temperatureField\" + \".hdf5\"\n",
    "    pressfile = \"pressureField\" + \".hdf5\"\n",
    "    velocityField.save(os.path.join(path, velfile))\n",
    "    temperatureField.save(os.path.join(path, tempfile))\n",
    "    pressureField.save(os.path.join(path, pressfile))\n",
    "    swarm.save(os.path.join(path, \"swarm.h5\") ) \n",
    "    for ix in range(len(varlist)):\n",
    "        varb = varlist[ix]\n",
    "        varb.save(os.path.join(path,varnames[ix] + \".h5\"))\n",
    "    \n",
    "    #Save the parameters\n",
    "    dict_list = [dp, sf, ndp, md] #if any of the dictionaries have changed, this list needs to be rebuilt\n",
    "    save_pickles(dict_list, dict_names, path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#These functions handle checkpointing\n",
    "##############\n",
    "\n",
    "def getnearpos(array,value):\n",
    "    idx = (np.abs(array-value)).argmin()\n",
    "    return idx \n",
    "\n",
    "def plate_info(srfilename, minx, maxx,  searchdx, oldszloc = 0.0):\n",
    "    \"\"\"\n",
    "    Use the surface strain rate field to find the location of the subduction zone in 2d\n",
    "    \n",
    "    \"\"\"\n",
    "    if type(srfilename) == str: #read surface strain rate points from file\n",
    "        sr = np.load(srfilename)\n",
    "    else:\n",
    "        sr =  srfilename        #read surface strain rates directly from array\n",
    "    xs = np.linspace(minx,maxx,sr.shape[0] )\n",
    "    #infs at the ends of the SR data...replace with adjacent values\n",
    "    sr[0] = sr[1] \n",
    "    sr[-1] = sr[2]\n",
    "    #Normalize\n",
    "    srx = (sr- sr.mean()) /(sr.max() - sr.min())\n",
    "    #reduce the search domain, to near the previous PB location\n",
    "    lx, rx = getnearpos(xs, oldszloc - searchdx),  getnearpos(xs, oldszloc + searchdx)\n",
    "    red_xs, red_sr = xs[lx:rx], srx[lx:rx]\n",
    "    #return the minima\n",
    "    newszLoc = red_xs[np.argmin(red_sr)]\n",
    "    return newszLoc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialise timer for computation\n",
    "start = time.clock()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#max_vx_surf(velocityField, mesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main simulation loop\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-190-f9c389f79938>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mfnamedb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"restrictFig\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".gldb\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mfullpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputPath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"gldbs/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfnamedb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             \u001b[0mfigRestrict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_database\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mfigures\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'store'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[0mfullpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputPath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"gldbs/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/root/underworld2/glucifer/_glucifer.pyc\u001b[0m in \u001b[0;36msave_database\u001b[1;34m(self, filename, regen)\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave_database\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mregen\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 576\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generate_DB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    577\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/root/underworld2/glucifer/_glucifer.pyc\u001b[0m in \u001b[0;36m_generate_DB\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    609\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m             \u001b[0mobjects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobjects\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_generate_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/root/underworld2/glucifer/_glucifer.pyc\u001b[0m in \u001b[0;36m_generate\u001b[1;34m(self, figname, objects, props)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[1;31m# go ahead and fill db\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m             \u001b[0mlibUnderworld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgLucifer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lucDatabase_Execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_db\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[1;31m#Output any custom geometry on objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#while step < 6:\n",
    "while realtime < 0.002:\n",
    "\n",
    "    # solve Stokes and advection systems\n",
    "    solver.solve(nonLinearIterate=True)\n",
    "    dt = advDiff.get_max_dt()\n",
    "    if step == 0:\n",
    "        dt = 0.\n",
    "    advDiff.integrate(dt)\n",
    "    passiveadvector.integrate(dt)\n",
    "    slab_line.advection(dt)\n",
    "    for f in faults:\n",
    "        f.advection(dt)\n",
    "        \n",
    "    \n",
    " \n",
    "    \n",
    "    # Increment\n",
    "    realtime += dt\n",
    "    step += 1\n",
    "    timevals.append(realtime)\n",
    "    ################\n",
    "    #Update temperature field in the air region\n",
    "    #Do this better...\n",
    "    ################\n",
    "    if (step % sticky_air_temp == 0):\n",
    "        for index, coord in enumerate(mesh.data):\n",
    "            if coord[1] >= 1.:\n",
    "                temperatureField.data[index] = ndp.TSP\n",
    "\n",
    "    # Calculate the Metrics, only on 1 of the processors:\n",
    "    ################\n",
    "    if (step % metric_output == 0):\n",
    "        ###############\n",
    "        #Rebuild the restriction functions where necessary\n",
    "        ###############\n",
    "        lowerPlateRestFn = gSwarm.add_variable( dataType=\"double\", count=1 )\n",
    "        lowerPlateRestFn.data[:] = 0.0\n",
    "        update_swarm_from_line(slab_line, lowerPlateRestFn )\n",
    "        lowerPlateRestFn.data[np.where(lowerPlateRestFn.data >= -1.*fthickness)] = 1.\n",
    "        lowerPlateRestFn.data[np.where(lowerPlateRestFn.data < -1.*fthickness)] = 0. \n",
    "        lowerPlateRestFn *= lithRestFn #Add next level up in hierarchy\n",
    "        \n",
    "        ###############\n",
    "        #Metrics\n",
    "        ###############\n",
    "        areaintRock = _areaintRock.evaluate()[0] #trivial except when using sticky air\n",
    "        tempintRock = _tempintRock.evaluate()[0]\n",
    "        rmsintRock = _rmsintRock.evaluate()[0]\n",
    "        dwintRock = _dwintRock.evaluate()[0]\n",
    "        vdintRock = _vdintRock.evaluate()[0]\n",
    "        areaintLith = _areaintLith.evaluate()[0]\n",
    "        tempintLith = _tempintLith.evaluate()[0]\n",
    "        rmsintLith = _rmsintLith.evaluate()[0]\n",
    "        dwintLith = _dwintLith.evaluate()[0]\n",
    "        vdintLith = _vdintLith.evaluate()[0]\n",
    "        areaintLower = _areaintLower.evaluate()[0]\n",
    "        tempintLower = _tempintLower.evaluate()[0]\n",
    "        rmsintLower = _rmsintLower.evaluate()[0]\n",
    "        dwintLower = _dwintLower.evaluate()[0]\n",
    "        vdintLower = _vdintLower.evaluate()[0]\n",
    "        vdintHinge = _vdintHinge.evaluate()[0]\n",
    "        #Surface integrals\n",
    "        rmsSurf = _rmsSurf.evaluate()[0]\n",
    "        nuTop = _nuTop.evaluate()[0]\n",
    "        nuBottom = _nuBottom.evaluate()[0]\n",
    "        plateness = _plateness.evaluate()[0]\n",
    "        #extrema\n",
    "        maxVel = _maxMinVel.max_global()\n",
    "        minVel = _maxMinVel.min_global() \n",
    "        maxSr = _maxMinSr.max_global()\n",
    "        minSr = _maxMinSr.min_global()\n",
    "        maxVxsurf = _maxMinVxSurf.max_global()\n",
    "        minVxsurf = _maxMinVxSurf.min_global()\n",
    "        # output to summary text file\n",
    "        if uw.rank()==0:\n",
    "            f_o.write((22*'%-15s ' + '\\n') % (areaintRock, tempintRock, rmsintRock, dwintRock, vdintRock,\n",
    "                                  areaintLith, tempintLith,rmsintLith, dwintLith, vdintLith,\n",
    "                                  areaintLower, tempintLower, rmsintLower, dwintLower, vdintLower, \n",
    "                                  vdintHinge,rmsSurf, nuTop, nuBottom, plateness, ndp.subzone, realtime))\n",
    "    ################\n",
    "    #Also repopulate entire swarm periodically\n",
    "    ################\n",
    "    #if step % swarm_repop == 0:\n",
    "    population_control.repopulate()   \n",
    "    ################\n",
    "    #Checkpoint\n",
    "    ################\n",
    "    if step % checkpoint_every == 0:\n",
    "        if uw.rank() == 0:\n",
    "            checkpoint1(step, checkpointPath,f_o, metric_output)           \n",
    "        checkpoint2(step, checkpointPath, gSwarm, f_o, varlist = varlist, varnames = varnames)\n",
    "        f_o = open(os.path.join(outputPath, outputFile), 'a') #is this line supposed to be here?\n",
    "    ################\n",
    "    #Gldb output\n",
    "    ################ \n",
    "    if (step % gldbs_output == 0): \n",
    "        if figures == 'gldb':\n",
    "            #Remember to rebuild any necessary swarm variables\n",
    "            fnamedb = \"dbFig\" + \"_\" + str(step) + \".gldb\"\n",
    "            fullpath = os.path.join(outputPath + \"gldbs/\" + fnamedb)\n",
    "            figDb.save_database(fullpath)\n",
    "            \n",
    "            #Temp figure\n",
    "            fnamedb = \"restrictFig\" + \"_\" + str(step) + \".gldb\"\n",
    "            fullpath = os.path.join(outputPath + \"gldbs/\" + fnamedb)\n",
    "            figRestrict.save_database(fullpath)\n",
    "        elif figures == 'store':      \n",
    "            fullpath = os.path.join(outputPath + \"gldbs/\")\n",
    "            store.step = step\n",
    "            #Save figures to store\n",
    "            figVisc.save( fullpath + \"Visc\" + str(step).zfill(4))\n",
    "            #figMech.save( fullPath + \"Mech\" + str(step).zfill(4))\n",
    "            figTemp.save( fullpath + \"Temp\"    + str(step).zfill(4))\n",
    "    ################\n",
    "    #Files output\n",
    "    ################ \n",
    "    if (step % files_output == 0):\n",
    "\n",
    "        vel_surface = velocityField.evaluate_global(surface_nodes)\n",
    "        norm_surface_sr = normgradV.evaluate_global(surface_nodes)\n",
    "        if uw.rank() == 0:\n",
    "            fnametemp = \"velsurface\" + \"_\" + str(step)\n",
    "            fullpath = os.path.join(outputPath + \"files/\" + fnametemp)\n",
    "            np.save(fullpath, vel_surface)\n",
    "            fnametemp = \"norm_surface_sr\" + \"_\" + str(step)\n",
    "            fullpath = os.path.join(outputPath + \"files/\" + fnametemp)\n",
    "            np.save(fullpath, norm_surface_sr)\n",
    "            \n",
    "        #Save the slab_lineand tipswarm coords \n",
    "        fnametemp1 = \"midSwarm\" + \"_\" + str(step)\n",
    "        fullpath1 = os.path.join(outputPath + \"files/\" + fnametemp1)\n",
    "        slab_line.swarm.save(fullpath1)\n",
    "        #tipVar.data[:,:2] = velocityField.evaluate(tipSwarm)\n",
    "        #tipVar.data[:,2:] = xFn.evaluate(tipSwarm)\n",
    "        #tipVar.data[:,3:] = yFn.evaluate(tipSwarm)\n",
    "        #comm.barrier()\n",
    "        #fnametemp2 = \"tipSwarm\" + \"_\" + str(step)\n",
    "        #fullpath2 = os.path.join(outputPath + \"files/\" + fnametemp2)\n",
    "        #tipVar.save('fullpath2')\n",
    "            \n",
    "    ################\n",
    "    #Update the subduction zone / plate information\n",
    "    ################ \n",
    "    \n",
    "    comm.barrier()\n",
    "    if (step % files_output == 0):\n",
    "        \n",
    "        if uw.rank() == 0:\n",
    "            fnametemp = \"norm_surface_sr\" + \"_\" + str(step) + \".npy\"\n",
    "            fullpath = os.path.join(outputPath + \"files/\" + fnametemp)\n",
    "            ndp.subzone = plate_info(fullpath, MINX, MAXX,  800e3/dp.LS, oldszloc = ndp.subzone)\n",
    "            \n",
    "        else:\n",
    "            ndp.subzone = None\n",
    "        \n",
    "        comm.barrier()    \n",
    "        #send out the updated info for sz location\n",
    "        \n",
    "        ndp.subzone = comm.bcast(ndp.subzone, root=0)\n",
    "\n",
    "        #Has the polarity reversed?\n",
    "\n",
    "        if dp.sense == 'right':\n",
    "            tempop = operator.lt\n",
    "            szoffet *= -1\n",
    "        else:\n",
    "            tempop = operator.gt\n",
    "            \n",
    "        #Update the relevant parts of the material graph\n",
    "        #Remove and rebuild edges related to crust\n",
    "        DG.remove_edges_from([(mantleIndex,crustIndex)])\n",
    "        DG.add_edges_from([(mantleIndex,crustIndex)])\n",
    "        DG.remove_edges_from([(harzIndex,crustIndex)])\n",
    "        DG.add_edges_from([(harzIndex,crustIndex)])\n",
    "\n",
    "        #... to crust\n",
    "        DG.add_transition((mantleIndex,crustIndex), depthFn, operator.lt, 0.5)\n",
    "        DG.add_transition((mantleIndex,crustIndex), xFn, tempop , ndp.subzone) #No crust on the upper plate\n",
    "        DG.add_transition((mantleIndex,crustIndex), ageVariable, operator.gt, 0.2)\n",
    "\n",
    "        DG.add_transition((harzIndex,crustIndex), depthFn, operator.lt, ndp.MANTLETOCRUST)\n",
    "        DG.add_transition((harzIndex,crustIndex), xFn, tempop, ndp.subzone) #This one sets no crust on the upper plate\n",
    "        DG.add_transition((harzIndex,crustIndex), ageVariable, operator.gt, crustageCond)\n",
    "        \n",
    "        comm.barrier()\n",
    "                   \n",
    "    \n",
    "    ################\n",
    "    #Particle update\n",
    "    ###############    \n",
    "    #ageVariable.data[:] += dt #increment the ages (is this efficient?)\n",
    "    ageDT += dt\n",
    "    \n",
    "    if step % swarm_update == 0:\n",
    "        #Increment age stuff. \n",
    "        ageConditions = [ (depthFn < ndp.AGETRACKDEPTH, ageVariable + ageDT ),  #add ageDThere\n",
    "                  (True, 0.) ]\n",
    "        ageVariable.data[:] = fn.branching.conditional( ageConditions ).evaluate(gSwarm)        \n",
    "        ageDT = 0. #reset the age incrementer\n",
    "        \n",
    "        #Apply any materialVariable changes\n",
    "        for i in range(2): #go through twice\n",
    "            materialVariable.data[:] = fn.branching.conditional(DG.condition_list).evaluate(gSwarm)\n",
    "        \n",
    "        #Also update any information related to faults:\n",
    "        update_swarm_from_faults(faults[1:], proximityVariable, directorVector, signedDistanceVariable)\n",
    "        mask_materials(faults[1], airIndex, materialVariable, proximityVariable, directorVector, signedDistanceVariable)\n",
    "\n",
    "        update_swarm_from_faults(faults[0:-1], proximityVariable, directorVector, signedDistanceVariable)\n",
    "        mask_materials(faults[0], crustIndex, materialVariable, proximityVariable, directorVector, signedDistanceVariable)\n",
    "        \n",
    "        proximityVariable.data[gSwarm.particleCoordinates.data[:,1]  < (1. - ndp.CRUSTVISCUTOFF)] = 0.\n",
    "            \n",
    "    \n",
    "\n",
    "    \n",
    "f_o.close()\n",
    "print 'step =',step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
