{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composite, non-linear rheology, extended Boussinesq approximation:\n",
    "\n",
    "\n",
    "The viscous rheology in this model is similar to the Garel et al paper cited below. Other parts of the model setup are similar to Čížková and Bina (2015), Arredondo and Billen (2016).\n",
    "\n",
    "Here we use a dimensionless system. For the psuedo-plastic effective rheology a Drucker-prager model is used.\n",
    "\n",
    "\n",
    "**Keywords:** subduction, composite rheology, dislocation creep\n",
    "\n",
    "\n",
    "**References:**\n",
    "\n",
    "\n",
    "Garel, Fanny, et al. \"Interaction of subducted slabs with the mantle transition‐zone: A regime diagram from 2‐D thermo‐mechanical models with a mobile trench and an overriding plate.\" Geochemistry, Geophysics, Geosystems 15.5 (2014): 1739-1765.\n",
    "\n",
    "Čížková, Hana, and Craig R. Bina. \"Geodynamics of trench advance: Insights from a Philippine-Sea-style geometry.\" Earth and Planetary Science Letters 430 (2015): 408-415.\n",
    "\n",
    "Arredondo, Katrina M., and Magali I. Billen. \"The Effects of Phase Transitions and Compositional Layering in Two-dimensional Kinematic Models of Subduction.\" Journal of Geodynamics (2016).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/underworld2/unsupported/interfaces/__init__.py:9: UserWarning: \n",
      "\n",
      "The interface module is not supported.\n",
      "Questions should be addressed to louis.moresi@unimelb.edu.au \n",
      " \n",
      "  Questions should be addressed to louis.moresi@unimelb.edu.au \\n \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import underworld as uw\n",
    "import math\n",
    "from underworld import function as fn\n",
    "import glucifer\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import natsort\n",
    "import shutil\n",
    "from easydict import EasyDict as edict\n",
    "import operator\n",
    "import pint\n",
    "import time\n",
    "import operator\n",
    "from slippy2 import boundary_layer2d\n",
    "from slippy2 import material_graph\n",
    "from slippy2 import spmesh\n",
    "from slippy2 import phase_function\n",
    "from unsupported.interfaces import markerLine2D\n",
    "\n",
    "\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#####\n",
    "#Stubborn version number conflicts - need to figure out my Docker container runs an old version. For now...\n",
    "#####\n",
    "try:\n",
    "    natsort.natsort = natsort.natsorted\n",
    "except:\n",
    "    natsort.natsort = natsort.natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#store = glucifer.Store('subduction')\n",
    "#figParticle = glucifer.Figure( store, figsize=(960,300), name=\"Particles\" )\n",
    "\n",
    "#figParticle.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model name and directories\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############\n",
    "#Model letter and number\n",
    "############\n",
    "\n",
    "\n",
    "#Model letter identifier default\n",
    "Model = \"T\"\n",
    "\n",
    "#Model number identifier default:\n",
    "ModNum = 0\n",
    "\n",
    "#Any isolated letter / integer command line args are interpreted as Model/ModelNum\n",
    "\n",
    "if len(sys.argv) == 1:\n",
    "    ModNum = ModNum \n",
    "elif sys.argv[1] == '-f': #\n",
    "    ModNum = ModNum \n",
    "else:\n",
    "    for farg in sys.argv[1:]:\n",
    "        if not '=' in farg: #then Assume it's a not a paramter argument\n",
    "            try:\n",
    "                ModNum = int(farg) #try to convert everingthing to a float, else remains string\n",
    "            except ValueError:\n",
    "                Model  = farg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Standard output directory setup\n",
    "###########\n",
    "\n",
    "outputPath = \"results\" + \"/\" +  str(Model) + \"/\" + str(ModNum) + \"/\" \n",
    "imagePath = outputPath + 'images/'\n",
    "filePath = outputPath + 'files/'\n",
    "checkpointPath = outputPath + 'checkpoint/'\n",
    "dbPath = outputPath + 'gldbs/'\n",
    "xdmfPath = outputPath + 'xdmf/'\n",
    "outputFile = 'results_model' + Model + '_' + str(ModNum) + '.dat'\n",
    "\n",
    "if uw.rank()==0:\n",
    "    # make directories if they don't exist\n",
    "    if not os.path.isdir(outputPath):\n",
    "        os.makedirs(outputPath)\n",
    "    if not os.path.isdir(checkpointPath):\n",
    "        os.makedirs(checkpointPath)\n",
    "    if not os.path.isdir(imagePath):\n",
    "        os.makedirs(imagePath)\n",
    "    if not os.path.isdir(dbPath):\n",
    "        os.makedirs(dbPath)\n",
    "    if not os.path.isdir(filePath):\n",
    "        os.makedirs(filePath)\n",
    "    if not os.path.isdir(xdmfPath):\n",
    "        os.makedirs(xdmfPath)\n",
    "        \n",
    "comm.Barrier() #Barrier here so no procs run the check in the next cell too early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/T/0/checkpoint/ is empty\n"
     ]
    }
   ],
   "source": [
    "###########\n",
    "#Check if starting from checkpoint\n",
    "###########\n",
    "\n",
    "checkdirs = []\n",
    "for dirpath, dirnames, files in os.walk(checkpointPath):\n",
    "    if files:\n",
    "        print dirpath, 'has files'\n",
    "        checkpointLoad = True\n",
    "        checkdirs.append(dirpath)\n",
    "    if not files:\n",
    "        print dirpath, 'is empty'\n",
    "        checkpointLoad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup summary output file (name above)\n",
    "if checkpointLoad:\n",
    "    checkpointLoadDir = natsort.natsort(checkdirs)[-1]\n",
    "    if uw.rank() == 0:\n",
    "        shutil.copyfile(os.path.join(checkpointLoadDir, outputFile), outputPath+outputFile)\n",
    "    comm.Barrier()\n",
    "    f_o = open(os.path.join(outputPath, outputFile), 'a')\n",
    "    prevdata = np.genfromtxt(os.path.join(outputPath, outputFile), skip_header=0, skip_footer=0)\n",
    "    if len(prevdata.shape) == 1: #this is in case there is only one line in previous file\n",
    "        realtime = prevdata[-1]  #This corresponds to the column you write time data to\n",
    "    else:\n",
    "        realtime = prevdata[prevdata.shape[0]-1, -1]\n",
    "    step = int(checkpointLoadDir.split('/')[-1])\n",
    "    timevals = [0.]\n",
    "else:\n",
    "    f_o = open(outputPath+outputFile, 'w')\n",
    "    realtime = 0.\n",
    "    step = 0\n",
    "    timevals = [0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup parameters\n",
    "-----\n",
    "\n",
    "Set simulation parameters for test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use pint to setup any unit conversions we'll need**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "10000.0 meter/megayear"
      ],
      "text/latex": [
       "$10000.0 \\frac{meter}{megayear}$"
      ],
      "text/plain": [
       "<Quantity(10000.0, 'meter / megayear')>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = pint.UnitRegistry()\n",
    "cmpery = 1.*u.cm/u.year\n",
    "mpermy = 1.*u.m/u.megayear\n",
    "year = 1.*u.year\n",
    "spery = year.to(u.sec)\n",
    "cmpery.to(mpermy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.04, 1.2675505856327397e-11)\n"
     ]
    }
   ],
   "source": [
    "box_half_width =4000e3\n",
    "age_at_trench = 100e6\n",
    "cmperyear = box_half_width / age_at_trench #m/y\n",
    "mpersec = cmperyear*(cmpery.to(u.m/u.second)).magnitude #m/sec\n",
    "print(cmperyear, mpersec )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set parameter dictionaries**\n",
    "\n",
    "* Parameters are stored in dictionaries. \n",
    "* If starting from checkpoint, parameters are loaded using pickle\n",
    "* If params are passed in as flags to the script, they overwrite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Parameter / settings dictionaries get saved&loaded using pickle\n",
    "###########\n",
    " \n",
    "dp = edict({}) #dimensional parameters\n",
    "sf = edict({}) #scaling factors\n",
    "ndp = edict({}) #dimensionless paramters\n",
    "md = edict({}) #model paramters, flags etc\n",
    "#od = edict({}) #output frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dict_list = [dp, sf, ndp, md]\n",
    "dict_names = ['dp.pkl', 'sf.pkl', 'ndp.pkl', 'md.pkl']\n",
    "\n",
    "def save_pickles(dict_list, dict_names, dictPath):\n",
    "    import pickle\n",
    "    counter = 0\n",
    "    for pdict in dict_list:\n",
    "        myfile = os.path.join(dictPath, dict_names[counter])\n",
    "        with open(myfile, 'wb') as f:\n",
    "            pickle.dump(pdict, f)\n",
    "        counter+=1\n",
    "\n",
    "\n",
    "#ended up having to pretty much write a hard-coded function\n",
    "#All dictionaries we want checkpointed will have to  be added here \n",
    "#and where the function is called\n",
    "#Fortunately, this function is only called ONCE\n",
    "\n",
    "def load_pickles():\n",
    "    import pickle\n",
    "    dirpath = os.path.join(checkpointPath, str(step))\n",
    "    dpfile = open(os.path.join(dirpath, 'dp.pkl'), 'r')\n",
    "    dp = pickle.load(dpfile)\n",
    "#    #\n",
    "    ndpfile = open(os.path.join(dirpath, 'ndp.pkl'), 'r')\n",
    "    ndp = edict(pickle.load(ndpfile))\n",
    "    #\n",
    "    sffile = open(os.path.join(dirpath, 'sf.pkl'), 'r')\n",
    "    sf = edict(pickle.load(sffile))\n",
    "    #\n",
    "    mdfile = open(os.path.join(dirpath, 'md.pkl'), 'r')\n",
    "    md = edict(pickle.load(mdfile))\n",
    "    return dp, ndp, sf, md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Store the physical parameters, scale factors and dimensionless pramters in easyDicts\n",
    "#Mainly helps with avoiding overwriting variables\n",
    "###########\n",
    "\n",
    "\n",
    "#Style => parameters_like_this\n",
    "\n",
    "dp = edict({#Main physical paramters\n",
    "           'depth':2000e3, #Depth\n",
    "           'LS':2900.*1e3, #Length scale\n",
    "           'rho':3300.,  #reference density\n",
    "           'g':9.8, #surface gravity\n",
    "           'eta0':1e20, #Dislocation creep at 250 km, 1573 K, 1e-15 s-1 \n",
    "           'k':1e-6, #thermal diffusivity\n",
    "           'a':3e-5, #surface thermal expansivity\n",
    "           'R':8.314, #gas constant\n",
    "           'Cp':1250., #Specific heat (Jkg-1K-1)\n",
    "           'TP':1573., #mantle potential temp (K)\n",
    "           'TS':273., #surface temp (K)\n",
    "            #Rheology - flow law paramters\n",
    "           'cm':2e6, #mantle cohesion in Byerlee law\n",
    "           'cc':2e6, #crust cohesion in Byerlee law\n",
    "           'fcm':0.2,   #mantle friction coefficient in Byerlee law (tan(phi))\n",
    "           'fcc':0.02,   #crust friction coefficient \n",
    "           'Adf':3e-11, #pre-exp factor for diffusion creep\n",
    "           'Ads':5e-16, #pre-exp factor for dislocation creep\n",
    "           'Apr':1e-150,#pre-exp factor for Peierls creep\n",
    "           #'Apr':1e-145,#pre-exp factor for Peierls creep\n",
    "           'Edf':3e5,\n",
    "           'Eds':5.4e5,\n",
    "           'Epr':5.4e5,\n",
    "           'Vdf':4e-6,\n",
    "           'Vds':12e-6,\n",
    "           'Vpr':10e-6,\n",
    "           'Alm':2e-17,\n",
    "           'Elm':2.0e5,\n",
    "           'Vlm':1.5e-6,\n",
    "           'SR':1e-15, #reference strain rate\n",
    "           'n':3.5, #Dislocation creep stress exponent\n",
    "           'np':20., #Peierls creep stress exponent \n",
    "           #Rheology - cutoff values\n",
    "           'eta_min':1e18, \n",
    "           'eta_max':1e25, #viscosity max in the mantle material\n",
    "           'eta_min_crust':1e18, #viscosity min in the weak-crust material\n",
    "           'eta_max_crust':1e20, #viscosity max in the weak-crust material\n",
    "           'ysMax':10000*1e6, #10 GPa\n",
    "           #Length scales\n",
    "           'MANTLETOCRUST':8.*1e3, #Crust depth\n",
    "           'HARZBURGDEPTH':40e3,\n",
    "           'CRUSTTOMANTLE':800.*1e3,\n",
    "           'LITHTOMANTLE':(900.*1e3),\n",
    "           'MANTLETOLITH':200.*1e3, \n",
    "           'TOPOHEIGHT':10.*1e3,  #rock-air topography limits\n",
    "           'CRUSTTOECL':100.*1e3,\n",
    "           'LOWMANTLEDEPTH':660.*1e3, \n",
    "           'CRUSTVISCUTOFF':250.*1e3, #Deeper than this, crust material rheology reverts to mantle rheology\n",
    "           'AGETRACKDEPTH':100e3, #above this depth we track the age of the lithsphere (below age is assumed zero)\n",
    "           #Slab and plate parameters\n",
    "           'roc':250e3,     #radius of curvature of slab\n",
    "           'subzone':0.0,   #X position of subduction zone...km\n",
    "           'lRidge':-1.*(5000e3),  #For depth = 670 km, aspect ratio of 4, this puts the ridges at MINX, MAXX\n",
    "           'rRidge':(5000e3),\n",
    "           'maxDepth':200e3,\n",
    "           'theta':70., #Angle to truncate the slab (can also control with a maxDepth param)\n",
    "           'slabmaxAge':100e6, #age of subduction plate at trench\n",
    "           'platemaxAge':100e6, #max age of slab (Plate model)\n",
    "           'opmaxAge':100e6, #age of op\n",
    "           'sense':'Right', #dip direction\n",
    "           #'op_age_fac':0.2, #this controls the overidding plate age reduction\n",
    "           #Misc\n",
    "           'rDepth':250e3, #reference depth (used to scale / normalize the flow laws)\n",
    "           'StALS':100e3, #depth of sticky air layer\n",
    "           'Steta_n':1e19, #stick air viscosity, normal\n",
    "           'Steta_s':1e18, #stick air viscosity, shear \n",
    "           'plate_vel':4,\n",
    "           'low_mantle_visc_fac':1.\n",
    "             })\n",
    "\n",
    "#append any derived parameters to the dictionary\n",
    "#Adiabatic heating stuff\n",
    "\n",
    "#dp.dTa = (dp.a*dp.g*(dp.TP))/dp.Cp #adibatic gradient, at Tp\n",
    "dp.dTa = 0.0005 #adiabatic gradient, upper mantle value used in Garel et al. \n",
    "dp.deltaTa = (dp.TP + dp.dTa*dp.LS) - dp.TS  #Adiabatic Temp at base of mantle, minus Ts\n",
    "\n",
    "dp.rTemp= dp.TP + dp.rDepth*dp.dTa #reference temp, (potential temp + adiabat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Modelling and Physics switches\n",
    "\n",
    "md = edict({'refineMesh':False,\n",
    "            'stickyAir':False,\n",
    "            'subductionFault':False,\n",
    "            'symmetricIcs':False,\n",
    "            'velBcs':False,\n",
    "            'aspectRatio':5., # (aspect ratio of 6.897, i.e preserves width when half mantle depth is used\n",
    "            'compBuoyancy':False, #use compositional & phase buoyancy, or simply thermal\n",
    "            'periodicBcs':False,\n",
    "            'RES':64,\n",
    "            'PIC_integration':True,\n",
    "            'ppc':50,\n",
    "            'elementType':\"Q1/dQ0\",\n",
    "            #'elementType':\"Q2/DPC1\",\n",
    "            'compBuoyancy':False, #use compositional & phase buoyancy, or simply thermal\n",
    "            'viscMechs':['diffusion', 'dislocation', 'peierls', 'yielding'],\n",
    "            'viscCombine':'harmonic', #'harmonic', 'min', 'mixed'....\n",
    "            'secInvFac':math.sqrt(1.),\n",
    "            'courantFac':0.5 #extra limitation on timestepping\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#If starting from a checkpoint load params from file\n",
    "###########\n",
    "\n",
    "if checkpointLoad:\n",
    "    dp, ndp, sf, md = load_pickles()  #remember to add any extra dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#If command line args are given, overwrite\n",
    "#Note that this assumes that params as commans line args/\n",
    "#only append to the 'dimensional' and 'model' dictionary (not the non-dimensional)\n",
    "###########    \n",
    "\n",
    "\n",
    "###########\n",
    "#If extra arguments are provided to the script\" eg:\n",
    "### >>> uw.py 2 dp.arg1=1 dp.arg2=foo dp.arg3=3.0\n",
    "###\n",
    "###This would assign ModNum = 2, all other values go into the dp dictionary, under key names provided\n",
    "###\n",
    "###Two operators are searched for, = & *=\n",
    "###\n",
    "###If =, parameter is re-assigned to givn value\n",
    "###If *=, parameter is multipled by given value\n",
    "###\n",
    "### >>> uw.py 2 dp.arg1=1 dp.arg2=foo dp.arg3*=3.0\n",
    "###########\n",
    "\n",
    "for farg in sys.argv[1:]:\n",
    "    try:\n",
    "        (dicitem,val) = farg.split(\"=\") #Split on equals operator\n",
    "        (dic,arg) = dicitem.split(\".\") #colon notation\n",
    "        if '*=' in farg:\n",
    "            (dicitem,val) = farg.split(\"*=\") #If in-place multiplication, split on '*='\n",
    "            (dic,arg) = dicitem.split(\".\")\n",
    "            \n",
    "        if val == 'True': \n",
    "            val = True\n",
    "        elif val == 'False':     #First check if args are boolean\n",
    "            val = False\n",
    "        else:\n",
    "            try:\n",
    "                val = float(val) #next try to convert  to a float,\n",
    "            except ValueError:\n",
    "                pass             #otherwise leave as string\n",
    "        #Update the dictionary\n",
    "        if farg.startswith('dp'):\n",
    "            if '*=' in farg:\n",
    "                dp[arg] = dp[arg]*val #multiply parameter by given factor\n",
    "            else:\n",
    "                dp[arg] = val    #or reassign parameter by given value\n",
    "        if farg.startswith('md'):\n",
    "            if '*=' in farg:\n",
    "                md[arg] = md[arg]*val #multiply parameter by given factor\n",
    "            else:\n",
    "                md[arg] = val    #or reassign parameter by given value\n",
    "                \n",
    "    except:\n",
    "        pass\n",
    "            \n",
    "\n",
    "comm.barrier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2750.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.deltaTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not checkpointLoad:\n",
    "    \n",
    "    #Scaling factors, used to map the dimensional parameters to dimensionless\n",
    "    \n",
    "    sf = edict({'stress':dp.LS**2/(dp.k*dp.eta0),\n",
    "            'lith_grad':dp.rho*dp.g*(dp.LS)**3/(dp.eta0*dp.k) ,\n",
    "            'vel':dp.LS/dp.k,\n",
    "            'SR':dp.LS**2/dp.k,\n",
    "            'W':(dp.rho*dp.g*dp.LS)/(dp.R*dp.deltaTa), #Including adiabatic compression, and deltaTa\n",
    "            'E': 1./(dp.R*dp.deltaTa), #using deltaTa, the guesstimated adiabatic temp differnnce to scale these paramters\n",
    "            'Ads':1./((dp.eta0**(-1.*dp.n))*(dp.k**(1. - dp.n))*(dp.LS**(-2.+ (2.*dp.n)))),\n",
    "            'Adf':dp.eta0,\n",
    "            'Apr':2.6845783276046923e+40 #same form as Ads, but ndp.np =20. (hardcoded because numbers are too big)\n",
    "                \n",
    "\n",
    "           })\n",
    "    \n",
    "     #dimensionless parameters\n",
    "    ndp = edict({'RA':(dp.g*dp.rho*dp.a*dp.deltaTa*(dp.LS)**3)/(dp.k*dp.eta0),\n",
    "             'depth':dp.depth/dp.LS,\n",
    "             'Di': dp.a*dp.g*dp.LS/dp.Cp, #Dissipation number\n",
    "             'H':0.,\n",
    "             #Temperatures and reference depth\n",
    "             'TSP':0., #dimensionless potential temp\n",
    "             'TPP':(dp.TP - dp.TS)/dp.deltaTa, #dimensionless potential temp\n",
    "             'TS':dp.TS/dp.deltaTa,\n",
    "             'TP':dp.TP/dp.deltaTa,\n",
    "             'rTemp':(dp.rTemp- dp.TS)/dp.deltaTa,\n",
    "             'rDepth':dp.rDepth/dp.LS,\n",
    "              #Rheology - flow law paramters  \n",
    "             'Ads':dp.Ads*sf.Ads,\n",
    "             'Adf':dp.Adf*sf.Adf,\n",
    "             'Apr':dp.Apr*sf.Apr,\n",
    "             'Alm':dp.Alm*sf.Adf,\n",
    "             'Wdf':dp.Vdf*sf.W,\n",
    "             'Edf':dp.Edf*sf.E,\n",
    "             'Wps':dp.Vpr*sf.W,\n",
    "             'Eps':dp.Epr*sf.E,\n",
    "             'Wds':dp.Vds*sf.W,      #{df  => diffusion creep}\n",
    "             'Eds':dp.Eds*sf.E,      #{ds  => dislocation creep}\n",
    "             'Elm':dp.Elm*sf.E,      #{pr  => Peierls creep}\n",
    "             'Elm':dp.Elm*sf.E,\n",
    "             'Wlm':dp.Vlm*sf.W,\n",
    "             'cm':dp.cm*sf.stress,\n",
    "             'cc':dp.cc*sf.stress,    #{dimensionless cohesion in mantl, crust, interface}\n",
    "             'fcmd':dp.fcm*sf.lith_grad, \n",
    "             'fccd':dp.fcc*sf.lith_grad, #{dimensionless friction coefficient in mantle, crust, interface}\n",
    "             'n':dp.n, #Dislocation creep stress exponent\n",
    "             'np':dp.np, #Peierls creep stress exponent \n",
    "             #Rheology - cutoff values\n",
    "             'eta_min':dp.eta_min/dp.eta0, \n",
    "             'eta_max':dp.eta_max/dp.eta0, #viscosity max in the mantle material\n",
    "             'eta_min_crust':dp.eta_min_crust/dp.eta0, #viscosity min in the weak-crust material\n",
    "             'eta_max_crust':dp.eta_max_crust/dp.eta0, #viscosity max in the weak-crust material\n",
    "             'ysMax':dp.ysMax*sf.stress,\n",
    "             #Lengths scales\n",
    "             'MANTLETOCRUST':dp.MANTLETOCRUST/dp.LS, #Crust depth\n",
    "             'HARZBURGDEPTH':dp.HARZBURGDEPTH/dp.LS,\n",
    "             'CRUSTTOMANTLE':dp.CRUSTTOMANTLE/dp.LS,\n",
    "             'LITHTOMANTLE':dp.LITHTOMANTLE/dp.LS,\n",
    "             'MANTLETOLITH':dp.MANTLETOLITH/dp.LS,\n",
    "             'TOPOHEIGHT':dp.TOPOHEIGHT/dp.LS,  #rock-air topography limits\n",
    "             'CRUSTTOECL':dp.CRUSTTOECL/dp.LS,\n",
    "             'LOWMANTLEDEPTH':dp.LOWMANTLEDEPTH/dp.LS, \n",
    "             'CRUSTVISCUTOFF':dp.CRUSTVISCUTOFF/dp.LS, #Deeper than this, crust material rheology reverts to mantle rheology\n",
    "             'AGETRACKDEPTH':dp.AGETRACKDEPTH/dp.LS,\n",
    "             #Slab and plate parameters\n",
    "             'roc':dp.roc/dp.LS,         #radius of curvature of slab\n",
    "             'subzone':dp.subzone/dp.LS, #X position of subduction zone...km\n",
    "             'lRidge':dp.lRidge/dp.LS,   #For depth = 670 km, aspect ratio of 4, this puts the ridges at MINX, MAXX\n",
    "             'rRidge':dp.rRidge/dp.LS,\n",
    "             'maxDepth':dp.maxDepth/dp.LS,\n",
    "             #Misc\n",
    "             'Steta_n':dp.Steta_n/dp.eta0, #stick air viscosity, normal\n",
    "             'Steta_s':dp.Steta_n/dp.eta0, #stick air viscosity, shear \n",
    "             'StALS':dp.StALS/dp.LS,\n",
    "             'plate_vel':sf.vel*dp.plate_vel*(cmpery.to(u.m/u.second)).magnitude,\n",
    "             'low_mantle_visc_fac':dp.low_mantle_visc_fac\n",
    "            })\n",
    "\n",
    "    #Append any more derived paramters\n",
    "    ndp.SR = dp.SR*sf.SR #characteristic strain rate\n",
    "    ndp.StRA = (3300.*dp.g*(dp.LS)**3)/(dp.eta0 *dp.k) #Composisitional Rayleigh number for rock-air buoyancy force\n",
    "    ndp.TaP = 1. - ndp.TPP,  #Dimensionles adiabtic component of deltaT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Metric output stuff\n",
    "figures =  'store' #glucifer Store won't work on all machines, if not, set to 'gldb' \n",
    "\n",
    "#The following are step-based actions\n",
    "swarm_repop, swarm_update = 5, 10\n",
    "checkpoint_every = 100\n",
    "metric_output = 10\n",
    "sticky_air_temp = 1e6\n",
    "\n",
    "\n",
    "#The following are time-based actions\n",
    "filesMy = 0.5e6 #dimensional time intervale to write files\n",
    "files_freq  = filesMy*(3600.*365.*24.)/sf.SR  #applies to files and gldbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model/ mesh  setup parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Model setup parameters\n",
    "###########\n",
    "\n",
    "dim = 2          # number of spatial dimensions\n",
    "\n",
    "\n",
    "#Domain and Mesh paramters\n",
    "Xres = int(md.RES*8)   #more than twice the resolution in X-dim, which will be 'corrected' by the refinement we'll use in Y\n",
    "\n",
    "\n",
    "\n",
    "MINY = 1. - (ndp.depth)\n",
    "if md.stickyAir:\n",
    "    Yres = int(md.RES)\n",
    "    MAXY = 1. + dp.StALS/dp.LS #150km\n",
    "    \n",
    "else:\n",
    "    Yres = int(md.RES)\n",
    "    MAXY = 1.\n",
    "\n",
    "\n",
    "periodic = [False, False]\n",
    "if md.periodicBcs:\n",
    "    periodic = [True, False]\n",
    "    \n",
    "    \n",
    "half_width = np.round(0.5*(ndp.depth)*md.aspectRatio, 1)\n",
    "MINX = -1.*half_width\n",
    "\n",
    "MAXX = half_width\n",
    "MAXY = 1.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mesh = uw.mesh.FeMesh_Cartesian( elementType = (md.elementType),\n",
    "                                 elementRes  = (Xres, Yres), \n",
    "                                 minCoord    = (MINX, MINY), \n",
    "                                 maxCoord    = (MAXX, MAXY), periodic=periodic)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "velocityField       = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=2 )\n",
    "pressureField       = uw.mesh.MeshVariable( mesh=mesh.subMesh, nodeDofCount=1 )\n",
    "temperatureField    = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=1 )\n",
    "temperatureDotField = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=1 )\n",
    "\n",
    "\n",
    "velocityField.data[:]       = [0.,0.]\n",
    "pressureField.data[:]       = 0.\n",
    "temperatureDotField.data[:] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coordinate = fn.input()\n",
    "depthFn = 1. - coordinate[1] #a function providing the depth\n",
    "xFn = coordinate[0]  #a function providing the x-coordinate\n",
    "yFn = coordinate[1]  #a function providing the y-coordinate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mesh.reset()\n",
    "\n",
    "jWalls = mesh.specialSets[\"MinJ_VertexSet\"] + mesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "yFn = coordinate[1]\n",
    "yField = uw.mesh.MeshVariable( mesh=mesh, nodeDofCount=1 )\n",
    "yField.data[:] = 0.\n",
    "yBC = uw.conditions.DirichletCondition( variable=yField, indexSetsPerDof=(jWalls,) )\n",
    "\n",
    "# set bottom wall temperature bc\n",
    "for index in mesh.specialSets[\"MinJ_VertexSet\"]:\n",
    "    yField.data[index] = mesh.minCoord[1]\n",
    "# set top wall temperature bc\n",
    "for index in mesh.specialSets[\"MaxJ_VertexSet\"]:\n",
    "    yField.data[index] = mesh.maxCoord[1]\n",
    "    \n",
    "    \n",
    "    \n",
    "s = 3.5\n",
    "intensityFac = 2.5\n",
    "intensityFn = (((yFn - MINY)/(MAXY-MINY))**s)\n",
    "intensityFn *= intensityFac\n",
    "intensityFn += 1.\n",
    "\n",
    "\n",
    "yLaplaceEquation = uw.systems.SteadyStateHeat(temperatureField=yField, fn_diffusivity=intensityFn, conditions=[yBC,])\n",
    "\n",
    "# get the default heat equation solver\n",
    "yLaplaceSolver = uw.systems.Solver(yLaplaceEquation)\n",
    "# solve\n",
    "yLaplaceSolver.solve()\n",
    "\n",
    "\n",
    "#Get the array of Y positions - copy may be necessary, not sure. \n",
    "newYpos = yField.data.copy() \n",
    "\n",
    "uw.barrier()\n",
    "with mesh.deform_mesh():\n",
    "     mesh.data[:,1] = newYpos[:,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fig= glucifer.Figure(quality=3)\n",
    "\n",
    "#fig.append( glucifer.objects.Surface(mesh,intensityFn, discrete=True))\n",
    "#fig.append( glucifer.objects.Mesh(mesh))\n",
    "#fig.show()\n",
    "#fig.save_database('test.gldb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#THis is a hack for adding a sticky air domain, we refine MAXY and things like the temperature stencil work from Y = 1. \n",
    "\n",
    "if md.stickyAir:\n",
    "    MAXY = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial conditions\n",
    "-------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "potTempFn = ndp.TPP + (depthFn)*ndp.TaP #a function providing the adiabatic temp at any depth\n",
    "abHeatFn = -1.*velocityField[1]*temperatureField*ndp.Di #a function providing the adiabatic heating rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fix the ridge locations of greater than boundaries... \n",
    "\n",
    "if ndp.lRidge < mesh.minCoord[0]:\n",
    "    ndp.lRidge = mesh.minCoord[0] + (10e3/dp.LS)\n",
    " \n",
    "if ndp.rRidge > mesh.maxCoord[0]:\n",
    "    ndp.rRidge = mesh.maxCoord[0] - (10e3/dp.LS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def age_fn(xFn, sz = 0.0, lMOR=MINX, rMOR=MAXX, opFac=1., conjugate_plate = False):\n",
    "    \"\"\"\n",
    "    Simple function to generate a discrete 1-d (i.e x-coordinate) function for the age of the thermal BC. \n",
    "    All paramters are dimensionless\n",
    "    sz: location of subduction zone\n",
    "    lMOR: location of left-hand MOR\n",
    "    rMOR: location of right-hand MOR\n",
    "    opFac: uniform reduce the age of the right hand plate by this factor\n",
    "    conjugate_plate: if True, build plates on the outer sides of the MORs, if False, age = 0. \n",
    "    \"\"\"\n",
    "    \n",
    "    if lMOR < MINX:\n",
    "        lMOR = MINX\n",
    "    if rMOR > MAXX:\n",
    "        rMOR = MAXX\n",
    "\n",
    "    if conjugate_plate:\n",
    "        ageFn = fn.branching.conditional([(operator.and_(xFn > lMOR, xFn < sz) , (xFn + abs(lMOR))/(abs(sz-lMOR))), \n",
    "                                      (operator.and_(xFn < rMOR, xFn >= sz), (1.-(xFn + abs(sz))/abs(rMOR-sz))*opFac),\n",
    "                                      (xFn > rMOR, opFac*(xFn -abs(rMOR)) / abs(rMOR-sz) ),\n",
    "                                      (True, fn.math.abs((((xFn + abs(lMOR)) / (abs(sz-lMOR))))))\n",
    "                                         ])\n",
    "    else:    \n",
    "        \n",
    "        ageFn = fn.branching.conditional([(operator.and_(xFn > lMOR, xFn < sz) , (xFn + abs(lMOR))/(abs(sz-lMOR))), \n",
    "                                      (operator.and_(xFn < rMOR, xFn >= sz), (1.-(xFn + abs(sz))/abs(rMOR-sz))*opFac),\n",
    "\n",
    "                                      (True, 0.0)])\n",
    "    return ageFn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Thermal initial condition 2: \n",
    "#if symmetricIC == False, we build an asymmetric subduction-zone\n",
    "###########\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  a few conversions\n",
    "ageAtTrenchSeconds = min(dp.platemaxAge*(3600*24*365), dp.slabmaxAge*(3600*24*365))\n",
    "Org = (ndp.subzone, MAXY-ndp.roc)\n",
    "\n",
    "\n",
    "#This builds the age function\n",
    "ageFn = age_fn(xFn, sz =ndp.subzone, lMOR=ndp.lRidge,rMOR=ndp.rRidge, conjugate_plate=True, opFac = dp.opmaxAge/dp.slabmaxAge)\n",
    "\n",
    "\n",
    "#dimensionlize the age function\n",
    "ageFn *= ageAtTrenchSeconds\n",
    "\n",
    "w0 = (2.*math.sqrt(dp.k*ageAtTrenchSeconds))/dp.LS #diffusion depth of plate at the trench\n",
    "\n",
    "tempBL = (potTempFn) *fn.math.erf((depthFn*dp.LS)/(2.*fn.math.sqrt(dp.k*ageFn))) + ndp.TSP #boundary layer function\n",
    "\n",
    "tempTBL =  fn.branching.conditional([(depthFn < w0, tempBL),\n",
    "                          (True, potTempFn)])\n",
    "\n",
    "if not md.symmetricIcs:\n",
    "    if not checkpointLoad:\n",
    "        out = uw.utils.MeshVariable_Projection( temperatureField, tempTBL) #apply function with projection\n",
    "        out.solve()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now build the perturbation part\n",
    "def inCircleFnGenerator(centre, radius):\n",
    "    coord = fn.input()\n",
    "    offsetFn = coord - centre\n",
    "    return fn.math.dot( offsetFn, offsetFn ) < radius**2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#We use three circles to define our slab and crust perturbation,  \n",
    "Oc = inCircleFnGenerator(Org , ndp.roc)\n",
    "Oc2 = inCircleFnGenerator(Org , ndp.roc + (0.5*ndp.MANTLETOCRUST)) #increases the amount of crust in the interface\n",
    "Ic = inCircleFnGenerator(Org , ndp.roc - w0)\n",
    "Cc = inCircleFnGenerator(Org , ndp.roc - (1.*ndp.MANTLETOCRUST)) #... weak zone on 'inside' of slab\n",
    "Hc = inCircleFnGenerator(Org , ndp.roc - ndp.HARZBURGDEPTH) #... Harzburgite layer \n",
    "dx = (ndp.roc)*(np.math.tan((np.math.pi/180.)*dp.theta))\n",
    "\n",
    "\n",
    "#We'll also create a triangle which will truncate the circles defining the slab...\n",
    "if dp.sense == 'Left':\n",
    "    ptx = ndp.subzone - dx\n",
    "else:\n",
    "    ptx = ndp.subzone + dx\n",
    "coords = ((0.+ ndp.subzone, MAXY), (0.+ ndp.subzone, MAXY-ndp.roc), (ptx, MAXY))\n",
    "Tri = fn.shape.Polygon(np.array(coords))\n",
    "\n",
    "#Actually apply the perturbation\n",
    "if not md.symmetricIcs:\n",
    "    if not checkpointLoad:\n",
    "        sdFn = ((ndp.roc - fn.math.sqrt((coordinate[0] - Org[0])**2. + (coordinate[1] - Org[1])**2.)))\n",
    "        slabFn = ndp.TPP*fn.math.erf((sdFn*dp.LS)/(2.*math.sqrt(dp.k*ageAtTrenchSeconds))) + ndp.TSP\n",
    "        for index, coord in enumerate(mesh.data):\n",
    "            if (\n",
    "                Oc.evaluate(tuple(coord)) and\n",
    "                Tri.evaluate(tuple(coord)) and not\n",
    "                Ic.evaluate(tuple(coord)) and\n",
    "                coord[1] > (1. - ndp.maxDepth)\n",
    "                ): #In the quarter-circle defining the lithosphere\n",
    "                temperatureField.data[index] = slabFn.evaluate(mesh)[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Make sure material in sticky air region is at the surface temperature.\n",
    "for index, coord in enumerate(mesh.data):\n",
    "            if coord[1] >= MAXY:\n",
    "                temperatureField.data[index] = ndp.TSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#temperatureField.data.max(), temperatureField.data.mean(), temperatureField.data.std(), temperatureField.data.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig= glucifer.Figure(quality=3)\n",
    "\n",
    "fig.append( glucifer.objects.Surface(mesh,temperatureField, discrete=True))\n",
    "#fig.append( glucifer.objects.Mesh(mesh))\n",
    "\n",
    "\n",
    "#fig.show()\n",
    "#fig.save_database('test.gldb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ageFn = age_fn(xFn, sz =ndp.subzone, lMOR=ndp.lRidge,rMOR=ndp.rRidge, conjugate_plate=True, opFac = dp.opmaxAge/dp.slabmaxAge)\n",
    "#ageFn.evaluate(mesh).min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boundary conditions\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "iWalls = mesh.specialSets[\"MinI_VertexSet\"] + mesh.specialSets[\"MaxI_VertexSet\"]\n",
    "jWalls = mesh.specialSets[\"MinJ_VertexSet\"] + mesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "tWalls = mesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "bWalls =mesh.specialSets[\"MinJ_VertexSet\"]\n",
    "\n",
    "\n",
    "for index in mesh.specialSets[\"MinJ_VertexSet\"]:\n",
    "    temperatureField.data[index] = potTempFn.evaluate(bWalls).min() #Adiabatic temp at bottom of mesh/domain\n",
    "for index in mesh.specialSets[\"MaxJ_VertexSet\"]:\n",
    "    temperatureField.data[index] = ndp.TSP\n",
    "\n",
    "VelBCs = mesh.specialSets[\"Empty\"]\n",
    "\n",
    "\n",
    "\n",
    "if md.velBcs:\n",
    "    for index in list(tWalls.data):\n",
    "\n",
    "        if (mesh.data[int(index)][0] < (ndp.subzone - 0.05*md.aspectRatio) and \n",
    "            mesh.data[int(index)][0] > (mesh.minCoord[0] + 0.05*md.aspectRatio)): #Only push with a portion of teh overiding plate\n",
    "            #print \"first\"\n",
    "            VelBCs.add(int(index))\n",
    "            #Set the plate velocities for the kinematic phase\n",
    "            velocityField.data[index] = [ndp.plate_vel, 0.]\n",
    "        \n",
    "        elif (mesh.data[int(index)][0] > (ndp.subzone + 0.05*md.aspectRatio) and \n",
    "            mesh.data[int(index)][0] < (mesh.maxCoord[0] - 0.05*md.aspectRatio)):\n",
    "            #print \"second\"\n",
    "            VelBCs.add(int(index))\n",
    "            #Set the plate velocities for the kinematic phase\n",
    "            velocityField.data[index] = [0., 0.]\n",
    "        \n",
    "\n",
    "#If periodic, we'll fix a the x-vel at a single node - at the bottom left (index 0)\n",
    "Fixed = mesh.specialSets[\"Empty\"]\n",
    "Fixed.add(int(0))        \n",
    "        \n",
    "\n",
    "if periodic[0] == False:\n",
    "    if md.velBcs:\n",
    "        print(1)\n",
    "        freeslipBC = uw.conditions.DirichletCondition( variable      = velocityField, \n",
    "                                               indexSetsPerDof = ( iWalls + VelBCs, jWalls) )\n",
    "    else:\n",
    "        print(2)\n",
    "        freeslipBC = uw.conditions.DirichletCondition( variable      = velocityField, \n",
    "                                               indexSetsPerDof = ( iWalls, jWalls) )\n",
    "\n",
    "\n",
    "\n",
    "if periodic[0] == True:\n",
    "    if md.velBcs:\n",
    "        print(3)\n",
    "        freeslipBC = uw.conditions.DirichletCondition( variable      = velocityField, \n",
    "                                               indexSetsPerDof = ( Fixed + VelBCs , jWalls) )\n",
    "    else:\n",
    "        print(4)\n",
    "        freeslipBC = uw.conditions.DirichletCondition( variable      = velocityField, \n",
    "                                               indexSetsPerDof = ( Fixed, jWalls) )\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "# also set dirichlet for temp field\n",
    "dirichTempBC = uw.conditions.DirichletCondition(     variable=temperatureField, \n",
    "                                              indexSetsPerDof=(tWalls,) )\n",
    "dT_dy = [0.,0.]\n",
    "\n",
    "# also set dirichlet for temp field\n",
    "neumannTempBC = uw.conditions.NeumannCondition( dT_dy, variable=temperatureField, \n",
    "                                         nodeIndexSet=bWalls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check VelBCs are where we want them\n",
    "#test = np.zeros(len(tWalls.data))\n",
    "#VelBCs\n",
    "#tWalls.data\n",
    "#tWalls.data[VelBCs.data]\n",
    "#test[np.in1d(tWalls.data, VelBCs.data)] = 1.\n",
    "#test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Swarm setup\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Material Swarm and variables\n",
    "###########\n",
    "\n",
    "#create material swarm\n",
    "gSwarm = uw.swarm.Swarm(mesh=mesh, particleEscape=True)\n",
    "vSwarm = uw.swarm.Swarm(mesh=mesh, particleEscape=True)\n",
    "\n",
    "\n",
    "#create swarm variables\n",
    "yieldingCheck = gSwarm.add_variable( dataType=\"int\", count=1 )\n",
    "#tracerVariable = gSwarm.add_variable( dataType=\"int\", count=1)\n",
    "materialVariable = gSwarm.add_variable( dataType=\"int\", count=1 )\n",
    "ageVariable = gSwarm.add_variable( dataType=\"double\", count=1 )\n",
    "#testVariable = gSwarm.add_variable( dataType=\"float\", count=1 )\n",
    "\n",
    "\n",
    "#these lists  are part of the checkpointing implementation\n",
    "varlist = [materialVariable, yieldingCheck, ageVariable]\n",
    "varnames = ['materialVariable', 'yieldingCheck', 'ageVariable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mantleIndex = 0\n",
    "crustIndex = 1\n",
    "harzIndex = 2\n",
    "airIndex = 3\n",
    "\n",
    "\n",
    "\n",
    "if checkpointLoad:\n",
    "    checkpointLoadDir = natsort.natsort(checkdirs)[-1]\n",
    "    temperatureField.load(os.path.join(checkpointLoadDir, \"temperatureField\" + \".hdf5\"))\n",
    "    pressureField.load(os.path.join(checkpointLoadDir, \"pressureField\" + \".hdf5\"))\n",
    "    velocityField.load(os.path.join(checkpointLoadDir, \"velocityField\" + \".hdf5\"))\n",
    "    gSwarm.load(os.path.join(checkpointLoadDir, \"swarm\" + \".h5\"))\n",
    "    for ix in range(len(varlist)):\n",
    "        varb = varlist[ix]\n",
    "        varb.load(os.path.join(checkpointLoadDir,varnames[ix] + \".h5\"))\n",
    "\n",
    "else:\n",
    "\n",
    "    # Layouts are used to populate the swarm across the whole domain\n",
    "    layout = uw.swarm.layouts.PerCellRandomLayout(swarm=gSwarm, particlesPerCell=int(md.ppc))\n",
    "    gSwarm.populate_using_layout( layout=layout ) # Now use it to populate.\n",
    "\n",
    "\n",
    "    # Swarm variables\n",
    "    materialVariable.data[:] = mantleIndex\n",
    "    #tracerVariable.data[:] = 1\n",
    "    yieldingCheck.data[:] = 0\n",
    "    ageVariable.data[:] = -1\n",
    "\n",
    "    #Set initial air and crust materials (allow the graph to take care of lithsophere)\n",
    "    #########\n",
    "    #This initial material setup will be model dependent\n",
    "    #########\n",
    "    for particleID in range(gSwarm.particleCoordinates.data.shape[0]):\n",
    "        if (1. - gSwarm.particleCoordinates.data[particleID][1]) < ndp.MANTLETOCRUST:\n",
    "                 materialVariable.data[particleID] = crustIndex\n",
    "                \n",
    "                \n",
    "                \n",
    "#also create a swarm for viewing. This one doesn't need to be checkpointed               \n",
    "layout1 = uw.swarm.layouts.PerCellRandomLayout(swarm=vSwarm, particlesPerCell=int(md.ppc/8))\n",
    "vSwarm.populate_using_layout( layout=layout1 ) # Now use it to populate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#Set the initial particle age for particles above the critical depth; \n",
    "#only material older than crustageCond will be transformed to crust / harzburgite\n",
    "##############\n",
    "\n",
    "ageVariable.data[:] = 0. #start with all zero\n",
    "ageVariable.data[:] = ageFn.evaluate(gSwarm)/sf.SR\n",
    "crustageCond = 2e6*(3600.*365.*24.)/sf.SR #set inital age above critical depth. (x...Ma)\n",
    "\n",
    "\n",
    "\n",
    "ageConditions = [ (depthFn < ndp.AGETRACKDEPTH, ageVariable),  #In the main loop we add ageVariable + dt here\n",
    "                  (True, 0.) ]\n",
    "                 \n",
    "#apply conditional \n",
    "ageVariable.data[:] = fn.branching.conditional( ageConditions ).evaluate(gSwarm)\n",
    "\n",
    "ageDT = 0.#this is used in the main loop for short term time increments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fig= glucifer.Figure()\n",
    "#fig.append( glucifer.objects.Points(gSwarm,ageVariable))\n",
    "#fig.append( glucifer.objects.Points(gSwarm, viscosityMapFn, logScale=True, valueRange =[1e-3,1e5]))\n",
    "\n",
    "#fig.append( glucifer.objects.Surface(mesh, strainRate_2ndInvariant, logScale=True, valueRange =[1e-3,1e5] ))\n",
    "#fig.append( glucifer.objects.VectorArrows(mesh,velocityField, scaling=0.002))\n",
    "#fig.append( glucifer.objects.Surface(mesh,densityMapFn))\n",
    "#fig.append( glucifer.objects.Surface(mesh,raylieghFn))\n",
    "\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#Here we set up a directed graph object that we we use to control the transformation from one material type to another\n",
    "##############\n",
    "\n",
    "#All depth conditions are given as (km/D) where D is the length scale,\n",
    "#note that 'model depths' are used, e.g. 1-z, where z is the vertical Underworld coordinate\n",
    "#All temp conditions are in dimensionless temp. [0. - 1.]\n",
    "\n",
    "#Need a list of all material indexes (safer in parallel)\n",
    "material_list = [0,1,2,3]\n",
    "\n",
    "if not checkpointLoad:\n",
    "    materialVariable.data[:] = 0 #Initialize to zero \n",
    "\n",
    "#Setup the graph object\n",
    "DG = material_graph.MatGraph()\n",
    "\n",
    "#Important: First thing to do is to add all the material types to the graph (i.e add nodes)\n",
    "DG.add_nodes_from(material_list)\n",
    "\n",
    "#Now set the conditions for transformations\n",
    "\n",
    "hs = 2e3/dp.LS  #add some hysteresis to the depths of transition\n",
    "\n",
    "#... to mantle\n",
    "DG.add_transition((crustIndex,mantleIndex), depthFn, operator.gt, ndp.CRUSTTOMANTLE + hs)\n",
    "DG.add_transition((harzIndex,mantleIndex), depthFn, operator.gt, ndp.CRUSTTOMANTLE + hs)\n",
    "DG.add_transition((airIndex,mantleIndex), depthFn, operator.gt, ndp.TOPOHEIGHT + hs)\n",
    "\n",
    "#... to crust\n",
    "DG.add_transition((mantleIndex,crustIndex), depthFn, operator.lt, ndp.MANTLETOCRUST)\n",
    "DG.add_transition((mantleIndex,crustIndex), xFn, operator.lt, ndp.subzone) #No crust on the upper plate\n",
    "DG.add_transition((mantleIndex,crustIndex), ageVariable, operator.gt, crustageCond)\n",
    "\n",
    "\n",
    "DG.add_transition((harzIndex,crustIndex), depthFn, operator.lt, ndp.MANTLETOCRUST)\n",
    "DG.add_transition((harzIndex,crustIndex), xFn, operator.lt, ndp.subzone) #This one sets no crust on the upper plate\n",
    "DG.add_transition((harzIndex,crustIndex), ageVariable, operator.gt, crustageCond)\n",
    "\n",
    "#... to Harzbugite\n",
    "DG.add_transition((mantleIndex,harzIndex), depthFn, operator.lt, ndp.HARZBURGDEPTH)\n",
    "DG.add_transition((mantleIndex,harzIndex), depthFn, operator.gt, ndp.MANTLETOCRUST)\n",
    "DG.add_transition((mantleIndex,harzIndex), ageVariable, operator.gt, crustageCond) #Note we can mix functions and swarm variabls\n",
    "\n",
    "#... to air\n",
    "DG.add_transition((mantleIndex,airIndex), depthFn, operator.lt,0. - ndp.TOPOHEIGHT)\n",
    "DG.add_transition((crustIndex,airIndex), depthFn, operator.lt, 0. - ndp.TOPOHEIGHT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#For the slab_IC, we'll also add a crustal weak zone following the dipping perturbation\n",
    "##############\n",
    "\n",
    "if checkpointLoad != True:\n",
    "    if not md.symmetricIcs:\n",
    "        for particleID in range(gSwarm.particleCoordinates.data.shape[0]):\n",
    "            if (\n",
    "                Oc2.evaluate(list(gSwarm.particleCoordinates.data[particleID])) and\n",
    "                Tri.evaluate(list(gSwarm.particleCoordinates.data[particleID])) and\n",
    "                gSwarm.particleCoordinates.data[particleID][1] > (1. - ndp.maxDepth) and\n",
    "                Cc.evaluate(list(gSwarm.particleCoordinates.data[particleID])) == False\n",
    "                \n",
    "                ):\n",
    "                materialVariable.data[particleID] = crustIndex\n",
    "                \n",
    "            elif (\n",
    "                Oc.evaluate(list(gSwarm.particleCoordinates.data[particleID])) and\n",
    "                Tri.evaluate(list(gSwarm.particleCoordinates.data[particleID])) and\n",
    "                gSwarm.particleCoordinates.data[particleID][1] > (1. - ndp.maxDepth) and\n",
    "                Hc.evaluate(list(gSwarm.particleCoordinates.data[particleID])) == False\n",
    "                \n",
    "                ):\n",
    "                materialVariable.data[particleID] = harzIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#This is how we use the material graph object to test / apply material transformations\n",
    "##############\n",
    "\n",
    "if not checkpointLoad:\n",
    "    DG.build_condition_list(materialVariable)\n",
    "\n",
    "    for i in range(1): \n",
    "        materialVariable.data[:] = fn.branching.conditional(DG.condition_list).evaluate(gSwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fig= glucifer.Figure()\n",
    "#fig.append( glucifer.objects.Points(vSwarm,temperatureField))\n",
    "#fig.append( glucifer.objects.Surface(mesh, corrTempFn))\n",
    "#fig.show()\n",
    "#fig.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## phase and compositional buoyancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#Set up phase buoyancy contributions\n",
    "#the phase function approach of Yuen and Christenson is implemented in the Slippy2 phase_function class \n",
    "##############\n",
    "\n",
    "\n",
    "#olivine\n",
    "olivinePhase = phase_function.component_phases(name = 'ol', \n",
    "                        depths=[410e3,660e3], #depths of phase transitions along adiabat\n",
    "                        temps = [1600., 1900.], #temperatures of phase transitions along adiabat\n",
    "                        widths = [20e3, 20e3], #width if transition\n",
    "                        claps=[2.e6, -2.5e6],  #Clapeyron slope of trnasition\n",
    "                        densities = [180., 400.]) #density change of phase transition\n",
    "\n",
    "olivinePhase.build_nd_dict(dp.LS, dp.rho, dp.g, dp.deltaTa)\n",
    "\n",
    "\n",
    "rp = olivinePhase.nd_reduced_pressure(depthFn, \n",
    "                                   temperatureField,\n",
    "                                   olivinePhase.ndp['depths'][0],\n",
    "                                   olivinePhase.ndp['claps'][0],\n",
    "                                   olivinePhase.ndp['temps'][0])\n",
    "\n",
    "#ph_410 = olivinePhase.nd_phase(rp, test.ndp['widths'][0])\n",
    "#pf_sum = test.phase_function_sum(temperatureField, depthFn)\n",
    "\n",
    "olivine_phase_buoyancy = olivinePhase.buoyancy_sum(temperatureField, depthFn, dp.g, dp.LS, dp.k, dp.eta0)\n",
    "\n",
    "#garnet\n",
    "garnetPhase = phase_function.component_phases(name = 'grt', \n",
    "                        depths=[60e3,400e3, 720e3],\n",
    "                        temps = [1000., 1600., 1900.], \n",
    "                        widths = [20e3, 20e3, 20e3], \n",
    "                        claps=[0.e6, 1.e6, 1.e6], \n",
    "                        densities = [350., 150., 400.])\n",
    "\n",
    "garnetPhase.build_nd_dict(dp.LS, dp.rho, dp.g, dp.deltaTa)\n",
    "\n",
    "\n",
    "rp = garnetPhase.nd_reduced_pressure(depthFn, \n",
    "                                   temperatureField,\n",
    "                                   garnetPhase.ndp['depths'][0],\n",
    "                                   garnetPhase.ndp['claps'][0],\n",
    "                                   garnetPhase.ndp['temps'][0])\n",
    "\n",
    "#ph_410 = olivinePhase.nd_phase(rp, test.ndp['widths'][0])\n",
    "#pf_sum = test.phase_function_sum(temperatureField, depthFn)\n",
    "\n",
    "garnet_phase_buoyancy = garnetPhase.buoyancy_sum(temperatureField, depthFn, dp.g, dp.LS, dp.k, dp.eta0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fig= glucifer.Figure(quality=3)\n",
    "\n",
    "#fig.append( glucifer.objects.Points(gSwarm,olivine_phase_buoyancy/ndp.RA , discrete=True, fn_mask=lithRestFn))\n",
    "#fig.append( glucifer.objects.Surface(mesh,olivine_phase_buoyancy/ndp.RA , discrete=True))\n",
    "#fig.append( glucifer.objects.Points(gSwarm,temperatureField , discrete=True, fn_mask=lithRestFn))\n",
    "\n",
    "#fig.append( glucifer.objects.Mesh(mesh))\n",
    "#fig.show()\n",
    "#fig.save_database('test.gldb')\n",
    "#fig.save_image('active.png')\n",
    "#fig.save_image('active_phase.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#Set up compositional buoyancy contributions\n",
    "##############\n",
    "\n",
    "buoyancy_factor = (dp.g*dp.LS**3)/(dp.eta0*dp.k)\n",
    "\n",
    "basalt_comp_buoyancy  = (dp.rho - 2940.)*buoyancy_factor\n",
    "harz_comp_buoyancy = (dp.rho - 3235.)*buoyancy_factor\n",
    "pyrolite_comp_buoyancy = (dp.rho - 3300.)*buoyancy_factor\n",
    "\n",
    "#print(basalt_comp_buoyancy, harz_comp_buoyancy, pyrolite_comp_buoyancy)\n",
    "\n",
    "\n",
    "#this function accounts for the decrease in expansivity, and acts to reduce the rayleigh number with depth\n",
    "alphaRatio = 1.2/3\n",
    "taFn = 1. - (depthFn)*(1. - alphaRatio) \n",
    "\n",
    "\n",
    "if not md.compBuoyancy:\n",
    "    pyrolitebuoyancyFn =  (ndp.RA*temperatureField*taFn)\n",
    "    harzbuoyancyFn =      (ndp.RA*temperatureField*taFn) \n",
    "    basaltbuoyancyFn =    (ndp.RA*temperatureField*taFn)\n",
    "\n",
    "else : \n",
    "    pyrolitebuoyancyFn =  (ndp.RA*temperatureField*taFn) -\\\n",
    "                          (0.6*olivine_phase_buoyancy + 0.4*garnet_phase_buoyancy) +\\\n",
    "                           pyrolite_comp_buoyancy\n",
    "    harzbuoyancyFn =      (ndp.RA*temperatureField*taFn) -\\\n",
    "                          (0.8*olivine_phase_buoyancy + 0.2*garnet_phase_buoyancy) +\\\n",
    "                           harz_comp_buoyancy\n",
    "    basaltbuoyancyFn =    (ndp.RA*temperatureField*taFn) -\\\n",
    "                          (1.*garnet_phase_buoyancy) +\\\n",
    "                           basalt_comp_buoyancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Faults / interfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/2dthermalslabs/eba/unsupported_dan/interfaces/__init__.py:9: UserWarning: \n",
      "\n",
      "The interface module is not supported.\n",
      "Questions should be addressed to louis.moresi@unimelb.edu.au \n",
      " \n",
      "  Questions should be addressed to louis.moresi@unimelb.edu.au \\n \"\"\"\n",
      "/workspace/2dthermalslabs/eba/unsupported_dan/faults/__init__.py:9: UserWarning: \n",
      "\n",
      "The fault module is not supported.\n",
      "Questions should be addressed to louis.moresi@unimelb.edu.au \n",
      " \n",
      "  Questions should be addressed to louis.moresi@unimelb.edu.au \\n \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from unsupported_dan.interfaces.marker2D import markerLine2D\n",
    "from unsupported_dan.faults.faults2D import fault2D, fault_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def copy_markerLine2D(ml, thickness=False, ID=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    if not thickness:\n",
    "        thickness = ml.thickness\n",
    "    if not ID:\n",
    "        ID = -1*ml.ID\n",
    "    new_line = markerLine2D(mesh, velocityField, [], [], thickness,  ID)\n",
    "    if ml.swarm.particleCoordinates.data.shape[0] > 0:\n",
    "        new_line.swarm.add_particles_with_coordinates(ml.swarm.particleCoordinates.data.copy())\n",
    "        \n",
    "    new_line.rebuild()\n",
    "    return new_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Initial Coordinates for inerfaces and faults\n",
    "###########\n",
    "\n",
    "#subduction fault\n",
    "introPoint = ndp.subzone - abs(ndp.subzone - ndp.lRidge)/2. #half way between ridge and Sz\n",
    "faultthickness = ndp.MANTLETOCRUST/2. #initiale fault at half-depth of crust\n",
    "nfault = 200\n",
    "faultCoords =np.zeros((nfault, 2))\n",
    "\n",
    "reducedRocM = ndp.roc  - faultthickness\n",
    "xlimslab = reducedRocM*math.cos(math.pi*(90. - dp.theta)/180)\n",
    "faultCoords[:, 0] = np.linspace(introPoint, ndp.subzone + xlimslab, nfault) #note SZ location is hardcoded here \n",
    "for index, xval in np.ndenumerate(faultCoords[:,0]):\n",
    "    #print index, xval\n",
    "    #swarmCoords[index[0], 1] = 1. - isodepthFn.evaluate((xval, 0.)) #This bit for the plate \n",
    "    if  xval < ndp.subzone:\n",
    "        faultCoords[index[0], 1] = MAXY - faultthickness #This bit for the plate \n",
    "        \n",
    "    else:\n",
    "        faultCoords[index[0], 1] = (MAXY - (faultthickness) - (reducedRocM - ( math.sqrt((reducedRocM**2 - (xval-ndp.subzone)**2)))))\n",
    "        \n",
    "    \n",
    "faultCoords = faultCoords[faultCoords[:,1] > (MAXY - ndp.maxDepth)] #kill any deeper than cutoff\n",
    "\n",
    "\n",
    "#surface tracer interface:\n",
    "surfaceCoords =np.ones((nfault, 2))*1.\n",
    "surfaceCoords[:,0] = np.linspace(MINX, MAXX, nfault)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initiaze the swarms in a \n",
    "fault  = fault2D(mesh, velocityField, [], [], faultthickness, 0., 0., crustIndex)\n",
    "surface  = fault2D(mesh, velocityField, [], [], ndp.StALS, 0., 0., airIndex)\n",
    "#slab_seg  = marker2D.markerLine2D(mesh, velocityField, [], [], 1e9/dp.LS, crustIndex)   #Note very large fault thickness \n",
    "\n",
    "fault_coll = fault_collection([fault])\n",
    "\n",
    "#Initiaze the swarms in a \n",
    "#fault_seg  = marker2D.markerLine2D(mesh, velocityField, [], [], faultthickness, 0.0, 0.0, crustIndex)\n",
    "#surface_seg  = marker2D.markerLine2D(mesh, velocityField, [], [], ndp.StALS, 0.0, 0.0, airIndex)\n",
    "#slab_seg  = marker2D.markerLine2D(mesh, velocityField, [], [], 1e9/dp.LS, 0.0, 0.0, crustIndex)   #Note very large fault thickness\n",
    "\n",
    "#These lists are used to checkpoint the marker lines, similar to the swarm variables.        \n",
    "interfaces = []\n",
    "interfaces.append(fault)\n",
    "interfaces.append(surface)\n",
    "interfacenames = ['fault_seg', 'surface_seg']\n",
    "\n",
    "\n",
    "#If restarting, load the swarms from file Interfaces are just swarms, so should be fine to rely on parallel h5 machinery here\n",
    "if checkpointLoad:\n",
    "    for ix in range(len(interfaces)):\n",
    "        tempname = interfacenames[ix]\n",
    "        interfaces[ix].swarm.load(os.path.join(checkpointLoadDir,  tempname + \".h5\"))\n",
    "\n",
    "#otherwise add the point from at the initial locations\n",
    "else:\n",
    "    fault.add_points(faultCoords[:, 0], faultCoords[:, 1])\n",
    "    surface.add_points(surfaceCoords[:, 0], surfaceCoords[:, 1])\n",
    "    #slab_seg.add_points(slabCoords[:, 0], slabCoords[:, 1]) \n",
    "    \n",
    "\n",
    "#rebuild the fault, necessary to swicth off empty flag., if starting fom checkpoint\n",
    "    \n",
    "fault.rebuild()\n",
    "surface.rebuild()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add variables to the surface swarm\n",
    "surfaceVelx = surface.swarm.add_variable( dataType=\"float\", count=1 )\n",
    "surfaceVelx.data[...] = velocityField[0].evaluate(surface.swarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add the necessary swarm variables\n",
    "#note that these swarm vars. don't get checkpointed, they should rebuild from model state\n",
    "\n",
    "proximityVariable      = gSwarm.add_variable( dataType=\"int\", count=1 )\n",
    "signedDistanceVariable = gSwarm.add_variable( dataType=\"float\", count=1 )\n",
    "directorVector   = gSwarm.add_variable( dataType=\"double\", count=2)\n",
    "\n",
    "directorVector.data[:,:] = 0.0\n",
    "proximityVariable.data[:] = 0\n",
    "signedDistanceVariable.data[:] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#inform the mesh of the fault\n",
    "\n",
    "sd, pts0 = fault.compute_signed_distance(gSwarm.particleCoordinates.data, distance=w0)\n",
    "sp, pts0 = fault.compute_marker_proximity(gSwarm.particleCoordinates.data)\n",
    "\n",
    "proximityVariable.data[np.logical_and(sd<0,sp == fault.ID)] = sp[np.logical_and(sd<0,sp == fault.ID)]\n",
    "\n",
    "dv, nzv = fault.compute_normals(gSwarm.particleCoordinates.data)\n",
    "directorVector.data[nzv] = dv[nzv]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "edotn_SFn, edots_SFn = fault_coll.global_fault_strainrate_fns(velocityField, directorVector, proximityVariable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rheology\n",
    "-----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#Set up any functions required by the rheology\n",
    "##############\n",
    "\n",
    "sym_strainRate = fn.tensor.symmetric( \n",
    "                            velocityField.fn_gradient )\n",
    "\n",
    "strainRate_2ndInvariant = fn.tensor.second_invariant( \n",
    "                            sym_strainRate)/md.secInvFac # secInvFac sometimes required if differnet definition of eii is used.\n",
    "\n",
    "def safe_visc(func, viscmin=ndp.eta_min, viscmax=ndp.eta_max):\n",
    "    return fn.misc.max(viscmin, fn.misc.min(viscmax, func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#strainRate_2ndInvariant = fn.misc.constant(ndp.SR) #dummy fucntion to check which mechanisms are at active are reference strain rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#Get dimensional viscosity values at reference values of temp, pressure, and strain rate\n",
    "##############\n",
    "dp.rPressure  = dp.rho*dp.g*dp.rDepth\n",
    "rDf = (1./dp.Adf)*np.exp( ((dp.Edf + dp.Vdf*dp.rPressure))/((dp.R*dp.rTemp)))\n",
    "rLm = (1./dp.Alm)*np.exp( ((dp.Elm + dp.Vlm*dp.rPressure))/((dp.R*dp.rTemp)))\n",
    "\n",
    "rDs = (1./dp.Ads**(1./ndp.n))*(dp.SR**((1.-ndp.n)/ndp.n))*np.exp( ((dp.Eds + dp.Vds*dp.rPressure))/((ndp.n*dp.R*dp.rTemp)))\n",
    "rPr = (1./dp.Apr**(1./ndp.np))*(dp.SR**((1.-ndp.np)/ndp.np))*np.exp( ((dp.Epr + dp.Vpr*dp.rPressure))/((ndp.np*dp.R*dp.rTemp)))\n",
    "\n",
    "dsfac = rDs/dp.eta0\n",
    "dffac = rDf/dp.eta0\n",
    "prfac = rPr/dp.eta0\n",
    "lmfac = rLm/dp.eta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#These guys are legacy - to be fixed\n",
    "\n",
    "corrDepthFn = depthFn\n",
    "correctrDepth = ndp.rDepth\n",
    "corrTempFn = temperatureField\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "############\n",
    "#Rheology: create UW2 functions for all viscous mechanisms\n",
    "#############\n",
    "\n",
    "omega = fn.misc.constant(1.) #this function can hold any arbitary viscosity modifications \n",
    "\n",
    "\n",
    "##Diffusion Creep\n",
    "diffusion = dffac*fn.math.exp( ((ndp.Edf + (corrDepthFn*ndp.Wdf))/((corrTempFn+ ndp.TS))) - \n",
    "              ((ndp.Edf + (correctrDepth*ndp.Wdf))/((ndp.rTemp + ndp.TS)))  ) \n",
    "\n",
    "\n",
    "##Diffusion Creep\n",
    "lmdiffusion = lmfac*fn.math.exp( ((ndp.Elm + (corrDepthFn*ndp.Wlm))/((corrTempFn+ ndp.TS))) - \n",
    "              ((ndp.Elm + (correctrDepth*ndp.Wlm))/((ndp.rTemp + ndp.TS)))  ) \n",
    "\n",
    "\n",
    "linearVisc = safe_visc(diffusion)\n",
    "\n",
    "##Dislocation Creep\n",
    "nl_correction = (strainRate_2ndInvariant/ndp.SR)**((1.-ndp.n)/(ndp.n))\n",
    "dislocation = dsfac*(nl_correction)*fn.math.exp( ((ndp.Eds + (corrDepthFn*ndp.Wds))/(ndp.n*(corrTempFn + ndp.TS))) -\n",
    "                                     ((ndp.Eds + (correctrDepth*ndp.Wds))/(ndp.n*(ndp.rTemp + ndp.TS))))\n",
    "\n",
    "\n",
    "\n",
    "##Peirls Creep\n",
    "nl_correction = (strainRate_2ndInvariant/ndp.SR)**((1.-ndp.np)/(ndp.np))\n",
    "\n",
    "peierls = prfac*(nl_correction)*fn.math.exp( ((ndp.Eps + (corrDepthFn*ndp.Wps))/(ndp.np*(corrTempFn+ ndp.TS))) -\n",
    "                                     ((ndp.Eps + (correctrDepth*ndp.Wps))/(ndp.np*(ndp.rTemp + ndp.TS))))\n",
    "\n",
    "\n",
    "##Define the mantle Plasticity\n",
    "ys =  ndp.cm + (depthFn*ndp.fcmd)\n",
    "ysf = fn.misc.min(ys, ndp.ysMax)\n",
    "yielding = ysf/(2.*(strainRate_2ndInvariant)) \n",
    "\n",
    "##Crust rheology\n",
    "crustys =  ndp.cc + (depthFn*ndp.fccd)\n",
    "crustysf = fn.misc.min(crustys, ndp.ysMax)\n",
    "crustyielding = crustysf/(2.*(strainRate_2ndInvariant)) \n",
    "\n",
    "\n",
    "##Interface rheology\n",
    "interfaceys =  ndp.ci + (depthFn*ndp.fcid) #only weakened cohesion is discussed, not fc\n",
    "interfaceysf = fn.misc.min(interfaceys, ndp.ysMax)\n",
    "interfaceyielding = interfaceysf/(2.*(strainRate_2ndInvariant))\n",
    "\n",
    "\n",
    "#Condition for weak crust rheology to be active\n",
    "interfaceCond = operator.and_((depthFn < ndp.CRUSTVISCUTOFF), (depthFn > ndp.MANTLETOCRUST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############\n",
    "#Rheology: create UW2 functions for all viscous mechanisms\n",
    "#############\n",
    "\n",
    "omega = fn.misc.constant(1.) #this function can hold any arbitary viscosity modifications \n",
    "\n",
    "\n",
    "##Diffusion Creep\n",
    "diffusion = (1./ndp.Adf ) *fn.math.exp( ((ndp.Edf + (corrDepthFn*ndp.Wdf))/((corrTempFn+ ndp.TS)))) \n",
    "\n",
    "\n",
    "##Diffusion Creep\n",
    "lmdiffusion = (1./ndp.Alm ) *fn.math.exp( ((ndp.Elm + (corrDepthFn*ndp.Wlm))/((corrTempFn+ ndp.TS)))) \n",
    "\n",
    "\n",
    "linearVisc = safe_visc(diffusion)\n",
    "\n",
    "##Dislocation Creep\n",
    "pefac = (ndp.Ads**((-1./ndp.n)))\n",
    "srfac = strainRate_2ndInvariant**((1.-ndp.n)/ndp.n)\n",
    "dislocation = pefac*srfac*fn.math.exp( ((ndp.Eds + (corrDepthFn*ndp.Wds))/(ndp.n*(corrTempFn + ndp.TS))))\n",
    "\n",
    "\n",
    "##Peirls Creep\n",
    "pefac = (ndp.Apr**((-1./ndp.np)))\n",
    "srfac = strainRate_2ndInvariant**((1.-ndp.np)/ndp.np)\n",
    "peierls = pefac*srfac*fn.math.exp( ((ndp.Eps + (corrDepthFn*ndp.Wps))/(ndp.np*(corrTempFn+ ndp.TS))))\n",
    "\n",
    "\n",
    "##Define the mantle Plasticity\n",
    "ys =  ndp.cm + (depthFn*ndp.fcmd)\n",
    "ysf = fn.misc.min(ys, ndp.ysMax)\n",
    "yielding = ysf/(2.*(strainRate_2ndInvariant)) \n",
    "\n",
    "##Crust rheology\n",
    "crustys =  ndp.cc + (depthFn*ndp.fccd)\n",
    "crustysf = fn.misc.min(crustys, ndp.ysMax)\n",
    "crustyielding = crustysf/(2.*(strainRate_2ndInvariant)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#crustyielding.evaluate(mesh).min(), crustyielding.evaluate(mesh).mean(),crustyielding.evaluate(mesh).max()\n",
    "#finalcrustviscosityFn.evaluate(mesh).min(),finalcrustviscosityFn.evaluate(mesh).max(), finalcrustviscosityFn.evaluate(mesh).mean()\n",
    "#strainRate_2ndInvariant.evaluate(mesh).min(), strainRate_2ndInvariant.evaluate(mesh).mean(), strainRate_2ndInvariant.evaluate(mesh).max()\n",
    "#safe_visc(diffusion).evaluate(mesh).mean()\n",
    "#interfaceviscosityFn.evaluate(mesh).min(), interfaceviscosityFn.evaluate(mesh).max(), interfaceviscosityFn.evaluate(mesh).mean()\n",
    "#interfaceyielding.evaluate(mesh).min(), interfaceyielding.evaluate(mesh).mean(), interfaceyielding.evaluate(mesh).max()\n",
    "#ndp.eta_min, ndp.eta_max_interface\n",
    "#finalviscosityFn.evaluate(mesh).min(),finalviscosityFn.evaluate(mesh).max(), finalviscosityFn.evaluate(mesh).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############\n",
    "#Rheology: combine viscous mechanisms in various ways \n",
    "#harmonic: harmonic average of all mechanims\n",
    "#min: minimum effective viscosity of the mechanims\n",
    "#mixed: takes the minimum of the harmonic and the plastic effective viscosity\n",
    "#############\n",
    "\n",
    "#Map viscMechs list (defined in setup), to the actual functions, requires that same names are used.\n",
    "viscdict = {}\n",
    "for i in md.viscMechs:\n",
    "    viscdict[i] = locals()[i]\n",
    "\n",
    "   \n",
    "    \n",
    "#Harmonic average of all mechanisms    \n",
    "if md.viscCombine == 'harmonic':\n",
    "    denom = fn.misc.constant(0.)\n",
    "    for mech in viscdict.values():\n",
    "        denom += 1./mech\n",
    "    mantleviscosityFn = safe_visc(1./denom)\n",
    "    harmonic_test = mantleviscosityFn\n",
    "    #Only diffusuion creep for lower mantle\n",
    "    finalviscosityFn  = fn.branching.conditional([(depthFn < ndp.LOWMANTLEDEPTH, mantleviscosityFn),\n",
    "                                  (True, safe_visc(lmdiffusion*ndp.low_mantle_visc_fac))])\n",
    "\n",
    "    #Add the weaker crust mechanism, plus any cutoffs\n",
    "    crust_denom = denom + (1./crustyielding)\n",
    "    crustviscosityFn = safe_visc(1./crust_denom, viscmin=ndp.eta_min_crust, viscmax=ndp.eta_max_crust)\n",
    "    #Crust viscosity only active above between CRUSTVISCUTOFF and MANTLETOCRUST\n",
    "    finalcrustviscosityFn  = fn.branching.conditional([(depthFn < ndp.CRUSTVISCUTOFF, crustviscosityFn),\n",
    "                                                     (True, finalviscosityFn)])\n",
    "\n",
    "    \n",
    "    \n",
    "if md.viscCombine == 'min':\n",
    "    mantleviscosityFn = fn.misc.constant(ndp.eta_max)\n",
    "    for mech in viscdict.values():\n",
    "        mantleviscosityFn = fn.misc.min(mech, mantleviscosityFn )\n",
    "    mantleviscosityFn = safe_visc(mantleviscosityFn)\n",
    "    min_test = mantleviscosityFn\n",
    "    #Only diffusion creep for lower mantle\n",
    "    finalviscosityFn  = fn.branching.conditional([(depthFn < ndp.LOWMANTLEDEPTH, mantleviscosityFn),\n",
    "                                  (True, safe_visc(lmdiffusion*ndp.low_mantle_visc_fac))])\n",
    "    #Add the weaker crust and interface mechanisms, plus any cutoffs\n",
    "    crustviscosityFn = safe_visc(fn.misc.min(finalviscosityFn, crustyielding), viscmin=ndp.eta_min, viscmax=ndp.eta_max_crust)\n",
    "    #Crust viscosity only active above between CRUSTVISCUTOFF and MANTLETOCRUST\n",
    "    finalcrustviscosityFn  = fn.branching.conditional([(depthFn < ndp.CRUSTVISCUTOFF, crustviscosityFn),\n",
    "                                                     (True, finalviscosityFn)])\n",
    "\n",
    "if md.viscCombine == 'mixed':\n",
    "    denom = fn.misc.constant(0.)\n",
    "    for mech in viscdict.values():\n",
    "        denom += 1./mech\n",
    "    mantleviscosityFn = safe_visc(fn.misc.min(yielding, (1./denom))) #min of harmonic average and yielding\n",
    "    mixed_test = mantleviscosityFn\n",
    "    #Only diffusuion creep for lower mantle\n",
    "    finalviscosityFn  = fn.branching.conditional([(depthFn < ndp.LOWMANTLEDEPTH, mantleviscosityFn),\n",
    "                                  (True, safe_visc(lmdiffusion*ndp.low_mantle_visc_fac))])\n",
    "    \n",
    "    #Add the weaker crust mechanism, plus any cutoffs\n",
    "    crust_denom = denom + (1./crustyielding)\n",
    "    crustviscosityFn = safe_visc(fn.misc.min(crustyielding,1./crust_denom), viscmin=ndp.eta_min, viscmax=ndp.eta_max_crust)\n",
    "    #Crust viscosity only active above between CRUSTVISCUTOFF and MANTLETOCRUST\n",
    "    finalcrustviscosityFn  = fn.branching.conditional([(depthFn < ndp.CRUSTVISCUTOFF, crustviscosityFn),\n",
    "                                                     (True, finalviscosityFn)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check the implementation above, using a simpler formulation\n",
    "\n",
    "\n",
    "#denoms1 =  ((1./diffusion) + (1./dislocation) + (1./peierls) + (1./yielding) )\n",
    "#mantleviscosityFn1 = safe_visc((1./denoms1) )\n",
    "#finalviscosityFn1  = fn.branching.conditional([(depthFn < ndp.LOWMANTLEDEPTH, mantleviscosityFn),\n",
    "#                                  (True, safe_visc(lmdiffusion*ndp.low_mantle_visc_fac))])\n",
    "\n",
    "#crust_denoms1 = ((1./diffusion) + (1./dislocation) + (1./peierls) + (1./crustyielding) )\n",
    "#crustviscosityFn1 = safe_visc(1./crust_denoms1, viscmin=ndp.eta_max_crust, viscmax=ndp.eta_max_crust)\n",
    "#finalcrustviscosityFn1  = fn.branching.conditional([(depthFn < ndp.CRUSTVISCUTOFF, crustviscosityFn1),\n",
    "#                                                     (True, finalviscosityFn1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#viscMinConditions = fn.misc.min(diffusion, dislocation, peierls, yielding)\n",
    "\n",
    "viscMin = fn.misc.constant(ndp.eta_max)\n",
    "#Generate the minimum viscosity function \n",
    "for mech in [safe_visc(diffusion), safe_visc(dislocation), safe_visc(peierls), safe_visc(yielding)]:\n",
    "    viscMin = fn.misc.min(mech, viscMin) \n",
    "    \n",
    "dm = 1e-5\n",
    "   \n",
    "    \n",
    "viscMinConditions = [ ( operator.and_((viscMin > (ndp.eta_max - dm) ),\n",
    "                           (viscMin < (ndp.eta_max + dm) ))  , 0),  #visc = ndp.eta_max\n",
    "                      ( operator.and_((viscMin > (diffusion - dm) ),\n",
    "                           (viscMin < (diffusion + dm) ))  , 1),  #visc = diffusion\n",
    "                      ( operator.and_((viscMin > (dislocation - dm) ),\n",
    "                           (viscMin < (dislocation + dm) ))  , 2),#visc = dislocation\n",
    "                      ( operator.and_((viscMin > (peierls - dm) ),\n",
    "                           (viscMin < (peierls + dm) ))  , 3),    #visc = peierls\n",
    "                      ( operator.and_((viscMin > (yielding - dm) ),\n",
    "                           (viscMin < (yielding + dm) ))  , 4),   #visc = yielding\n",
    "                      ( True                                           , 5) ] #visc = eta_min (should be)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# use the branching conditional function to set each particle's index\n",
    "fnViscMin = fn.branching.conditional( viscMinConditions )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stokes system setup\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "densityMapFn = fn.branching.map( fn_key = materialVariable,\n",
    "                         mapping = {airIndex:ndp.StRA,\n",
    "                                    crustIndex:basaltbuoyancyFn, \n",
    "                                    mantleIndex:pyrolitebuoyancyFn,\n",
    "                                    harzIndex:harzbuoyancyFn} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define our vertical unit vector using a python tuple (this will be automatically converted to a function).\n",
    "gravity = ( 0.0, 1.0 )\n",
    "\n",
    "# Now create a buoyancy force vector using the density and the vertical unit vector. \n",
    "buoyancyFn = densityMapFn * gravity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/underworld2/underworld/systems/_stokes.py:70: UserWarning: 'swarm' paramater has been renamed to 'voronoi_swarm'. Please update your models. 'swarm' parameter will be removed in the next release.\n",
      "  \"'swarm' parameter will be removed in the next release.\")\n"
     ]
    }
   ],
   "source": [
    "if md.PIC_integration:\n",
    "    stokesPIC = uw.systems.Stokes(velocityField=velocityField, \n",
    "                              pressureField=pressureField,\n",
    "                              conditions=[freeslipBC,],\n",
    "                              fn_viscosity=linearVisc, \n",
    "                              fn_bodyforce=buoyancyFn,\n",
    "                             swarm=gSwarm)\n",
    "    \n",
    "\n",
    "else:\n",
    "    stokesPIC = uw.systems.Stokes(velocityField=velocityField, \n",
    "                              pressureField=pressureField,\n",
    "                              conditions=[freeslipBC,],\n",
    "                              fn_viscosity=linearVisc, \n",
    "                              fn_bodyforce=buoyancyFn )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solver = uw.systems.Solver(stokesPIC)\n",
    "if not checkpointLoad:\n",
    "    solver.solve() #A solve on the linear visocisty is unhelpful unless we're starting from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "viscosityMapFn = fn.branching.map( fn_key = materialVariable,\n",
    "                         mapping = {crustIndex:finalcrustviscosityFn,\n",
    "                                    mantleIndex:finalviscosityFn,\n",
    "                                    harzIndex:finalviscosityFn} )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add the non-linear viscosity to the Stokes system\n",
    "stokesPIC.fn_viscosity = viscosityMapFn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35m\n",
      " \n",
      "Pressure iterations:   3\n",
      "Velocity iterations:   1 (presolve)      \n",
      "Velocity iterations:  -1 (pressure solve)\n",
      "Velocity iterations:   1 (backsolve)     \n",
      "Velocity iterations:   1 (total solve)   \n",
      " \n",
      "SCR RHS  solve time: 7.7675e-01\n",
      "Pressure solve time: 6.8193e-02\n",
      "Velocity solve time: 7.7155e-01 (backsolve)\n",
      "Total solve time   : 1.7464e+00\n",
      " \n",
      "Velocity solution min/max: 0.0000e+00/0.0000e+00\n",
      "Pressure solution min/max: 0.0000e+00/0.0000e+00\n",
      " \n",
      "\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "solver.set_inner_method(\"mumps\")\n",
    "solver.options.scr.ksp_type=\"cg\"\n",
    "solver.set_penalty(1.0e7)\n",
    "solver.options.scr.ksp_rtol = 1.0e-4\n",
    "solver.solve(nonLinearIterate=True)\n",
    "solver.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check which particles are yielding\n",
    "#yieldingCheck.data[:] = 0\n",
    "\n",
    "#yieldconditions = [ ( mantleviscosityFn < Visc , 1), \n",
    "#               ( True                                           , 0) ]\n",
    "\n",
    "# use the branching conditional function to set each particle's index\n",
    "#yieldingCheck.data[:] = fn.branching.conditional( yieldconditions ).evaluate(gSwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fig= glucifer.Figure()\n",
    "#fig.append( glucifer.objects.Points(gSwarm,lowerPlateRestFn))\n",
    "#fig.append( glucifer.objects.Points(gSwarm, diffusion, logScale=True, valueRange =[1e-1,1e5]))\n",
    "#fig.append( glucifer.objects.Surface(mesh, temperatureField ))#\n",
    "#fig.append( glucifer.objects.VectorArrows(mesh,velocityField, scaling=0.002))\n",
    "#fig.append( glucifer.objects.Surface(mesh,densityMapFn))\n",
    "#fig.append( glucifer.objects.Surface(mesh,raylieghFn))\n",
    "#fig.append( glucifer.objects.Points(swarmPlateBoundary, pointSize=4))\n",
    "#fig.show()\n",
    "#fig.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up principal stress vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#there are some sign problems I need to figure out here. \n",
    "\n",
    "eig1       = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=2 )\n",
    "\n",
    "sRt = sym_strainRate.evaluate(mesh)\n",
    "\n",
    "tau = np.sqrt(((sRt[:,0]+ 1e-14 - sRt[:,1])**2)/4. + sRt[:,2]**2) #shear stress max.\n",
    "principalAngles = 0.5*np.arcsin(sRt[:,2]/tau)*(180./np.pi)\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "eig1.data[:,0] = np.cos(np.radians(principalAngles))\n",
    "eig1.data[:,1] = np.sin(np.radians(principalAngles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "eig1       = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=2 )\n",
    "eig2       = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=2 )\n",
    "\n",
    "ssr = sym_strainRate.evaluate(mesh)\n",
    "\n",
    "for ti, val in enumerate(eig1.data):\n",
    "    eigVals, eigVex= np.linalg.eig(np.array([[ssr[ti][0],ssr[ti][2]],[ssr[ti][2],ssr[ti][1]]]))\n",
    "    pi = np.argmax(np.abs(eigVals)) #index of largest eigenvalue\n",
    "    eig1.data[ti] = eigVex[pi]\n",
    "    eig2.data[ti] = eigVex[abs(pi - 1)] #index of other eigenvalue - 2D assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#fig= glucifer.Figure()\n",
    "#fig.append( glucifer.objects.VectorArrows(mesh,eig1, scaling=0.1,arrowHead=0.1))\n",
    "#fig.append( glucifer.objects.VectorArrows(mesh,eig2, scaling=0.1,arrowHead=0.1))\n",
    "\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advection-diffusion System setup\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "advDiff = uw.systems.AdvectionDiffusion( phiField       = temperatureField, \n",
    "                                         phiDotField    = temperatureDotField, \n",
    "                                         velocityField  = velocityField,\n",
    "                                         fn_sourceTerm    = 0.0,\n",
    "                                         fn_diffusivity = 1.0, \n",
    "                                         #conditions     = [neumannTempBC, dirichTempBC] )\n",
    "                                         conditions     = [ dirichTempBC] )\n",
    "order = 2\n",
    "if md.periodicBcs:\n",
    "    order = 1\n",
    "\n",
    "materialadvector = uw.systems.SwarmAdvector( swarm         = gSwarm, \n",
    "                                     velocityField = velocityField, \n",
    "                                     order         = order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#population_control = uw.swarm.PopulationControl(gSwarm,deleteThreshold=0.2,splitThreshold=1.,maxDeletions=3,maxSplits=0, aggressive=True, particlesPerCell=int(md.ppc))\n",
    "\n",
    "population_control = uw.swarm.PopulationControl(gSwarm,deleteThreshold=0.006,splitThreshold=0.1,maxDeletions=int(md.ppc/5),maxSplits=int(md.ppc/5), aggressive=True,aggressiveThreshold=0.9, particlesPerCell=int(md.ppc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "############\n",
    "#Slightly Diffuse the initial perturbation\n",
    "#############\n",
    "\n",
    "#I was playing around with a tailored diffusivity to target the slab\n",
    "\n",
    "inCircleFnGenerator#Now build the perturbation part\n",
    "def htan(centre, radius, widthPh, farVal = 0.01, fac = 10.):\n",
    "    coord = fn.input()\n",
    "    offsetFn = coord - centre\n",
    "    dist = fn.math.sqrt(fn.math.dot( offsetFn, offsetFn ))\n",
    "    \n",
    "    \n",
    "    return (((fn.math.tanh(((radius - dist))/widthPh) + 1.) /2.))*fac + farVal\n",
    "\n",
    "tfun = htan((0.1, 0.9), 0.1, 0.1, 0.1)\n",
    "\n",
    "for index in mesh.specialSets[\"MinJ_VertexSet\"]:\n",
    "    temperatureField.data[index] = \n",
    "for index in mesh.specialSets[\"MaxJ_VertexSet\"]:\n",
    "    temperatureField.data[index] = \n",
    "\n",
    "timetoDifffuse = 0.#Million years\n",
    "incrementtoDiffuse = 0.2 #Million years\n",
    "\n",
    "timetoDifffuse = (timetoDifffuse*1e6*(spery)/sf.SR).magnitude\n",
    "incrementtoDiffuse = (incrementtoDiffuse*1e6*(spery)/sf.SR).magnitude\n",
    "\n",
    "totAdt = 0.\n",
    "it = 0\n",
    "while totAdt < timetoDifffuse:\n",
    "    dtad = advDiff.get_max_dt()\n",
    "    print(\"step\") + str(it) \n",
    "    advDiff.integrate(incrementtoDiffuse)\n",
    "    totAdt += incrementtoDiffuse\n",
    "    it += 1\n",
    "    \n",
    "#Reset Boundary conds.   \n",
    "for index in mesh.specialSets[\"MinJ_VertexSet\"]:\n",
    "    temperatureField.data[index] = ndp.TBP\n",
    "for index in mesh.specialSets[\"MaxJ_VertexSet\"]:\n",
    "    temperatureField.data[index] = ndp.TSP\n",
    "    \n",
    "comm.Barrier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis functions / routines\n",
    "-----\n",
    "\n",
    "Most of the metrics we want to calculate are either:\n",
    "\n",
    "* extrema of some field / function\n",
    "* integral of some field / function\n",
    "* average value of some function (integral divide by area)\n",
    "\n",
    "In addition, we also want to be able to determine these metrics over some restricted part of the domain, where the restriction may either be due some value of a field, a material type, or something more arbitrary.\n",
    "\n",
    "Much of he challenge lies in defining these restriction functions in an efficient and robust way (i.e they don't break down as the model evolves)\n",
    "\n",
    "For volume integrals, and extrema, we build a hierarchy of restriction functions, each borrowing from the previous, until we have divided the domain into a number of sub regions of interest. \n",
    "\n",
    "In general, averages are found afterwards by combining the integral and the area of the relavent subregion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###################\n",
    "#Volume Restriction functions\n",
    "###################\n",
    "\n",
    "#Level 1. Global\n",
    "globRestFn = fn.misc.constant(1.)\n",
    "\n",
    "#Level 2. Rock - air:\n",
    "rockRestFn = uw.swarm.SwarmVariable(gSwarm, dataType='double', count=1)\n",
    "rockRestFn.data[:] = 0.\n",
    "rockRestFn.data[np.where(materialVariable.data[:] != airIndex)] = 1.\n",
    "rockRestFn *= globRestFn #Add next level up in heirarchy\n",
    "\n",
    "\n",
    "#Level 3. lithosphere - mantle:\n",
    "mantleconditions = [ (                                  operator.and_(temperatureField < 0.9*ndp.TPP, operator.and_(xFn> ndp.lRidge,xFn< ndp.rRidge )), 1.),\n",
    "                   (                                                   True , 0.) ]\n",
    "lithRestFn = fn.branching.conditional(mantleconditions)\n",
    "lithRestFn*=rockRestFn #Add next level up in heirarchy\n",
    "\n",
    "\n",
    "#Level 4. lower plate - upper plate:\n",
    "\n",
    "\n",
    "#This whole section simply builds a restriction Fn that separates the upper and lower plate \n",
    "#It's pretty cumbersome, and will need to advected, rebuilt\n",
    "#can YOU think of a better way?\n",
    "   \n",
    "lowerPlateRestFn = gSwarm.add_variable( dataType=\"double\", count=1 )\n",
    "lowerPlateRestFn.data[:] = 0.0\n",
    "sd, pts0 = fault.compute_signed_distance(gSwarm.particleCoordinates.data, distance=w0)\n",
    "sp, pts0 = fault.compute_marker_proximity(gSwarm.particleCoordinates.data, distance=w0)\n",
    "\n",
    "lowerPlateRestFn.data[np.logical_and(sd>0,sp == fault.ID)] = sp[np.logical_and(sd>0,sp == fault.ID)]\n",
    "lowerPlateRestFn *= lithRestFn #Add next level up in heirarchy\n",
    "#The lowerPlateRestFn isn't working on restart - no idea why\n",
    "\n",
    "\n",
    "#Level 5. hinge of lower plate:\n",
    "\n",
    "hinge60Spatialconditions = [ (           operator.and_( (depthFn < (60e3/dp.LS)),  (xFn > ndp.subzone - 60e3/dp.LS)), 1.),\n",
    "                   (                                                   True , 0.) ]\n",
    "\n",
    "hinge60RestFn = fn.branching.conditional(hinge60Spatialconditions)\n",
    "hinge60RestFn*=lowerPlateRestFn #Add next level up in heirarchy\n",
    "\n",
    "\n",
    "\n",
    "hinge180Spatialconditions = [ (           operator.and_( (depthFn < (180e3/dp.LS)),  (xFn > ndp.subzone - 180e3/dp.LS)), 1.),\n",
    "                   (                                                   True , 0.) ]\n",
    "\n",
    "hinge180RestFn = fn.branching.conditional(hinge180Spatialconditions)\n",
    "hinge180RestFn*=lowerPlateRestFn #Add next level up in heirarchy\n",
    "\n",
    "\n",
    "#Level 6. crust/interface in hinge of lower plate:\n",
    "\n",
    "interfaceRestFn = uw.swarm.SwarmVariable(gSwarm, dataType='double', count=1)\n",
    "interfaceRestFn.data[:] = 0.\n",
    "interfaceRestFn.data[np.where(materialVariable.data[:] == crustIndex)] = 1.\n",
    "interfaceRestFn *= hinge60RestFn #Add next level up in heirarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#fig= glucifer.Figure()\n",
    "#fig.append( glucifer.objects.Points(gSwarm,lithRestFn))\n",
    "#fig.append( glucifer.objects.Points(gSwarm, viscosityMapFn, logScale=True, valueRange =[1e-3,1e5]))\n",
    "#fig.append( glucifer.objects.Points(gSwarm, lowerPlateRestFn ))\n",
    "#fig.append( glucifer.objects.VectorArrows(mesh,velocityField, scaling=0.002))\n",
    "#fig.append( glucifer.objects.Surface(mesh,densityMapFn))\n",
    "#fig.append( glucifer.objects.Surface(mesh,raylieghFn))\n",
    "#fig.append( glucifer.objects.Points(slab_seg.swarm, pointSize=10))\n",
    "#fig.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "respltconditions = [ \n",
    "                    (                                  hinge60RestFn*2. > rockRestFn*1., 1.),\n",
    "                    (                                  lowerPlateRestFn*3. > hinge60RestFn*2. , 3.),\n",
    "                    (                                  lithRestFn*5. > lowerPlateRestFn*3. , 4.),\n",
    "                   (                                                   True , 0.) ]\n",
    "\n",
    "respltFn = fn.branching.conditional(respltconditions )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################\n",
    "#Surface Restriction functions\n",
    "###################\n",
    "\n",
    "def platenessFn(val = 0.1):\n",
    "    normgradV = fn.math.abs(velocityField.fn_gradient[0]/fn.math.sqrt(velocityField[0]*velocityField[0])) #[du*/dx]/sqrt(u*u)\n",
    "\n",
    "\n",
    "\n",
    "    srconditions = [ (                                  normgradV < val, 1.),\n",
    "                   (                                                   True , 0.) ]\n",
    "\n",
    "\n",
    "    return fn.branching.conditional(srconditions)\n",
    "\n",
    "srRestFn = platenessFn(val = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###################\n",
    "#Setup any Functions to be integrated\n",
    "###################\n",
    "\n",
    "sqrtv2 = fn.math.sqrt(fn.math.dot(velocityField,velocityField))\n",
    "vx = velocityField[0]\n",
    "v2x = fn.math.dot(velocityField[0],velocityField[0])\n",
    "sqrtv2x = fn.math.sqrt(fn.math.dot(velocityField[0],velocityField[0]))\n",
    "dw = temperatureField*velocityField[1]\n",
    "sinner = fn.math.dot( strainRate_2ndInvariant, strainRate_2ndInvariant )\n",
    "vd = 4.*viscosityMapFn*sinner #there's an extra factor of 2, which is necessary because the of factor of 0.5 in the UW second invariant \n",
    "dTdZ = temperatureField.fn_gradient[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################\n",
    "#Create integral, max/min templates \n",
    "###################\n",
    "\n",
    "def volumeint(Fn = 1., rFn=globRestFn):\n",
    "    return uw.utils.Integral( Fn*rFn,  mesh )\n",
    "\n",
    "def surfint(Fn = 1., rFn=globRestFn, surfaceIndexSet=mesh.specialSets[\"MaxJ_VertexSet\"]):\n",
    "    return uw.utils.Integral( Fn*rFn, mesh=mesh, integrationType='Surface', surfaceIndexSet=surfaceIndexSet)\n",
    "\n",
    "def maxMin(Fn = 1.):\n",
    "    #maxMin(Fn = 1., rFn=globRestFn\n",
    "    #vuFn = fn.view.min_max(Fn*rFn) #the restriction functions don't work with the view.min_max fn yet\n",
    "    vuFn = fn.view.min_max(Fn)\n",
    "    return vuFn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setup volume integrals on different sub regions\n",
    "\n",
    "##Whole rock domain\n",
    "\n",
    "_areaintRock = volumeint(rockRestFn)\n",
    "_tempintRock = volumeint(temperatureField, rockRestFn)\n",
    "_rmsintRock = volumeint(sqrtv2,rockRestFn)\n",
    "_dwintRock = volumeint(dw,rockRestFn)\n",
    "_vdintRock = volumeint(vd,rockRestFn)\n",
    "\n",
    "##Lith \n",
    "\n",
    "_areaintLith  = volumeint(lithRestFn)\n",
    "_tempintLith  = volumeint(temperatureField, lithRestFn)\n",
    "_rmsintLith  = volumeint(sqrtv2,lithRestFn)\n",
    "_dwintLith  = volumeint(dw,lithRestFn)\n",
    "_vdintLith  = volumeint(vd,lithRestFn)\n",
    "\n",
    "##Lower plate\n",
    "\n",
    "_areaintLower  = volumeint(lowerPlateRestFn)\n",
    "_tempintLower  = volumeint(temperatureField, lowerPlateRestFn)\n",
    "_rmsintLower  = volumeint(sqrtv2,lowerPlateRestFn)\n",
    "_dwintLower = volumeint(dw,lowerPlateRestFn)\n",
    "_vdintLower  = volumeint(vd,lowerPlateRestFn)\n",
    "\n",
    "##Hinge lower plate\n",
    "\n",
    "_areaintHinge180  = volumeint(hinge180RestFn)\n",
    "_vdintHinge180  = volumeint(vd,hinge180RestFn)\n",
    "\n",
    "_areaintHinge60  = volumeint(hinge60RestFn)\n",
    "_vdintHinge60  = volumeint(vd,hinge60RestFn)\n",
    "\n",
    "\n",
    "##Interface\n",
    "\n",
    "_areaintInterface  = volumeint(interfaceRestFn)\n",
    "_vdintInterface = volumeint(vd,interfaceRestFn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setup surface integrals\n",
    "\n",
    "_surfLength = surfint()\n",
    "_rmsSurf = surfint(sqrtv2x)\n",
    "_nuTop = surfint(dTdZ)\n",
    "_nuBottom = surfint(dTdZ, surfaceIndexSet=mesh.specialSets[\"MinJ_VertexSet\"])\n",
    "_plateness = surfint(srRestFn)\n",
    "_pressure = surfint(pressureField)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Setup max min fns (at the moment, we can't pass restriction function to view.min_max, so we're limited to whole volume or surface extrema)\n",
    "\n",
    "##Whole rock domain\n",
    "\n",
    "#_maxMinVisc = maxMin(viscosityMapFn1)  #These don't work on swarm variables or mapping functions, yet\n",
    "#dummyFn = _maxMinVisc.evaluate(mesh)\n",
    "#_maxMinStressInv = maxMin(2*viscosityMapFn1*strainRate_2ndInvariant) #These don't work on swarm variables or mapping functions, yet\n",
    "#dummyFn = _maxMinStress.evaluate(mesh)\n",
    "#_maxMinVd = maxMin(vd) #These don't work on swarm variables or mapping functions, yet\n",
    "#dummyFn = _maxMinVd.evaluate(mesh)\n",
    "\n",
    "\n",
    "_maxMinVel = maxMin(velocityField) \n",
    "dummyFn = _maxMinVel.evaluate(mesh)\n",
    "\n",
    "_maxMinSr = maxMin(strainRate_2ndInvariant) \n",
    "dummyFn = _maxMinSr.evaluate(mesh)\n",
    "\n",
    "\n",
    "#Surface extrema\n",
    "_maxMinVxSurf = maxMin(vx)\n",
    "dummyFn = _maxMinVxSurf.evaluate(tWalls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Volume Ints\n",
    "areaintRock = _areaintRock.evaluate()[0]\n",
    "tempintRock = _tempintRock.evaluate()[0]\n",
    "rmsintRock = _rmsintRock.evaluate()[0]\n",
    "dwintRock = _dwintRock.evaluate()[0]\n",
    "vdintRock = _vdintRock.evaluate()[0]\n",
    "areaintLith = _areaintLith.evaluate()[0]\n",
    "tempintLith = _tempintLith.evaluate()[0]\n",
    "rmsintLith = _rmsintLith.evaluate()[0]\n",
    "dwintLith = _dwintLith.evaluate()[0]\n",
    "vdintLith = _vdintLith.evaluate()[0]\n",
    "areaintLower = _areaintLower.evaluate()[0]\n",
    "tempintLower = _tempintLower.evaluate()[0]\n",
    "rmsintLower = _rmsintLower.evaluate()[0]\n",
    "dwintLower = _dwintLower.evaluate()[0]\n",
    "vdintLower = _vdintLower.evaluate()[0]\n",
    "vdintHinge180 = _vdintHinge180.evaluate()[0]\n",
    "areaintHinge180 = _areaintHinge180.evaluate()[0]\n",
    "vdintHinge60 = _vdintHinge60.evaluate()[0]\n",
    "areaintHinge60= _areaintHinge60.evaluate()[0]\n",
    "vdintInterface = _vdintInterface.evaluate()[0]\n",
    "areaintInterface= _areaintInterface.evaluate()[0]\n",
    "\n",
    "#Surface Ints\n",
    "surfLength = _surfLength.evaluate()[0]\n",
    "rmsSurf = _rmsSurf.evaluate()[0]\n",
    "nuTop = _nuTop.evaluate()[0]\n",
    "nuBottom = _nuBottom.evaluate()[0]\n",
    "plateness = _plateness.evaluate()[0]\n",
    "pressureSurf = _pressure.evaluate()[0]\n",
    "\n",
    "\n",
    "#Max mins\n",
    "maxVel = _maxMinVel.max_global()\n",
    "minVel = _maxMinVel.min_global() \n",
    "maxSr = _maxMinSr.max_global()\n",
    "minSr = _maxMinSr.min_global()\n",
    "maxVxsurf = _maxMinVxSurf.max_global()\n",
    "minVxsurf = _maxMinVxSurf.min_global()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(areaintRock)\n",
    "print(tempintRock)\n",
    "print(rmsintRock)\n",
    "print(dwintRock)\n",
    "print(vdintRock)\n",
    "print(areaintLith)\n",
    "print(tempintLith )\n",
    "print(rmsintLith)\n",
    "print(dwintLith)\n",
    "print(vdintLith)\n",
    "print(areaintLower)\n",
    "print(tempintLower)\n",
    "print(rmsintLower) \n",
    "print(dwintLower)\n",
    "print(vdintLower)\n",
    "print(vdintHinge60)\n",
    "print(vdintHinge180)\n",
    "print(vdintInterface)\n",
    "\n",
    "print(surfLength)\n",
    "print(rmsSurf)\n",
    "print(nuTop)\n",
    "print(nuBottom)\n",
    "print(plateness)\n",
    "\n",
    "\n",
    "print(maxVel)\n",
    "print(minVel)\n",
    "print(maxSr)\n",
    "print(minSr)\n",
    "print(maxVxsurf)\n",
    "print(minVxsurf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viz.\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Build a depth dependent mask for the vizualisation\n",
    "\n",
    "depthVariable      = gSwarm.add_variable( dataType=\"float\", count=1 )\n",
    "depthVariable.data[:] = depthFn.evaluate(gSwarm)\n",
    "\n",
    "vizVariable      = gSwarm.add_variable( dataType=\"int\", count=1 )\n",
    "vizVariable.data[:] = 0\n",
    "\n",
    "for index, value in enumerate(depthVariable.data[:]):\n",
    "    #print index, value\n",
    "    if np.random.rand(1)**5 > value/(MAXY - MINY):\n",
    "        vizVariable.data[index] = 1\n",
    "        \n",
    "del index, value    #get rid of any variables that might be pointing at the .data handles (these are!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig= glucifer.Figure()\n",
    "fig.append( glucifer.objects.Points(gSwarm,temperatureField, fn_mask=vizVariable))\n",
    "fig.append( glucifer.objects.Mesh(mesh))\n",
    "#fig.show()\n",
    "fig.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if figures == 'gldb':\n",
    "    #Pack some stuff into a database as well\n",
    "    figDb = glucifer.Figure()\n",
    "    #figDb.append( glucifer.objects.Mesh(mesh))\n",
    "    figDb.append( glucifer.objects.VectorArrows(mesh,velocityField, scaling=0.0005))\n",
    "    #figDb.append( glucifer.objects.Points(gSwarm,tracerVariable, colours= 'white black'))\n",
    "    figDb.append( glucifer.objects.Points(gSwarm,materialVariable, fn_mask=vizVariable))\n",
    "\n",
    "    #figDb.append( glucifer.objects.Points(gSwarm,viscMinVariable))\n",
    "    figDb.append( glucifer.objects.Points(gSwarm,fnViscMin, fn_mask=vizVariable))\n",
    "    #figDb.append( glucifer.objects.Points(gSwarm,fnViscMin))\n",
    "    #figDb.append( glucifer.objects.Points(gSwarm, viscosityMapFn, logScale=True))\n",
    "    #figDb.append( glucifer.objects.Points(gSwarm, strainRate_2ndInvariant, logScale=True))\n",
    "    figDb.append( glucifer.objects.Points(gSwarm,temperatureField, fn_mask=vizVariable))\n",
    "    \n",
    "    \n",
    "    #figRestrict= glucifer.Figure()\n",
    "    #figRestrict.append( glucifer.objects.Points(gSwarm,respltFn))\n",
    "    #figRestrict.append( glucifer.objects.Points(gSwarm,lithRestFn))\n",
    "    #figRestrict.append( glucifer.objects.Points(gSwarm,lowerPlateRestFn))\n",
    "    #figRestrict.append( glucifer.objects.Points(gSwarm,hinge180RestFn))\n",
    "    #figRestrict.append( glucifer.objects.Points(gSwarm,interfaceRestFn))\n",
    "    #figRestrict.append( glucifer.objects.Points(interfaces[0].swarm, colours=\"Blue Blue\", pointSize=2.0, colourBar=False) )\n",
    "    #figRestrict.append( glucifer.objects.Points(interfaces[1].swarm, colours=\"Red Red\", pointSize=2.0, colourBar=False) )\n",
    "    #figRestrict.append( glucifer.objects.Points(slab_seg.swarm, colours=\"Black Black\", pointSize=2.0, colourBar=False) )\n",
    "\n",
    "elif figures == 'store':\n",
    "    fullpath = os.path.join(outputPath + \"gldbs/\")\n",
    "    store1 = glucifer.Store(fullpath + 'subduction1.gldb')\n",
    "    store2 = glucifer.Store(fullpath + 'subduction2.gldb')\n",
    "    store3 = glucifer.Store(fullpath + 'subduction3.gldb')\n",
    "    store4 = glucifer.Store(fullpath + 'subduction4.gldb')\n",
    "\n",
    "\n",
    "    figTemp = glucifer.Figure(store1,figsize=(300*np.round(md.aspectRatio,2),300))\n",
    "    figTemp.append( glucifer.objects.Points(gSwarm,temperatureField, fn_mask=vizVariable))\n",
    "\n",
    "    figVisc= glucifer.Figure(store2, figsize=(300*np.round(md.aspectRatio,2),300))\n",
    "    figVisc.append( glucifer.objects.Points(gSwarm,viscosityMapFn, logScale=True, valueRange =[1.,1e5], fn_mask=vizVariable))\n",
    "    figVisc.append( glucifer.objects.VectorArrows(mesh, eig1, arrowHead=0.0, scaling=0.05, glyphs=3, resolutionI=int(16*md.aspectRatio), resolutionJ=16*2))\n",
    "\n",
    "\n",
    "    figMech= glucifer.Figure(store3, figsize=(300*np.round(md.aspectRatio,2),300))\n",
    "    figMech.append( glucifer.objects.Points(gSwarm,fnViscMin, valueRange =[0.,5.], fn_mask=vizVariable))\n",
    "    \n",
    "    figMat= glucifer.Figure(store4, figsize=(300*np.round(md.aspectRatio,2),300))\n",
    "    figMat.append( glucifer.objects.Points(gSwarm,materialVariable, fn_mask=vizVariable))\n",
    "    figMat.append( glucifer.objects.VectorArrows(mesh,velocityField,resolutionI=int(16*md.aspectRatio), resolutionJ=16*2,  scaling=0.0001))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "if figures == 'gldb':\n",
    "    #Pack some stuff into a database as well\n",
    "    figDb = glucifer.Figure()\n",
    "    #figDb.append( glucifer.objects.Mesh(mesh))\n",
    "    figDb.append( glucifer.objects.VectorArrows(mesh,velocityField, scaling=0.0005))\n",
    "    #figDb.append( glucifer.objects.Points(gSwarm,tracerVariable, colours= 'white black'))\n",
    "    figDb.append( glucifer.objects.Points(gSwarm,materialVariable))\n",
    "    figDb.append( glucifer.objects.Points(swarmPlateBoundary, pointSize=4))\n",
    "\n",
    "    #figDb.append( glucifer.objects.Points(gSwarm,viscMinVariable))\n",
    "    figDb.append( glucifer.objects.Points(vSwarm,fnViscMin))\n",
    "    #figDb.append( glucifer.objects.Points(gSwarm,fnViscMin))\n",
    "    #figDb.append( glucifer.objects.Points(gSwarm, viscosityMapFn, logScale=True))\n",
    "    #figDb.append( glucifer.objects.Points(gSwarm, strainRate_2ndInvariant, logScale=True))\n",
    "    figDb.append( glucifer.objects.Points(vSwarm,temperatureField))\n",
    "    \n",
    "    \n",
    "    #figRestrict= glucifer.Figure()\n",
    "    #figRestrict.append( glucifer.objects.Points(gSwarm,respltFn))\n",
    "    #figRestrict.append( glucifer.objects.Points(gSwarm,lithRestFn))\n",
    "    #figRestrict.append( glucifer.objects.Points(gSwarm,lowerPlateRestFn))\n",
    "    #figRestrict.append( glucifer.objects.Points(gSwarm,hinge180RestFn))\n",
    "    #figRestrict.append( glucifer.objects.Points(gSwarm,interfaceRestFn))\n",
    "    #figRestrict.append( glucifer.objects.Points(interfaces[0].swarm, colours=\"Blue Blue\", pointSize=2.0, colourBar=False) )\n",
    "    #figRestrict.append( glucifer.objects.Points(interfaces[1].swarm, colours=\"Red Red\", pointSize=2.0, colourBar=False) )\n",
    "    #figRestrict.append( glucifer.objects.Points(slab_seg.swarm, colours=\"Black Black\", pointSize=2.0, colourBar=False) )\n",
    "\n",
    "elif figures == 'store':\n",
    "    fullpath = os.path.join(outputPath + \"gldbs/\")\n",
    "    store = glucifer.Store(fullpath + 'subduction.gldb')\n",
    "\n",
    "    figTemp = glucifer.Figure(store,figsize=(300*np.round(md.aspectRatio,2),300))\n",
    "    figTemp.append( glucifer.objects.Points(vSwarm,temperatureField))\n",
    "\n",
    "    figVisc= glucifer.Figure(store, figsize=(300*np.round(md.aspectRatio,2),300))\n",
    "    figVisc.append( glucifer.objects.Points(gSwarm,viscosityMapFn, logScale=True, valueRange =[1.,1e5]))\n",
    "\n",
    "    figMech= glucifer.Figure(store, figsize=(300*np.round(md.aspectRatio,2),300))\n",
    "    figMech.append( glucifer.objects.Points(vSwarm,fnViscMin))\n",
    "    \n",
    "    figMat= glucifer.Figure(store, figsize=(300*np.round(md.aspectRatio,2),300))\n",
    "    figMat.append( glucifer.objects.Points(gSwarm,materialVariable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Miscellania**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/numpy/core/numeric.py:190: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  a = empty(shape, dtype, order)\n"
     ]
    }
   ],
   "source": [
    "##############\n",
    "#Create a numpy array at the surface to get surface information on (using parallel-friendly evaluate_global)\n",
    "##############\n",
    "\n",
    "surface_xs = np.linspace(mesh.minCoord[0], mesh.maxCoord[0], mesh.elementRes[0] + 1)\n",
    "surface_nodes = np.array(zip(surface_xs, np.ones(len(surface_xs)*mesh.maxCoord[1]))) #For evaluation surface velocity\n",
    "normgradV = velocityField.fn_gradient[0]/fn.math.sqrt(velocityField[0]*velocityField[0])\n",
    "\n",
    "tempMM = fn.view.min_max(temperatureField)\n",
    "dummy = tempMM.evaluate(mesh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Not parallel friendly yet\n",
    "#tipXvels = np.sum(velocityField[0].evaluate(tipSwarm)) /\\\n",
    "#    tipSwarm.particleGlobalCount\n",
    "#tipXvels = np.sum(velocityField[1].evaluate(tipSwarm)) /\\\n",
    "#    tipSwarm.particleGlobalCount\n",
    "    \n",
    "#tipXpos = np.sum(xFn.evaluate(tipSwarm)) /\\\n",
    "#    tipSwarm.particleGlobalCount\n",
    "#tipYpos = np.sum(yFn.evaluate(tipSwarm)) /\\\n",
    "#    tipSwarm.particleGlobalCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#These functions handle checkpointing\n",
    "##############\n",
    "\n",
    "\n",
    "#Subzone = ndp.subzone\n",
    "\n",
    "\n",
    "def checkpoint1(step, checkpointPath,filename, filewrites):\n",
    "    path = checkpointPath + str(step) \n",
    "    os.mkdir(path)\n",
    "    ##Write and save the file, if not already a writing step\n",
    "    if not step % filewrites == 0:\n",
    "        f_o.write((30*'%-15s ' + '\\n') % (areaintRock, tempintRock, rmsintRock, dwintRock, vdintRock,\n",
    "                                  areaintLith, tempintLith,rmsintLith, dwintLith, vdintLith,\n",
    "                                  areaintLower, tempintLower, rmsintLower, dwintLower, vdintLower, \n",
    "                                  areaintHinge180,vdintHinge180, areaintHinge60, vdintHinge60, \n",
    "                                  areaintInterface, vdintInterface, vdintInterface,\n",
    "                                  rmsSurf, nuTop, nuBottom, plateness, ndp.subzone,ndp.lRidge, ndp.rRidge, realtime))\n",
    "    filename.close()\n",
    "    shutil.copyfile(os.path.join(outputPath, outputFile), os.path.join(path, outputFile))\n",
    "\n",
    "\n",
    "def checkpoint2(step, checkpointPath, swarm, filename, varlist = [materialVariable], varnames = ['materialVariable']):\n",
    "    path = checkpointPath + str(step) \n",
    "    velfile = \"velocityField\" + \".hdf5\"\n",
    "    tempfile = \"temperatureField\" + \".hdf5\"\n",
    "    pressfile = \"pressureField\" + \".hdf5\"\n",
    "    velocityField.save(os.path.join(path, velfile))\n",
    "    temperatureField.save(os.path.join(path, tempfile))\n",
    "    pressureField.save(os.path.join(path, pressfile))\n",
    "    swarm.save(os.path.join(path, \"swarm.h5\") ) \n",
    "    for ix in range(len(varlist)):\n",
    "        varb = varlist[ix]\n",
    "        varb.save(os.path.join(path,varnames[ix] + \".h5\"))\n",
    "    \n",
    "    #Save the parameters\n",
    "    dict_list = [dp, sf, ndp, md] #if any of the dictionaries have changed, this list needs to be rebuilt\n",
    "    save_pickles(dict_list, dict_names, path)\n",
    "    \n",
    "#Simple Checkpoint function for the faults / interfaces (markerLine2D)\n",
    "def checkpoint3(step,  checkpointPath, interfaces,interfacenames ):\n",
    "    path = checkpointPath + str(step)\n",
    "    for ix in range(len(interfaces)):\n",
    "        intf = interfaces[ix]\n",
    "        intf.swarm.save(os.path.join(path,interfacenames[ix] + \".h5\"))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plate_infoFn(velocityField,xFn,  depthLimit, xsearchlim = 1.0, currentloc = 0.0, plateType='convergent'):\n",
    "    \"\"\"\n",
    "    This functions is used to track the plate boundaries in 2D.\n",
    "    It returns the x value of the max / min of the x velocity gradient.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #Restriction fucntion \n",
    "    restictionFn = fn.branching.conditional([(operator.and_(fn.math.abs(xFn - currentloc) < xsearchlim, depthFn < depthLimit) , 1.),                                       \n",
    "                                             (True, 0.0)])\n",
    "    \n",
    "    #Normalised surface vel gradient\n",
    "    normgradV = velocityField.fn_gradient[0]/fn.math.sqrt(velocityField[0]*velocityField[0])\n",
    "\n",
    "    \n",
    "    plateFn0 = normgradV*restictionFn\n",
    "    \n",
    "    plateFn = fn.branching.conditional([(plateFn0 > 1e20, 0.),             #This attempts to fix inf values that appear at sidewalls                          \n",
    "                                             (True, plateFn0)])\n",
    "    \n",
    "    extremFn = fn.view.min_max(plateFn)\n",
    "    dummy = extremFn.evaluate(mesh)\n",
    "    \n",
    "    \n",
    "    print(extremFn.min_global(), extremFn.max_global())\n",
    "\n",
    "    #get global max\n",
    "    if plateType == 'convergent':   \n",
    "        testFn = fn.branching.conditional([(extremFn < extremFn.min_global() + 1e-10, coordinate[0]),                                       \n",
    "                                             (True, (-9999999.))])\n",
    "        extremFn2 = fn.view.min_max(testFn)\n",
    "        dummy2 = extremFn2.evaluate(mesh)\n",
    "        if extremFn2.max_global() == -9999999.:\n",
    "            return currentloc\n",
    "        else:\n",
    "            return extremFn2.max_global()\n",
    "    elif plateType == 'divergent':\n",
    "        testFn = fn.branching.conditional([(extremFn > extremFn.max_global() - 1e-3, coordinate[0]),                                       \n",
    "                                             (True, (-9999999.))])\n",
    "        extremFn2 = fn.view.min_max(testFn)\n",
    "        dummy2 = extremFn2.evaluate(mesh)\n",
    "        if extremFn2.max_global() == -9999999.:\n",
    "            return currentloc\n",
    "        else:\n",
    "            return extremFn2.max_global()\n",
    "    else:\n",
    "        raise ValueError('plateType should be one of convergent/divergent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#This will allow us to evaluate viscous shear heating, and add the result directly to the temperature field\n",
    "##############\n",
    "\n",
    "viscDisMapFn = 4.*viscosityMapFn*sinner\n",
    "viscDisFnmesh = uw.mesh.MeshVariable(mesh,nodeDofCount=1)\n",
    "viscDisProj = uw.utils.MeshVariable_Projection( viscDisFnmesh, viscDisMapFn)\n",
    "viscDisProj.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialise timer for computation\n",
    "start = time.clock()\n",
    "\n",
    "\n",
    "next_image_step = np.ceil((0./files_freq)+ 1/sf.SR) *files_freq #increment time for our next image / file dump\n",
    "#the 1/sf.SR kludge represents a dimensionless value of 1 second - avoids np.ceil(0.) = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ndp.lRidge, mesh.minCoord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main simulation loop\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'midthickness' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-d208a391f37b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[1;31m#Slab / mid swarm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msense\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Right'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m             \u001b[0mintroPoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mndp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlRidge\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmidthickness\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[0mintroPoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mndp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrRidge\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmidthickness\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'midthickness' is not defined"
     ]
    }
   ],
   "source": [
    "#while step < 21:\n",
    "while realtime < 1.:\n",
    "\n",
    "    # solve Stokes and advection systems\n",
    "    solver.solve(nonLinearIterate=True)\n",
    "    \n",
    "    \n",
    "    #remove drift /null space in pressure\n",
    "    pressureField.data[:] -= pressureSurf/surfLength\n",
    "    \n",
    "    files_this_step = False #don't write files / images unless conditions are triggered\n",
    "    dt = advDiff.get_max_dt()*md.courantFac\n",
    "    if step == 0:\n",
    "        dt = 0.\n",
    "        files_this_step = True #write files on the zeroth step\n",
    "    \n",
    "    #This relates to file writing at set period - override make sure we hit certain time values\n",
    "    if realtime + dt >= next_image_step:\n",
    "        dt = next_image_step - realtime\n",
    "        files_this_step = True\n",
    "        next_image_step += files_freq #increment time for our next image / file dump\n",
    "        \n",
    "    advDiff.integrate(dt)\n",
    "    materialadvector.integrate(dt)\n",
    "    #advect any interfaces\n",
    "    fault.advection(dt)\n",
    "    \n",
    "    #Add the adiabatic adjustment \n",
    "    temperatureField.data[:] += dt*abHeatFn.evaluate(mesh)\n",
    "    \n",
    "    #Add the viscous heating term\n",
    "    #Need to be skeptical of Projection for viscosity. Also try direct interpolation (IDW)\n",
    "    #viscDisProj = uw.utils.MeshVariable_Projection( viscDisFnmesh, viscDisMapFn)\n",
    "    #viscDisProj.solve()\n",
    "    #temperatureField.data[:] += (ndp.Di/ndp.RA)*dt*viscDisFnmesh.evaluate(mesh)\n",
    "    \n",
    "\n",
    "    # Increment\n",
    "    realtime += dt\n",
    "    step += 1\n",
    "    timevals.append(realtime)\n",
    "    \n",
    "    ################\n",
    "    #Update temperature field in the air region\n",
    "    #Do this better...\n",
    "    ################\n",
    "    if (step % sticky_air_temp == 0):\n",
    "        for index, coord in enumerate(mesh.data):\n",
    "            if coord[1] >= 1.:\n",
    "                temperatureField.data[index] = ndp.TSP\n",
    "                \n",
    "                \n",
    "    ################\n",
    "    #Files output\n",
    "    ################ \n",
    "    if files_this_step:\n",
    "        \n",
    "        gSwarm.update_particle_owners()\n",
    "        \n",
    "        #Save the fault swarm\n",
    "        fnametemp1 = \"faultSwarm\" + \"_\" + str(step)\n",
    "        fullpath1 = os.path.join(outputPath + \"files/\" + fnametemp1)\n",
    "        fault.swarm.save(fullpath1)\n",
    "        \n",
    "        #any fields / swarms to be saved go here\n",
    "        \n",
    "        \n",
    "\n",
    "                          \n",
    "\n",
    "    ################\n",
    "    #Update the subduction zone / plate information\n",
    "    ################ \n",
    "    \n",
    "    comm.barrier()\n",
    "    if (step % metric_output == 0):\n",
    "        \n",
    "\n",
    "        ndp.subzone = plate_infoFn(velocityField,xFn,  20e3/dp.LS, xsearchlim = 200e3/dp.LS, currentloc = ndp.subzone, plateType='convergent')\n",
    "        ndp.lRidge = plate_infoFn(velocityField,xFn,  20e3/dp.LS, xsearchlim = 200e3/dp.LS, currentloc = ndp.lRidge, plateType='divergent')\n",
    "        ndp.rRidge = plate_infoFn(velocityField,xFn,  20e3/dp.LS, xsearchlim = 200e3/dp.LS, currentloc = ndp.rRidge, plateType='divergent')\n",
    "\n",
    "    \n",
    "         \n",
    "            \n",
    "    ################\n",
    "    # Calculate the Metrics\n",
    "    ################\n",
    "    \n",
    "    if (step % metric_output == 0):\n",
    "        ###############\n",
    "        #Rebuild the restriction functions where necessary\n",
    "        ###############\n",
    "        \n",
    "        #Lithosphere - mantle:\n",
    "        mantleconditions = [ (                                  operator.and_(temperatureField < 0.9*ndp.TPP, operator.and_(xFn> ndp.lRidge,xFn< ndp.rRidge )), 1.),\n",
    "                   (                                                   True , 0.) ]\n",
    "        lithRestFn = fn.branching.conditional(mantleconditions)\n",
    "        lithRestFn*=rockRestFn #Add next level up in heirarchy\n",
    "        \n",
    "        #Lower plate\n",
    "        \n",
    "        lowerPlateRestFn = gSwarm.add_variable( dataType=\"double\", count=1 ) #weirdly we have to rebuild this one...\n",
    "        lowerPlateRestFn.data[:] = 0.0\n",
    "        sd, pts0 = fault.compute_signed_distance(gSwarm.particleCoordinates.data, distance=w0)\n",
    "        sp, pts0 = fault.compute_marker_proximity(gSwarm.particleCoordinates.data, distance=w0)\n",
    "        lowerPlateRestFn.data[np.logical_and(sd>0,sp == fault.ID)] = sp[np.logical_and(sd>0,sp == fault.ID)]\n",
    "        lowerPlateRestFn *= lithRestFn #Add next level up in heirarchy\n",
    "        \n",
    "        #Hinge\n",
    "        \n",
    "        hinge60Spatialconditions = [ (           operator.and_( (depthFn < MAXY - (60e3/dp.LS)),  (xFn > ndp.subzone - 60e3/dp.LS)), 1.),\n",
    "                   (                                                   True , 0.) ]\n",
    "        hinge60RestFn = fn.branching.conditional(hinge60Spatialconditions)\n",
    "        hinge60RestFn*=lowerPlateRestFn #Add next level up in hierarchy\n",
    "\n",
    "\n",
    "\n",
    "        hinge180Spatialconditions = [ (           operator.and_( (depthFn < MAXY - (180e3/dp.LS)),  (xFn > ndp.subzone - 180e3/dp.LS)), 1.),\n",
    "                           (                                                   True , 0.) ]\n",
    "        hinge180RestFn = fn.branching.conditional(hinge180Spatialconditions)\n",
    "        hinge180RestFn*=lowerPlateRestFn #Add next level up in hierarchy\n",
    "        \n",
    "        \n",
    "        #Reevaluate max min Functions\n",
    "        dummyFn = _maxMinVel.evaluate(mesh)\n",
    "        dummyFn = _maxMinSr.evaluate(mesh)\n",
    "        dummyFn = _maxMinVxSurf.evaluate(tWalls)\n",
    "        \n",
    "        ###############\n",
    "        #Metrics\n",
    "        ###############\n",
    "        areaintRock = _areaintRock.evaluate()[0] #trivial except when using sticky air\n",
    "        tempintRock = _tempintRock.evaluate()[0]\n",
    "        rmsintRock = _rmsintRock.evaluate()[0]\n",
    "        dwintRock = _dwintRock.evaluate()[0]\n",
    "        vdintRock = _vdintRock.evaluate()[0]\n",
    "        areaintLith = _areaintLith.evaluate()[0]\n",
    "        tempintLith = _tempintLith.evaluate()[0]\n",
    "        rmsintLith = _rmsintLith.evaluate()[0]\n",
    "        dwintLith = _dwintLith.evaluate()[0]\n",
    "        vdintLith = _vdintLith.evaluate()[0]\n",
    "        areaintLower = _areaintLower.evaluate()[0]\n",
    "        tempintLower = _tempintLower.evaluate()[0]\n",
    "        rmsintLower = _rmsintLower.evaluate()[0]\n",
    "        dwintLower = _dwintLower.evaluate()[0]\n",
    "        vdintLower = _vdintLower.evaluate()[0]\n",
    "        vdintHinge180 = _vdintHinge180.evaluate()[0]\n",
    "        areaintHinge180 = _areaintHinge180.evaluate()[0]\n",
    "        vdintHinge60 = _vdintHinge60.evaluate()[0]\n",
    "        areaintHinge60= _areaintHinge60.evaluate()[0]\n",
    "        vdintInterface = _vdintInterface.evaluate()[0]\n",
    "        areaintInterface= _areaintInterface.evaluate()[0]\n",
    "        #Surface integrals\n",
    "        rmsSurf = _rmsSurf.evaluate()[0]\n",
    "        nuTop = _nuTop.evaluate()[0]\n",
    "        nuBottom = _nuBottom.evaluate()[0]\n",
    "        plateness = _plateness.evaluate()[0]\n",
    "        #extrema\n",
    "        maxVel = _maxMinVel.max_global()\n",
    "        minVel = _maxMinVel.min_global() \n",
    "        maxSr = _maxMinSr.max_global()\n",
    "        minSr = _maxMinSr.min_global()\n",
    "        maxVxsurf = _maxMinVxSurf.max_global()\n",
    "        minVxsurf = _maxMinVxSurf.min_global()\n",
    "        # output to text file...root proc. handles this one\n",
    "        if uw.rank()==0:\n",
    "            f_o.write((35*'%-15s ' + '\\n') % (areaintRock, tempintRock, rmsintRock, dwintRock, vdintRock,\n",
    "                                  areaintLith, tempintLith,rmsintLith, dwintLith, vdintLith,\n",
    "                                  areaintLower, tempintLower, rmsintLower, dwintLower, vdintLower, \n",
    "                                  areaintHinge180,vdintHinge180, areaintHinge60, vdintHinge60, \n",
    "                                  areaintInterface, vdintInterface, vdintInterface,\n",
    "                                  minVel,maxVel, minVxsurf, maxVxsurf, surfLength,            \n",
    "                                  rmsSurf, nuTop, nuBottom, plateness, ndp.subzone,ndp.lRidge, ndp.rRidge, realtime))\n",
    "    \n",
    "    \n",
    "    ################\n",
    "    #Also repopulate entire swarm periodically\n",
    "    ################\n",
    "    if step % swarm_repop == 0:\n",
    "        population_control.repopulate()\n",
    "        \n",
    "        \n",
    "                       \n",
    "    ################\n",
    "    #Gldb output\n",
    "    ################ \n",
    "    if files_this_step: \n",
    "        \n",
    "        #ReBuild the principal stress vector\n",
    "        \n",
    "        sRt = sym_strainRate.evaluate(mesh)\n",
    "\n",
    "        tau = np.sqrt(((sRt[:,0]+ 1e-14 - sRt[:,1])**2)/4. + sRt[:,2]**2) #shear stress max.\n",
    "        principalAngles = 0.5*np.arcsin(sRt[:,2]/tau)*(180./np.pi)\n",
    "        eig1.data[:,0] = np.cos(np.radians(principalAngles))\n",
    "        eig1.data[:,1] = np.sin(np.radians(principalAngles))\n",
    "        \n",
    "        \n",
    "        \n",
    "        if figures == 'gldb':\n",
    "            #Remember to rebuild any necessary swarm variables\n",
    "            fnamedb = \"dbFig\" + \"_\" + str(step) + \".gldb\"\n",
    "            fullpath = os.path.join(outputPath + \"gldbs/\" + fnamedb)\n",
    "            figDb.save_database(fullpath)\n",
    "            \n",
    "            #Temp figure\n",
    "            #fnamedb = \"restrictFig\" + \"_\" + str(step) + \".gldb\"\n",
    "            #fullpath = os.path.join(outputPath + \"gldbs/\" + fnamedb)\n",
    "            #figRestrict.save_database(fullpath)\n",
    "        elif figures == 'store':      \n",
    "            fullpath = os.path.join(outputPath + \"gldbs/\")\n",
    "            store1.step = step\n",
    "            store2.step = step\n",
    "            store3.step = step\n",
    "            store4.step = step\n",
    "            #Save figures to store\n",
    "            figVisc.save( fullpath + \"Visc\" + str(step).zfill(4))\n",
    "            figMech.save( fullpath + \"Mech\" + str(step).zfill(4))\n",
    "            figTemp.save( fullpath + \"Temp\"    + str(step).zfill(4))\n",
    "            figMat.save( fullpath + \"Mat\"    + str(step).zfill(4))\n",
    "            #figSr.save( fullpath + \"Str_rte\"    + str(step).zfill(4))     \n",
    "            \n",
    "            \n",
    "    ################\n",
    "    #xdmf output\n",
    "    ################ \n",
    "    \n",
    "    fullpath = os.path.join(outputPath + \"xdmf/\")\n",
    "    if files_this_step:\n",
    "        \n",
    "        fullpath = os.path.join(outputPath + \"xdmf/\")\n",
    "        if not os.path.exists(fullpath+\"mesh.h5\"):\n",
    "            _mH = mesh.save(fullpath+\"mesh.h5\") \n",
    "            mh = _mH\n",
    "    \n",
    "        vH = velocityField.save(fullpath + \"velocity_\" + str(step) +\".h5\")\n",
    "        tH = temperatureField.save(fullpath + \"temp_\" + str(step) + \".h5\")\n",
    "        eH = eig1.save(fullpath + \"eig_\" + str(step) + \".h5\")\n",
    "        velocityField.xdmf(fullpath + \"velocity_\" + str(step), vH, 'velocity', mh, 'mesh', modeltime=realtime)\n",
    "        temperatureField.xdmf(fullpath + \"temp_\" + str(step), tH, 'temperature', mh, 'mesh', modeltime=realtime)\n",
    "        eig1.xdmf(fullpath + \"eig_\" + str(step), eH, 'eig', mh, 'mesh', modeltime=realtime)\n",
    "        \n",
    "    ################\n",
    "    #Particle update\n",
    "    ###############    \n",
    "    #ageVariable.data[:] += dt #increment the ages (is this efficient?)\n",
    "    ageDT += dt\n",
    "    \n",
    "    if step % swarm_update == 0:\n",
    "        \n",
    "        #Increment age stuff. \n",
    "        ageConditions = [ (depthFn < ndp.AGETRACKDEPTH, ageVariable + ageDT ),  #add ageDThere\n",
    "                  (True, 0.) ]\n",
    "        ageVariable.data[:] = fn.branching.conditional( ageConditions ).evaluate(gSwarm)        \n",
    "        ageDT = 0. #reset the age incrementer\n",
    "        \n",
    "        \n",
    "        #This is hardcoded to assume subduction is towards the right\n",
    "        tempop = operator.lt\n",
    "\n",
    "        #Update the relevant parts of the material graph\n",
    "        #Remove and rebuild edges related to crust\n",
    "        DG.remove_edges_from([(mantleIndex,crustIndex)])\n",
    "        DG.add_edges_from([(mantleIndex,crustIndex)])\n",
    "        DG.remove_edges_from([(harzIndex,crustIndex)])\n",
    "        DG.add_edges_from([(harzIndex,crustIndex)])\n",
    "\n",
    "        #... to crust\n",
    "        DG.add_transition((mantleIndex,crustIndex), depthFn, operator.lt, ndp.MANTLETOCRUST)\n",
    "        DG.add_transition((mantleIndex,crustIndex), xFn, operator.lt, 0.5*ndp.lRidge) #No crust on the upper plate\n",
    "        DG.add_transition((mantleIndex,crustIndex), ageVariable, operator.gt, 0.2)\n",
    "\n",
    "        DG.add_transition((harzIndex,crustIndex), depthFn, operator.lt, ndp.MANTLETOCRUST)\n",
    "        DG.add_transition((harzIndex,crustIndex), xFn, tempop, 0.5*ndp.lRidge) #This one sets no crust on the upper plate\n",
    "        DG.add_transition((harzIndex,crustIndex), ageVariable, operator.gt, crustageCond)\n",
    "        \n",
    "        \n",
    "        #Make sure to rebuild the condition list if you want changes to be applied\n",
    "        DG.build_condition_list(materialVariable)\n",
    "        \n",
    "        comm.barrier()\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        #Apply any materialVariable changes\n",
    "        for i in range(2): #go through twice\n",
    "            materialVariable.data[:] = fn.branching.conditional(DG.condition_list).evaluate(gSwarm)\n",
    "        \n",
    "        #Also update any information related to faults / interfaces:\n",
    "\n",
    "        sd, pts0 = fault.compute_signed_distance(gSwarm.particleCoordinates.data, distance=w0)\n",
    "        sp, pts0 = fault.compute_marker_proximity(gSwarm.particleCoordinates.data)\n",
    "\n",
    "        proximityVariable.data[np.logical_and(sd<0,sp == fault.ID)] = sp[np.logical_and(sd<0,sp == fault.ID)]\n",
    "\n",
    "        dv, nzv = fault.compute_normals(gSwarm.particleCoordinates.data)\n",
    "        directorVector.data[nzv] = dv[nzv]\n",
    "\n",
    "        proximityVariable.data[gSwarm.particleCoordinates.data[:,1]  < (1. - ndp.CRUSTVISCUTOFF)] = 0.\n",
    "        \n",
    "        #And add extra particles to interfaces as necessary\n",
    "        #subduction fault\n",
    "        introPoint = ndp.subzone - abs(ndp.subzone - ndp.lRidge)/2. #half way between ridge and Sz\n",
    "        fault.add_points([introPoint],[MAXY - faultthickness])\n",
    "\n",
    "\n",
    "        \n",
    "    ################\n",
    "    #Checkpoint\n",
    "    ################\n",
    "    if step % checkpoint_every == 0:\n",
    "        if uw.rank() == 0:\n",
    "            checkpoint1(step, checkpointPath,f_o, metric_output)           \n",
    "        checkpoint2(step, checkpointPath, gSwarm, f_o, varlist = varlist, varnames = varnames)\n",
    "        checkpoint3(step,  checkpointPath, interfaces,interfacenames )\n",
    "        f_o = open(os.path.join(outputPath, outputFile), 'a') #is this line supposed to be here?\n",
    "        \n",
    "    \n",
    "    \n",
    "f_o.close()\n",
    "print 'step =',step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d52958dc5cee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'file_path' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#viscVariable = gSwarm.add_variable( dataType=\"float\", count=1 )\n",
    "#viscVariable.data[:] = viscosityMapFn.evaluate(gSwarm)\n",
    "\n",
    "#buoyVariable = gSwarm.add_variable( dataType=\"float\", count=1 )\n",
    "#buoyVariable.data[:] = densityMapFn.evaluate(gSwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Level 3. lithosphere - mantle:\n",
    "tempMM = fn.view.min_max(temperatureField)\n",
    "tempMM.evaluate(mesh)\n",
    "TMAX = tempMM.max_global()\n",
    "mantleconditions = [ (                                  temperatureField < 0.9*ndp.TPP, 1.),\n",
    "                   (                                                   True , 0.) ]\n",
    "lithRestFn = fn.branching.conditional(mantleconditions)\n",
    "#lithRestFn*=rockRestFn #Add next level up in heirarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6026351151756232, 0.4643550314115336)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.1*ndp.TPP, 0.6*TMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='data:image/png;base64,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'>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig= glucifer.Figure()\n",
    "#fig.append( glucifer.objects.Points(gSwarm,lowerPlateRestFn))\n",
    "#fig.append( glucifer.objects.Points(gSwarm, viscosityMapFn, logScale=True, valueRange =[1e-3,1e5]))\n",
    "#fig.append( glucifer.objects.Surface(mesh, temperatureField ))#\n",
    "#fig.append( glucifer.objects.VectorArrows(mesh,velocityField, scaling=0.002))\n",
    "#fig.append( glucifer.objects.Surface(mesh,densityMapFn))\n",
    "#fig.append( glucifer.objects.Surface(mesh,raylieghFn))\n",
    "#fig.append( glucifer.objects.Points(swarmPlateBoundary, pointSize=4))\n",
    "#fig.show()\n",
    "#fig.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print('proc #' + str(comm.rank) + \" \" + str(Max_vx_surf ) )\n",
    "#if uw.rank()==0:\n",
    "#    print('Proc 0' +  \" \" + str(Max_vx_surf ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#figDb.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Add the viscous heating term\n",
    "#Need to be skeptical of Projection for viscosity. Also try direct interpolation (IDW)\n",
    "viscDisProj = uw.utils.MeshVariable_Projection( viscDisFnmesh, viscDisMapFn)\n",
    "viscDisProj.solve()\n",
    "#temperatureField.data[:] += ndp.Di*dt*viscDisFnmesh.evaluate(mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dt = advDiff.get_max_dt()*md.courantFac\n",
    "test = (ndp.Di/ndp.RA)*dt*viscDisFnmesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='data:image/png;base64,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'>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig= glucifer.Figure()\n",
    "#fig.append( glucifer.objects.Points(gSwarm,lowerPlateRestFn))\n",
    "#fig.append( glucifer.objects.Points(gSwarm, viscosityMapFn, logScale=True, valueRange =[1e-3,1e5]))\n",
    "fig.append( glucifer.objects.Surface(mesh, test))#\n",
    "\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7968333000347254e-05"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test.evaluate(mesh).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'results/T/0/xdmf/velocity_'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
